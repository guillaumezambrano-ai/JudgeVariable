{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9048bbf-22c3-4991-85b9-fe2dddc39b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could not fully set console to UTF-8 or wrap streams: 'OutStream' object has no attribute 'buffer'. Using PYTHONIOENCODING as fallback if set.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Load configuration from a file? (Default config if exists: pipeline_outputs\\experiment_20250630_212223\\run_config.json) (y/N):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                   Pipeline Configuration (Interactive Mode)                    \n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                            File Paths Configuration                            \n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter base directory for outputs (default: pipeline_outputs):  \n",
      "Enter path to cases XLSX file:  \"C:\\Users\\guill\\OneDrive\\Documentos\\MDPI_STATS\\EXPERIMENT3\\OUTCOME18937.xlsx\"\n",
      "Enter path to judges XLSX file (optional, press Enter to skip) (default: ):  \"C:\\Users\\guill\\OneDrive\\Documentos\\MDPI_STATS\\EXPERIMENT2\\JUDGES_pseudo.xlsx\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                              Configure Data Merge                              \n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                     RAW CASES Data - Select Linking Column                     \n",
      "================================================================================\n",
      "\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|   Index (for this list) | Column Name                                                      |\n",
      "+=========================+==================================================================+\n",
      "|                       0 | source_filename                                                  |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       1 | majority                                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       2 | foster care                                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       3 | name                                                             |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       4 | sex                                                              |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       5 | age_Trial                                                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       6 | age_Appeal                                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       7 | child_immediately_after_appeal_child_living_arrangement          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       8 | child_immediately_after_appeal_support_amount_eur                |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       9 | child_immediately_after_appeal_support_paid_by                   |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      10 | child_immediately_before_appeal_child_living_arrangement         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      11 | child_immediately_before_appeal_support_amount_eur               |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      12 | child_immediately_before_appeal_support_paid_by                  |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      13 | child_child_expressed_conflict                                   |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      14 | child_child_expressed_living_arrangement_preference              |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      15 | child_during_appeal_father_request_regarding_living_arrangements |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      16 | child_father_child_support_request                               |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      17 | child_during_appeal_mother_request_regarding_living_arrangements |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      18 | child_mother_child_support_request                               |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      19 | father_parental_fitness                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      20 | mother_parental_fitness                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      21 | father_has_history_of_abuse_against_child                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      22 | mother_has_history_of_abuse_against_child                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      23 | father_has_history_of_abuse_against_mother                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      24 | mother_has_history_of_abuse_against_father                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      25 | father_has_history_of_neglect                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      26 | mother_has_history_of_neglect                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      27 | father_has_psych_issues                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      28 | mother_has_psych_issues                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      29 | father_has_addiction_issues                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      30 | mother_has_addiction_issues                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      31 | father_is_invested_with_child                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      32 | mother_is_invested_with_child                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      33 | father_employment_status                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      34 | father_monthly_income                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      35 | mother_employment_status                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      36 | mother_monthly_income                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      37 | father_work_availability                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      38 | mother_work_availability                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      39 | father_housing_status                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      40 | mother_housing_status                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      41 | Parent Proximity                                                 |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      42 | father_lives_near_school                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      43 | mother_lives_near_school                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      44 | father_receives_social_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      45 | mother_receives_social_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "  Total columns in this list: 46\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter column name from RAW CASES data to link with Judges data:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                    RAW JUDGES Data - Select Linking Column                     \n",
      "================================================================================\n",
      "\n",
      "+-------------------------+----------------------------+\n",
      "|   Index (for this list) | Column Name                |\n",
      "+=========================+============================+\n",
      "|                       0 | source_file                |\n",
      "+-------------------------+----------------------------+\n",
      "|                       1 | capp_city                  |\n",
      "+-------------------------+----------------------------+\n",
      "|                       2 | capp_date                  |\n",
      "+-------------------------+----------------------------+\n",
      "|                       3 | CaseID                     |\n",
      "+-------------------------+----------------------------+\n",
      "|                       4 | jaf_city                   |\n",
      "+-------------------------+----------------------------+\n",
      "|                       5 | sex1                       |\n",
      "+-------------------------+----------------------------+\n",
      "|                       6 | judge1                     |\n",
      "+-------------------------+----------------------------+\n",
      "|                       7 | sex2                       |\n",
      "+-------------------------+----------------------------+\n",
      "|                       8 | judge2                     |\n",
      "+-------------------------+----------------------------+\n",
      "|                       9 | sex3                       |\n",
      "+-------------------------+----------------------------+\n",
      "|                      10 | judge3                     |\n",
      "+-------------------------+----------------------------+\n",
      "|                      11 | reporter                   |\n",
      "+-------------------------+----------------------------+\n",
      "|                      12 | mother_benefited_legal_aid |\n",
      "+-------------------------+----------------------------+\n",
      "|                      13 | father_benefited_legal_aid |\n",
      "+-------------------------+----------------------------+\n",
      "  Total columns in this list: 14\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter corresponding column name from RAW JUDGES data:  0\n",
      "Enter merge type (e.g., 'left', 'inner') (default: left) (options: left, right, inner, outer):  left\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                  Select Operational Columns from Merged Data                   \n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                   Full List of Columns in Final Merged Data                    \n",
      "================================================================================\n",
      "\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|   Index (for this list) | Column Name                                                      |\n",
      "+=========================+==================================================================+\n",
      "|                       0 | source_filename                                                  |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       1 | majority                                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       2 | foster care                                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       3 | name                                                             |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       4 | sex                                                              |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       5 | age_Trial                                                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       6 | age_Appeal                                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       7 | child_immediately_after_appeal_child_living_arrangement          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       8 | child_immediately_after_appeal_support_amount_eur                |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       9 | child_immediately_after_appeal_support_paid_by                   |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      10 | child_immediately_before_appeal_child_living_arrangement         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      11 | child_immediately_before_appeal_support_amount_eur               |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      12 | child_immediately_before_appeal_support_paid_by                  |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      13 | child_child_expressed_conflict                                   |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      14 | child_child_expressed_living_arrangement_preference              |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      15 | child_during_appeal_father_request_regarding_living_arrangements |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      16 | child_father_child_support_request                               |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      17 | child_during_appeal_mother_request_regarding_living_arrangements |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      18 | child_mother_child_support_request                               |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      19 | father_parental_fitness                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      20 | mother_parental_fitness                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      21 | father_has_history_of_abuse_against_child                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      22 | mother_has_history_of_abuse_against_child                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      23 | father_has_history_of_abuse_against_mother                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      24 | mother_has_history_of_abuse_against_father                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      25 | father_has_history_of_neglect                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      26 | mother_has_history_of_neglect                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      27 | father_has_psych_issues                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      28 | mother_has_psych_issues                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      29 | father_has_addiction_issues                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      30 | mother_has_addiction_issues                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      31 | father_is_invested_with_child                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      32 | mother_is_invested_with_child                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      33 | father_employment_status                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      34 | father_monthly_income                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      35 | mother_employment_status                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      36 | mother_monthly_income                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      37 | father_work_availability                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      38 | mother_work_availability                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      39 | father_housing_status                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      40 | mother_housing_status                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      41 | Parent Proximity                                                 |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      42 | father_lives_near_school                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      43 | mother_lives_near_school                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      44 | father_receives_social_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      45 | mother_receives_social_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      46 | source_file                                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      47 | capp_city                                                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      48 | capp_date                                                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      49 | CaseID                                                           |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      50 | jaf_city                                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      51 | sex1                                                             |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      52 | judge1                                                           |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      53 | sex2                                                             |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      54 | judge2                                                           |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      55 | sex3                                                             |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      56 | judge3                                                           |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      57 | reporter                                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      58 | mother_benefited_legal_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      59 | father_benefited_legal_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "  Total columns in this list: 60\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Will you use judge-specific bucketing? (Y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Select Judge ID for Bucketing ---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the column NAME or INDEX (from the full list above) for Judge ID (for bucketing):  52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Select Target Column ---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the TARGET column NAME or INDEX (from the full list above, e.g., 'custody_outcome'):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                             Select Feature Columns                             \n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "   POTENTIAL FEATURES (select from this list using its 0-based index or name)   \n",
      "================================================================================\n",
      "\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|   Index (for this list) | Column Name                                                      |\n",
      "+=========================+==================================================================+\n",
      "|                       0 | source_filename                                                  |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       1 | majority                                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       2 | foster care                                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       3 | name                                                             |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       4 | sex                                                              |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       5 | age_Trial                                                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       6 | age_Appeal                                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       7 | child_immediately_after_appeal_support_amount_eur                |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       8 | child_immediately_after_appeal_support_paid_by                   |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                       9 | child_immediately_before_appeal_child_living_arrangement         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      10 | child_immediately_before_appeal_support_amount_eur               |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      11 | child_immediately_before_appeal_support_paid_by                  |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      12 | child_child_expressed_conflict                                   |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      13 | child_child_expressed_living_arrangement_preference              |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      14 | child_during_appeal_father_request_regarding_living_arrangements |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      15 | child_father_child_support_request                               |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      16 | child_during_appeal_mother_request_regarding_living_arrangements |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      17 | child_mother_child_support_request                               |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      18 | father_parental_fitness                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      19 | mother_parental_fitness                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      20 | father_has_history_of_abuse_against_child                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      21 | mother_has_history_of_abuse_against_child                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      22 | father_has_history_of_abuse_against_mother                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      23 | mother_has_history_of_abuse_against_father                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      24 | father_has_history_of_neglect                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      25 | mother_has_history_of_neglect                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      26 | father_has_psych_issues                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      27 | mother_has_psych_issues                                          |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      28 | father_has_addiction_issues                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      29 | mother_has_addiction_issues                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      30 | father_is_invested_with_child                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      31 | mother_is_invested_with_child                                    |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      32 | father_employment_status                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      33 | father_monthly_income                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      34 | mother_employment_status                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      35 | mother_monthly_income                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      36 | father_work_availability                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      37 | mother_work_availability                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      38 | father_housing_status                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      39 | mother_housing_status                                            |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      40 | Parent Proximity                                                 |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      41 | father_lives_near_school                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      42 | mother_lives_near_school                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      43 | father_receives_social_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      44 | mother_receives_social_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      45 | source_file                                                      |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      46 | capp_city                                                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      47 | capp_date                                                        |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      48 | CaseID                                                           |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      49 | jaf_city                                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      50 | sex1                                                             |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      51 | sex2                                                             |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      52 | judge2                                                           |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      53 | sex3                                                             |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      54 | judge3                                                           |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      55 | reporter                                                         |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      56 | mother_benefited_legal_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "|                      57 | father_benefited_legal_aid                                       |\n",
      "+-------------------------+------------------------------------------------------------------+\n",
      "  Total columns in this list: 58\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Use all 58 listed POTENTIAL features? (Y/n):  n\n",
      "Enter FEATURE column NAMES or INDICES (comma-separated, from the POTENTIAL FEATURES list above):  12,13,14,16,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,34,36,37,38,39,40,41,42,43,44,56,57,50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                        Confirm Final Selected Features                         \n",
      "================================================================================\n",
      "\n",
      "You have selected the following features for the model:\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|   # (For Info) | Selected Feature Name                                            |\n",
      "+================+==================================================================+\n",
      "|              0 | child_child_expressed_conflict                                   |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|              1 | child_child_expressed_living_arrangement_preference              |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|              2 | child_during_appeal_father_request_regarding_living_arrangements |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|              3 | child_during_appeal_mother_request_regarding_living_arrangements |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|              4 | father_parental_fitness                                          |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|              5 | mother_parental_fitness                                          |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|              6 | father_has_history_of_abuse_against_child                        |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|              7 | mother_has_history_of_abuse_against_child                        |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|              8 | father_has_history_of_abuse_against_mother                       |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|              9 | mother_has_history_of_abuse_against_father                       |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             10 | father_has_history_of_neglect                                    |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             11 | mother_has_history_of_neglect                                    |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             12 | father_has_psych_issues                                          |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             13 | mother_has_psych_issues                                          |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             14 | father_has_addiction_issues                                      |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             15 | mother_has_addiction_issues                                      |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             16 | father_is_invested_with_child                                    |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             17 | mother_is_invested_with_child                                    |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             18 | father_employment_status                                         |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             19 | mother_employment_status                                         |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             20 | father_work_availability                                         |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             21 | mother_work_availability                                         |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             22 | father_housing_status                                            |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             23 | mother_housing_status                                            |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             24 | Parent Proximity                                                 |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             25 | father_lives_near_school                                         |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             26 | mother_lives_near_school                                         |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             27 | father_receives_social_aid                                       |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             28 | mother_receives_social_aid                                       |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             29 | mother_benefited_legal_aid                                       |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             30 | father_benefited_legal_aid                                       |\n",
      "+----------------+------------------------------------------------------------------+\n",
      "|             31 | sex1                                                             |\n",
      "+----------------+------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Proceed with these features? (Y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                            Feature Type Validation                             \n",
      "================================================================================\n",
      "\n",
      "\n",
      "--- Validating Feature: 'child_child_expressed_conflict' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['father' 'none' 'mother']\n",
      "  Number of Unique Values (non-NaN): 3\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'child_child_expressed_conflict' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'child_child_expressed_living_arrangement_preference' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['mother' 'unknown' 'father' 'shared']\n",
      "  Number of Unique Values (non-NaN): 4\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'child_child_expressed_living_arrangement_preference' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'child_during_appeal_father_request_regarding_living_arrangements' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['none' 'sole' 'shared' 'unknown']\n",
      "  Number of Unique Values (non-NaN): 4\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'child_during_appeal_father_request_regarding_living_arrangements' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'child_during_appeal_mother_request_regarding_living_arrangements' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['sole' 'shared' 'none' 'unknown']\n",
      "  Number of Unique Values (non-NaN): 4\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'child_during_appeal_mother_request_regarding_living_arrangements' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_parental_fitness' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['unfit' 'fit']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_parental_fitness' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_parental_fitness' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['fit' 'unfit']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_parental_fitness' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_has_history_of_abuse_against_child' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_has_history_of_abuse_against_child' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_has_history_of_abuse_against_child' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_has_history_of_abuse_against_child' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_has_history_of_abuse_against_mother' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_has_history_of_abuse_against_mother' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_has_history_of_abuse_against_father' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_has_history_of_abuse_against_father' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_has_history_of_neglect' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['yes' 'no']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_has_history_of_neglect' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_has_history_of_neglect' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_has_history_of_neglect' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_has_psych_issues' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_has_psych_issues' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_has_psych_issues' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_has_psych_issues' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_has_addiction_issues' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_has_addiction_issues' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_has_addiction_issues' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_has_addiction_issues' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_is_invested_with_child' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_is_invested_with_child' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_is_invested_with_child' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['yes' 'no']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_is_invested_with_child' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_employment_status' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['unemployed' 'employed']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_employment_status' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_employment_status' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['unemployed' 'employed']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_employment_status' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_work_availability' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['unknown' 'regular' 'irregular']\n",
      "  Number of Unique Values (non-NaN): 3\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_work_availability' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_work_availability' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['unknown' 'regular' 'irregular']\n",
      "  Number of Unique Values (non-NaN): 3\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_work_availability' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_housing_status' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['unknown' 'adequate' 'inadequate']\n",
      "  Number of Unique Values (non-NaN): 3\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_housing_status' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_housing_status' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['unknown' 'adequate' 'inadequate']\n",
      "  Number of Unique Values (non-NaN): 3\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_housing_status' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'Parent Proximity' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'Parent Proximity' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_lives_near_school' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes' 'unknown']\n",
      "  Number of Unique Values (non-NaN): 3\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_lives_near_school' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_lives_near_school' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['yes' 'no' 'unknown']\n",
      "  Number of Unique Values (non-NaN): 3\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_lives_near_school' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_receives_social_aid' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_receives_social_aid' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_receives_social_aid' ---\n",
      "  Original Data Type: object\n",
      "  Unique Values (sample, non-NaN): ['no' 'yes']\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Detected as non-numeric dtype.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_receives_social_aid' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'mother_benefited_legal_aid' ---\n",
      "  Original Data Type: int64\n",
      "  Unique Values (sample, non-NaN): [1 0]\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Numeric dtype, but <=7 unique values suggests it might be categorical (e.g., codes).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'mother_benefited_legal_aid' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'father_benefited_legal_aid' ---\n",
      "  Original Data Type: int64\n",
      "  Unique Values (sample, non-NaN): [0 1]\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Numeric dtype, but <=7 unique values suggests it might be categorical (e.g., codes).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'father_benefited_legal_aid' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "--- Validating Feature: 'sex1' ---\n",
      "  Original Data Type: float64\n",
      "  Unique Values (sample, non-NaN): [1. 0.]\n",
      "  Number of Unique Values (non-NaN): 2\n",
      "  Suggestion: Treat as CATEGORICAL. Reason: Numeric dtype, but <=7 unique values suggests it might be categorical (e.g., codes).\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Confirm type for 'sex1' (NUMERIC or CATEGORICAL)? (default: categorical) (options: numeric, categorical):  categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Selected as CATEGORICAL.\n",
      "\n",
      "================================================================================\n",
      "                          Data Encoding Configuration                           \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Target Variable: 'child_immediately_after_appeal_child_living_arrangement'\n",
      "  Unique values found in 'child_immediately_after_appeal_child_living_arrangement': ['mother' 'father' 'shared']\n",
      "  Expected target classes: mother, father, shared (mapped to [0, 1, 2])\n",
      "\n",
      "Please map your raw target labels to the standard numeric classes:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  Enter raw label in your data that corresponds to 'mother' (Class 0):  mother\n",
      "  Enter raw label in your data that corresponds to 'father' (Class 1):  father\n",
      "  Enter raw label in your data that corresponds to 'shared' (Class 2):  shared\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                         Judge Bucketing Configuration                          \n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enable judge-specific bucketing? (Y/n):  y\n",
      "Min samples per judge for dedicated bucket (others to 'generic') (default: 30):  300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                         Class Balancing Configuration                          \n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Balancing method (default: sampling) (options: none, sampling, weighting):  sampling\n",
      "Target class percentages for (mother,father,shared) (default: 33,33,34):  40,30,30\n",
      "Models to run (comma separated, available ['RandomForest', 'LogisticRegression', 'SVC', 'XGB']) (default: RandomForest,LogisticRegression,SVC,XGB):  RandomForest,SVC,XGB\n",
      "Number of CV folds (default: 5):  5\n",
      "RandomizedSearch iterations (default: 50):  18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                        Hyper-parameter Grid (optional)                         \n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Load hyper-parameter search space from a JSON file? (y/N):  y\n",
      "Path to hyper-param JSON file:  \"C:\\Users\\guill\\OneDrive\\Documentos\\MDPI_STATS\\CODE\\CASE OUTCOME PREDICTION\\HyperGrid_COMBO3.json\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Custom hyper-parameter grid loaded.\n",
      "\n",
      "================================================================================\n",
      "                                 DATA OVERVIEW                                  \n",
      "================================================================================\n",
      "\n",
      "Final dataframe shape : (18937, 60)\n",
      "\n",
      "================================================================================\n",
      "                         Class Balancing Configuration                          \n",
      "================================================================================\n",
      "\n",
      "Current global distribution:\n",
      "\n",
      "GLOBAL\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 12741 | 67.28 % |\n",
      "| father | 4216  | 22.26 % |\n",
      "| shared | 1980  | 10.46 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Balancing method (default: sampling) (options: none, sampling, weighting):  sampling\n",
      "Target class percentages for (mother,father,shared) (default: 33,33,34):  40,30,30\n",
      "\n",
      "Test-set percentage (default: 20):  20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation share per fold  20.0%\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET anatole  (824 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "anatole_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  122  | 23.15 % |\n",
      "| shared |  50   | 9.49 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.824\n",
      "\n",
      "anatole_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  122  | 23.15 % |\n",
      "| shared |  50   | 9.49 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.770\n",
      "\n",
      "anatole_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  123  | 23.34 % |\n",
      "| shared |  49   | 9.30 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.806\n",
      "\n",
      "anatole_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  123  | 23.34 % |\n",
      "| shared |  49   | 9.30 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.824\n",
      "\n",
      "anatole_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  356  | 67.42 % |\n",
      "| father |  122  | 23.11 % |\n",
      "| shared |  50   | 9.47 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.858\n",
      "  CV Macro-F1 = 0.816  0.029\n",
      "\n",
      "anatole_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  444  | 67.37 % |\n",
      "| father |  153  | 23.22 % |\n",
      "| shared |  62   | 9.41 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 40.00 % |\n",
      "| father |  198  | 30.00 % |\n",
      "| shared |  198  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.835\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "anatole_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  122  | 23.15 % |\n",
      "| shared |  50   | 9.49 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.824\n",
      "\n",
      "anatole_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  122  | 23.15 % |\n",
      "| shared |  50   | 9.49 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.770\n",
      "\n",
      "anatole_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  123  | 23.34 % |\n",
      "| shared |  49   | 9.30 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.853\n",
      "\n",
      "anatole_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  123  | 23.34 % |\n",
      "| shared |  49   | 9.30 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.835\n",
      "\n",
      "anatole_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  356  | 67.42 % |\n",
      "| father |  122  | 23.11 % |\n",
      "| shared |  50   | 9.47 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.864\n",
      "  CV Macro-F1 = 0.829  0.033\n",
      "\n",
      "anatole_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  444  | 67.37 % |\n",
      "| father |  153  | 23.22 % |\n",
      "| shared |  62   | 9.41 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 40.00 % |\n",
      "| father |  198  | 30.00 % |\n",
      "| shared |  198  | 30.00 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.830\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "anatole_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  122  | 23.15 % |\n",
      "| shared |  50   | 9.49 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.758\n",
      "\n",
      "anatole_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  122  | 23.15 % |\n",
      "| shared |  50   | 9.49 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.759\n",
      "\n",
      "anatole_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  123  | 23.34 % |\n",
      "| shared |  49   | 9.30 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.842\n",
      "\n",
      "anatole_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  355  | 67.36 % |\n",
      "| father |  123  | 23.34 % |\n",
      "| shared |  49   | 9.30 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.848\n",
      "\n",
      "anatole_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  356  | 67.42 % |\n",
      "| father |  122  | 23.11 % |\n",
      "| shared |  50   | 9.47 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  211  | 40.04 % |\n",
      "| father |  158  | 29.98 % |\n",
      "| shared |  158  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.801\n",
      "  CV Macro-F1 = 0.801  0.039\n",
      "\n",
      "anatole_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  444  | 67.37 % |\n",
      "| father |  153  | 23.22 % |\n",
      "| shared |  62   | 9.41 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "anatole_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 40.00 % |\n",
      "| father |  198  | 30.00 % |\n",
      "| shared |  198  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.821\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET babiche  (769 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "babiche_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.832\n",
      "\n",
      "babiche_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.821\n",
      "\n",
      "babiche_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.754\n",
      "\n",
      "babiche_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.786\n",
      "\n",
      "babiche_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  116  | 23.58 % |\n",
      "| shared |  52   | 10.57 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.765\n",
      "  CV Macro-F1 = 0.792  0.030\n",
      "\n",
      "babiche_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  405  | 65.85 % |\n",
      "| father |  144  | 23.41 % |\n",
      "| shared |  66   | 10.73 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  246  | 40.07 % |\n",
      "| father |  184  | 29.97 % |\n",
      "| shared |  184  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.826\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "babiche_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.810\n",
      "\n",
      "babiche_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.817\n",
      "\n",
      "babiche_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.708\n",
      "\n",
      "babiche_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.867\n",
      "\n",
      "babiche_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  116  | 23.58 % |\n",
      "| shared |  52   | 10.57 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.816\n",
      "  CV Macro-F1 = 0.803  0.052\n",
      "\n",
      "babiche_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  405  | 65.85 % |\n",
      "| father |  144  | 23.41 % |\n",
      "| shared |  66   | 10.73 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  246  | 40.07 % |\n",
      "| father |  184  | 29.97 % |\n",
      "| shared |  184  | 29.97 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.865\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "babiche_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.741\n",
      "\n",
      "babiche_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.829\n",
      "\n",
      "babiche_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.771\n",
      "\n",
      "babiche_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  115  | 23.37 % |\n",
      "| shared |  53   | 10.77 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.791\n",
      "\n",
      "babiche_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  324  | 65.85 % |\n",
      "| father |  116  | 23.58 % |\n",
      "| shared |  52   | 10.57 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  197  | 39.96 % |\n",
      "| father |  148  | 30.02 % |\n",
      "| shared |  148  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.750\n",
      "  CV Macro-F1 = 0.776  0.032\n",
      "\n",
      "babiche_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  405  | 65.85 % |\n",
      "| father |  144  | 23.41 % |\n",
      "| shared |  66   | 10.73 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "babiche_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  246  | 40.07 % |\n",
      "| father |  184  | 29.97 % |\n",
      "| shared |  184  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.846\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET cabeche  (731 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "cabeche_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  103  | 22.06 % |\n",
      "| shared |  69   | 14.78 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.859\n",
      "\n",
      "cabeche_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  103  | 22.06 % |\n",
      "| shared |  69   | 14.78 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.793\n",
      "\n",
      "cabeche_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  103  | 22.06 % |\n",
      "| shared |  69   | 14.78 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.805\n",
      "\n",
      "cabeche_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  104  | 22.27 % |\n",
      "| shared |  68   | 14.56 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.829\n",
      "\n",
      "cabeche_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  296  | 63.25 % |\n",
      "| father |  103  | 22.01 % |\n",
      "| shared |  69   | 14.74 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.816\n",
      "  CV Macro-F1 = 0.820  0.023\n",
      "\n",
      "cabeche_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  369  | 63.18 % |\n",
      "| father |  129  | 22.09 % |\n",
      "| shared |  86   | 14.73 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 40.07 % |\n",
      "| father |  175  | 29.97 % |\n",
      "| shared |  175  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.856\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "cabeche_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  103  | 22.06 % |\n",
      "| shared |  69   | 14.78 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.841\n",
      "\n",
      "cabeche_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  103  | 22.06 % |\n",
      "| shared |  69   | 14.78 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.695\n",
      "\n",
      "cabeche_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  103  | 22.06 % |\n",
      "| shared |  69   | 14.78 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.860\n",
      "\n",
      "cabeche_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  104  | 22.27 % |\n",
      "| shared |  68   | 14.56 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.832\n",
      "\n",
      "cabeche_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  296  | 63.25 % |\n",
      "| father |  103  | 22.01 % |\n",
      "| shared |  69   | 14.74 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.826\n",
      "  CV Macro-F1 = 0.811  0.059\n",
      "\n",
      "cabeche_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  369  | 63.18 % |\n",
      "| father |  129  | 22.09 % |\n",
      "| shared |  86   | 14.73 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 40.07 % |\n",
      "| father |  175  | 29.97 % |\n",
      "| shared |  175  | 29.97 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.808\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "cabeche_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  103  | 22.06 % |\n",
      "| shared |  69   | 14.78 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.821\n",
      "\n",
      "cabeche_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  103  | 22.06 % |\n",
      "| shared |  69   | 14.78 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.769\n",
      "\n",
      "cabeche_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  103  | 22.06 % |\n",
      "| shared |  69   | 14.78 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.813\n",
      "\n",
      "cabeche_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  295  | 63.17 % |\n",
      "| father |  104  | 22.27 % |\n",
      "| shared |  68   | 14.56 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.832\n",
      "\n",
      "cabeche_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  296  | 63.25 % |\n",
      "| father |  103  | 22.01 % |\n",
      "| shared |  69   | 14.74 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  187  | 40.04 % |\n",
      "| father |  140  | 29.98 % |\n",
      "| shared |  140  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.815\n",
      "  CV Macro-F1 = 0.810  0.022\n",
      "\n",
      "cabeche_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  369  | 63.18 % |\n",
      "| father |  129  | 22.09 % |\n",
      "| shared |  86   | 14.73 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "cabeche_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 40.07 % |\n",
      "| father |  175  | 29.97 % |\n",
      "| shared |  175  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.811\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET dacrons  (635 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "dacrons_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 65.02 % |\n",
      "| father |  97   | 23.89 % |\n",
      "| shared |  45   | 11.08 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 39.90 % |\n",
      "| father |  122  | 30.05 % |\n",
      "| shared |  122  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.907\n",
      "\n",
      "dacrons_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 65.02 % |\n",
      "| father |  97   | 23.89 % |\n",
      "| shared |  45   | 11.08 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 39.90 % |\n",
      "| father |  122  | 30.05 % |\n",
      "| shared |  122  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.878\n",
      "\n",
      "dacrons_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 65.02 % |\n",
      "| father |  96   | 23.65 % |\n",
      "| shared |  46   | 11.33 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 39.90 % |\n",
      "| father |  122  | 30.05 % |\n",
      "| shared |  122  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.850\n",
      "\n",
      "dacrons_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 64.86 % |\n",
      "| father |  97   | 23.83 % |\n",
      "| shared |  46   | 11.30 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  163  | 40.05 % |\n",
      "| father |  122  | 29.98 % |\n",
      "| shared |  122  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.888\n",
      "\n",
      "dacrons_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 64.86 % |\n",
      "| father |  97   | 23.83 % |\n",
      "| shared |  46   | 11.30 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  163  | 40.05 % |\n",
      "| father |  122  | 29.98 % |\n",
      "| shared |  122  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.788\n",
      "  CV Macro-F1 = 0.862  0.041\n",
      "\n",
      "dacrons_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  330  | 64.96 % |\n",
      "| father |  121  | 23.82 % |\n",
      "| shared |  57   | 11.22 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 40.04 % |\n",
      "| father |  152  | 29.98 % |\n",
      "| shared |  152  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.827\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "dacrons_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 65.02 % |\n",
      "| father |  97   | 23.89 % |\n",
      "| shared |  45   | 11.08 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 39.90 % |\n",
      "| father |  122  | 30.05 % |\n",
      "| shared |  122  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.866\n",
      "\n",
      "dacrons_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 65.02 % |\n",
      "| father |  97   | 23.89 % |\n",
      "| shared |  45   | 11.08 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 39.90 % |\n",
      "| father |  122  | 30.05 % |\n",
      "| shared |  122  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.859\n",
      "\n",
      "dacrons_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 65.02 % |\n",
      "| father |  96   | 23.65 % |\n",
      "| shared |  46   | 11.33 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 39.90 % |\n",
      "| father |  122  | 30.05 % |\n",
      "| shared |  122  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.819\n",
      "\n",
      "dacrons_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 64.86 % |\n",
      "| father |  97   | 23.83 % |\n",
      "| shared |  46   | 11.30 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  163  | 40.05 % |\n",
      "| father |  122  | 29.98 % |\n",
      "| shared |  122  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.830\n",
      "\n",
      "dacrons_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 64.86 % |\n",
      "| father |  97   | 23.83 % |\n",
      "| shared |  46   | 11.30 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  163  | 40.05 % |\n",
      "| father |  122  | 29.98 % |\n",
      "| shared |  122  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.804\n",
      "  CV Macro-F1 = 0.836  0.023\n",
      "\n",
      "dacrons_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  330  | 64.96 % |\n",
      "| father |  121  | 23.82 % |\n",
      "| shared |  57   | 11.22 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 40.04 % |\n",
      "| father |  152  | 29.98 % |\n",
      "| shared |  152  | 29.98 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.789\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "dacrons_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 65.02 % |\n",
      "| father |  97   | 23.89 % |\n",
      "| shared |  45   | 11.08 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 39.90 % |\n",
      "| father |  122  | 30.05 % |\n",
      "| shared |  122  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.840\n",
      "\n",
      "dacrons_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 65.02 % |\n",
      "| father |  97   | 23.89 % |\n",
      "| shared |  45   | 11.08 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 39.90 % |\n",
      "| father |  122  | 30.05 % |\n",
      "| shared |  122  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.878\n",
      "\n",
      "dacrons_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 65.02 % |\n",
      "| father |  96   | 23.65 % |\n",
      "| shared |  46   | 11.33 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 39.90 % |\n",
      "| father |  122  | 30.05 % |\n",
      "| shared |  122  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.879\n",
      "\n",
      "dacrons_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 64.86 % |\n",
      "| father |  97   | 23.83 % |\n",
      "| shared |  46   | 11.30 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  163  | 40.05 % |\n",
      "| father |  122  | 29.98 % |\n",
      "| shared |  122  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.859\n",
      "\n",
      "dacrons_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  264  | 64.86 % |\n",
      "| father |  97   | 23.83 % |\n",
      "| shared |  46   | 11.30 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  163  | 40.05 % |\n",
      "| father |  122  | 29.98 % |\n",
      "| shared |  122  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.765\n",
      "  CV Macro-F1 = 0.844  0.042\n",
      "\n",
      "dacrons_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  330  | 64.96 % |\n",
      "| father |  121  | 23.82 % |\n",
      "| shared |  57   | 11.22 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "dacrons_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 40.04 % |\n",
      "| father |  152  | 29.98 % |\n",
      "| shared |  152  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.789\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET echevin  (590 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "echevin_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  233  | 61.80 % |\n",
      "| father |  100  | 26.53 % |\n",
      "| shared |  44   | 11.67 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.872\n",
      "\n",
      "echevin_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  233  | 61.80 % |\n",
      "| father |  100  | 26.53 % |\n",
      "| shared |  44   | 11.67 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.909\n",
      "\n",
      "echevin_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 61.90 % |\n",
      "| father |  100  | 26.46 % |\n",
      "| shared |  44   | 11.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.905\n",
      "\n",
      "echevin_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 61.90 % |\n",
      "| father |  100  | 26.46 % |\n",
      "| shared |  44   | 11.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.857\n",
      "\n",
      "echevin_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 61.90 % |\n",
      "| father |  100  | 26.46 % |\n",
      "| shared |  44   | 11.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.896\n",
      "  CV Macro-F1 = 0.888  0.020\n",
      "\n",
      "echevin_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  292  | 61.86 % |\n",
      "| father |  125  | 26.48 % |\n",
      "| shared |  55   | 11.65 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  189  | 39.96 % |\n",
      "| father |  142  | 30.02 % |\n",
      "| shared |  142  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.870\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "echevin_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  233  | 61.80 % |\n",
      "| father |  100  | 26.53 % |\n",
      "| shared |  44   | 11.67 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.848\n",
      "\n",
      "echevin_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  233  | 61.80 % |\n",
      "| father |  100  | 26.53 % |\n",
      "| shared |  44   | 11.67 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.860\n",
      "\n",
      "echevin_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 61.90 % |\n",
      "| father |  100  | 26.46 % |\n",
      "| shared |  44   | 11.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.912\n",
      "\n",
      "echevin_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 61.90 % |\n",
      "| father |  100  | 26.46 % |\n",
      "| shared |  44   | 11.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.867\n",
      "\n",
      "echevin_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 61.90 % |\n",
      "| father |  100  | 26.46 % |\n",
      "| shared |  44   | 11.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.863\n",
      "  CV Macro-F1 = 0.870  0.022\n",
      "\n",
      "echevin_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  292  | 61.86 % |\n",
      "| father |  125  | 26.48 % |\n",
      "| shared |  55   | 11.65 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  189  | 39.96 % |\n",
      "| father |  142  | 30.02 % |\n",
      "| shared |  142  | 30.02 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.855\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "echevin_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  233  | 61.80 % |\n",
      "| father |  100  | 26.53 % |\n",
      "| shared |  44   | 11.67 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.855\n",
      "\n",
      "echevin_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  233  | 61.80 % |\n",
      "| father |  100  | 26.53 % |\n",
      "| shared |  44   | 11.67 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.865\n",
      "\n",
      "echevin_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 61.90 % |\n",
      "| father |  100  | 26.46 % |\n",
      "| shared |  44   | 11.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.896\n",
      "\n",
      "echevin_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 61.90 % |\n",
      "| father |  100  | 26.46 % |\n",
      "| shared |  44   | 11.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.822\n",
      "\n",
      "echevin_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  234  | 61.90 % |\n",
      "| father |  100  | 26.46 % |\n",
      "| shared |  44   | 11.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  151  | 40.05 % |\n",
      "| father |  113  | 29.97 % |\n",
      "| shared |  113  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.861\n",
      "  CV Macro-F1 = 0.860  0.024\n",
      "\n",
      "echevin_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  292  | 61.86 % |\n",
      "| father |  125  | 26.48 % |\n",
      "| shared |  55   | 11.65 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "echevin_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  189  | 39.96 % |\n",
      "| father |  142  | 30.02 % |\n",
      "| shared |  142  | 30.02 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.852\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET gargote  (572 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "gargote_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.34 % |\n",
      "| father |  65   | 17.81 % |\n",
      "| shared |  25   | 6.85 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.887\n",
      "\n",
      "gargote_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.34 % |\n",
      "| father |  65   | 17.81 % |\n",
      "| shared |  25   | 6.85 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.698\n",
      "\n",
      "gargote_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.14 % |\n",
      "| father |  65   | 17.76 % |\n",
      "| shared |  26   | 7.10 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.910\n",
      "\n",
      "gargote_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.14 % |\n",
      "| father |  65   | 17.76 % |\n",
      "| shared |  26   | 7.10 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.793\n",
      "\n",
      "gargote_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  276  | 75.41 % |\n",
      "| father |  64   | 17.49 % |\n",
      "| shared |  26   | 7.10 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.837\n",
      "  CV Macro-F1 = 0.825  0.075\n",
      "\n",
      "gargote_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  344  | 75.27 % |\n",
      "| father |  81   | 17.72 % |\n",
      "| shared |  32   | 7.00 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  183  | 40.04 % |\n",
      "| father |  137  | 29.98 % |\n",
      "| shared |  137  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.862\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "gargote_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.34 % |\n",
      "| father |  65   | 17.81 % |\n",
      "| shared |  25   | 6.85 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.887\n",
      "\n",
      "gargote_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.34 % |\n",
      "| father |  65   | 17.81 % |\n",
      "| shared |  25   | 6.85 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.679\n",
      "\n",
      "gargote_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.14 % |\n",
      "| father |  65   | 17.76 % |\n",
      "| shared |  26   | 7.10 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.923\n",
      "\n",
      "gargote_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.14 % |\n",
      "| father |  65   | 17.76 % |\n",
      "| shared |  26   | 7.10 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.750\n",
      "\n",
      "gargote_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  276  | 75.41 % |\n",
      "| father |  64   | 17.49 % |\n",
      "| shared |  26   | 7.10 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.837\n",
      "  CV Macro-F1 = 0.815  0.089\n",
      "\n",
      "gargote_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  344  | 75.27 % |\n",
      "| father |  81   | 17.72 % |\n",
      "| shared |  32   | 7.00 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  183  | 40.04 % |\n",
      "| father |  137  | 29.98 % |\n",
      "| shared |  137  | 29.98 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.880\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "gargote_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.34 % |\n",
      "| father |  65   | 17.81 % |\n",
      "| shared |  25   | 6.85 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.848\n",
      "\n",
      "gargote_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.34 % |\n",
      "| father |  65   | 17.81 % |\n",
      "| shared |  25   | 6.85 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.801\n",
      "\n",
      "gargote_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.14 % |\n",
      "| father |  65   | 17.76 % |\n",
      "| shared |  26   | 7.10 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.888\n",
      "\n",
      "gargote_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  275  | 75.14 % |\n",
      "| father |  65   | 17.76 % |\n",
      "| shared |  26   | 7.10 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.803\n",
      "\n",
      "gargote_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  276  | 75.41 % |\n",
      "| father |  64   | 17.49 % |\n",
      "| shared |  26   | 7.10 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 39.89 % |\n",
      "| father |  110  | 30.05 % |\n",
      "| shared |  110  | 30.05 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.797\n",
      "  CV Macro-F1 = 0.828  0.036\n",
      "\n",
      "gargote_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  344  | 75.27 % |\n",
      "| father |  81   | 17.72 % |\n",
      "| shared |  32   | 7.00 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "gargote_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  183  | 40.04 % |\n",
      "| father |  137  | 29.98 % |\n",
      "| shared |  137  | 29.98 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.871\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET faubers  (549 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "faubers_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.53 % |\n",
      "| father |  97   | 27.64 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.752\n",
      "\n",
      "faubers_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.53 % |\n",
      "| father |  97   | 27.64 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.811\n",
      "\n",
      "faubers_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.53 % |\n",
      "| father |  97   | 27.64 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.777\n",
      "\n",
      "faubers_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  224  | 63.82 % |\n",
      "| father |  96   | 27.35 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.797\n",
      "\n",
      "faubers_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.35 % |\n",
      "| father |  97   | 27.56 % |\n",
      "| shared |  32   | 9.09 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  141  | 39.94 % |\n",
      "| father |  106  | 30.03 % |\n",
      "| shared |  106  | 30.03 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.771\n",
      "  CV Macro-F1 = 0.782  0.020\n",
      "\n",
      "faubers_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  279  | 63.55 % |\n",
      "| father |  121  | 27.56 % |\n",
      "| shared |  39   | 8.88 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  176  | 40.00 % |\n",
      "| father |  132  | 30.00 % |\n",
      "| shared |  132  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.831\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "faubers_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.53 % |\n",
      "| father |  97   | 27.64 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.773\n",
      "\n",
      "faubers_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.53 % |\n",
      "| father |  97   | 27.64 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.811\n",
      "\n",
      "faubers_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.53 % |\n",
      "| father |  97   | 27.64 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.737\n",
      "\n",
      "faubers_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  224  | 63.82 % |\n",
      "| father |  96   | 27.35 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.740\n",
      "\n",
      "faubers_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.35 % |\n",
      "| father |  97   | 27.56 % |\n",
      "| shared |  32   | 9.09 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  141  | 39.94 % |\n",
      "| father |  106  | 30.03 % |\n",
      "| shared |  106  | 30.03 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.723\n",
      "  CV Macro-F1 = 0.757  0.032\n",
      "\n",
      "faubers_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  279  | 63.55 % |\n",
      "| father |  121  | 27.56 % |\n",
      "| shared |  39   | 8.88 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  176  | 40.00 % |\n",
      "| father |  132  | 30.00 % |\n",
      "| shared |  132  | 30.00 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.807\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "faubers_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.53 % |\n",
      "| father |  97   | 27.64 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.792\n",
      "\n",
      "faubers_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.53 % |\n",
      "| father |  97   | 27.64 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.799\n",
      "\n",
      "faubers_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.53 % |\n",
      "| father |  97   | 27.64 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.739\n",
      "\n",
      "faubers_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  224  | 63.82 % |\n",
      "| father |  96   | 27.35 % |\n",
      "| shared |  31   | 8.83 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  140  | 40.00 % |\n",
      "| father |  105  | 30.00 % |\n",
      "| shared |  105  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.789\n",
      "\n",
      "faubers_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  223  | 63.35 % |\n",
      "| father |  97   | 27.56 % |\n",
      "| shared |  32   | 9.09 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  141  | 39.94 % |\n",
      "| father |  106  | 30.03 % |\n",
      "| shared |  106  | 30.03 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.807\n",
      "  CV Macro-F1 = 0.785  0.024\n",
      "\n",
      "faubers_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  279  | 63.55 % |\n",
      "| father |  121  | 27.56 % |\n",
      "| shared |  39   | 8.88 %  |\n",
      "+--------+-------+---------+\n",
      "\n",
      "faubers_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  176  | 40.00 % |\n",
      "| father |  132  | 30.00 % |\n",
      "| shared |  132  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.733\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET hauynes  (497 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "hauynes_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 64.04 % |\n",
      "| father |  80   | 25.24 % |\n",
      "| shared |  34   | 10.73 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.823\n",
      "\n",
      "hauynes_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 64.04 % |\n",
      "| father |  81   | 25.55 % |\n",
      "| shared |  33   | 10.41 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.764\n",
      "\n",
      "hauynes_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  204  | 64.15 % |\n",
      "| father |  81   | 25.47 % |\n",
      "| shared |  33   | 10.38 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.790\n",
      "\n",
      "hauynes_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 63.84 % |\n",
      "| father |  81   | 25.47 % |\n",
      "| shared |  34   | 10.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.717\n",
      "\n",
      "hauynes_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 63.84 % |\n",
      "| father |  81   | 25.47 % |\n",
      "| shared |  34   | 10.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.755\n",
      "  CV Macro-F1 = 0.770  0.035\n",
      "\n",
      "hauynes_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  254  | 63.98 % |\n",
      "| father |  101  | 25.44 % |\n",
      "| shared |  42   | 10.58 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  159  | 40.05 % |\n",
      "| father |  119  | 29.97 % |\n",
      "| shared |  119  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.864\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "hauynes_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 64.04 % |\n",
      "| father |  80   | 25.24 % |\n",
      "| shared |  34   | 10.73 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.839\n",
      "\n",
      "hauynes_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 64.04 % |\n",
      "| father |  81   | 25.55 % |\n",
      "| shared |  33   | 10.41 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.759\n",
      "\n",
      "hauynes_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  204  | 64.15 % |\n",
      "| father |  81   | 25.47 % |\n",
      "| shared |  33   | 10.38 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.790\n",
      "\n",
      "hauynes_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 63.84 % |\n",
      "| father |  81   | 25.47 % |\n",
      "| shared |  34   | 10.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.734\n",
      "\n",
      "hauynes_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 63.84 % |\n",
      "| father |  81   | 25.47 % |\n",
      "| shared |  34   | 10.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.741\n",
      "  CV Macro-F1 = 0.773  0.039\n",
      "\n",
      "hauynes_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  254  | 63.98 % |\n",
      "| father |  101  | 25.44 % |\n",
      "| shared |  42   | 10.58 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  159  | 40.05 % |\n",
      "| father |  119  | 29.97 % |\n",
      "| shared |  119  | 29.97 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.790\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "hauynes_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 64.04 % |\n",
      "| father |  80   | 25.24 % |\n",
      "| shared |  34   | 10.73 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.833\n",
      "\n",
      "hauynes_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 64.04 % |\n",
      "| father |  81   | 25.55 % |\n",
      "| shared |  33   | 10.41 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.774\n",
      "\n",
      "hauynes_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  204  | 64.15 % |\n",
      "| father |  81   | 25.47 % |\n",
      "| shared |  33   | 10.38 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.728\n",
      "\n",
      "hauynes_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 63.84 % |\n",
      "| father |  81   | 25.47 % |\n",
      "| shared |  34   | 10.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.758\n",
      "\n",
      "hauynes_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  203  | 63.84 % |\n",
      "| father |  81   | 25.47 % |\n",
      "| shared |  34   | 10.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  127  | 40.06 % |\n",
      "| father |  95   | 29.97 % |\n",
      "| shared |  95   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.716\n",
      "  CV Macro-F1 = 0.762  0.041\n",
      "\n",
      "hauynes_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  254  | 63.98 % |\n",
      "| father |  101  | 25.44 % |\n",
      "| shared |  42   | 10.58 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "hauynes_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  159  | 40.05 % |\n",
      "| father |  119  | 29.97 % |\n",
      "| shared |  119  | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.746\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET jobelin  (408 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "jobelin_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  165  | 63.46 % |\n",
      "| father |  62   | 23.85 % |\n",
      "| shared |  33   | 12.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.809\n",
      "\n",
      "jobelin_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  165  | 63.22 % |\n",
      "| father |  63   | 24.14 % |\n",
      "| shared |  33   | 12.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.835\n",
      "\n",
      "jobelin_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  166  | 63.60 % |\n",
      "| father |  63   | 24.14 % |\n",
      "| shared |  32   | 12.26 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.835\n",
      "\n",
      "jobelin_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  166  | 63.60 % |\n",
      "| father |  62   | 23.75 % |\n",
      "| shared |  33   | 12.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.916\n",
      "\n",
      "jobelin_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  166  | 63.60 % |\n",
      "| father |  62   | 23.75 % |\n",
      "| shared |  33   | 12.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.687\n",
      "  CV Macro-F1 = 0.816  0.074\n",
      "\n",
      "jobelin_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  207  | 63.50 % |\n",
      "| father |  78   | 23.93 % |\n",
      "| shared |  41   | 12.58 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 39.88 % |\n",
      "| father |  98   | 30.06 % |\n",
      "| shared |  98   | 30.06 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.806\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "jobelin_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  165  | 63.46 % |\n",
      "| father |  62   | 23.85 % |\n",
      "| shared |  33   | 12.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.796\n",
      "\n",
      "jobelin_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  165  | 63.22 % |\n",
      "| father |  63   | 24.14 % |\n",
      "| shared |  33   | 12.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.945\n",
      "\n",
      "jobelin_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  166  | 63.60 % |\n",
      "| father |  63   | 24.14 % |\n",
      "| shared |  32   | 12.26 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.817\n",
      "\n",
      "jobelin_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  166  | 63.60 % |\n",
      "| father |  62   | 23.75 % |\n",
      "| shared |  33   | 12.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.858\n",
      "\n",
      "jobelin_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  166  | 63.60 % |\n",
      "| father |  62   | 23.75 % |\n",
      "| shared |  33   | 12.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.721\n",
      "  CV Macro-F1 = 0.827  0.074\n",
      "\n",
      "jobelin_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  207  | 63.50 % |\n",
      "| father |  78   | 23.93 % |\n",
      "| shared |  41   | 12.58 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 39.88 % |\n",
      "| father |  98   | 30.06 % |\n",
      "| shared |  98   | 30.06 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.842\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "jobelin_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  165  | 63.46 % |\n",
      "| father |  62   | 23.85 % |\n",
      "| shared |  33   | 12.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.754\n",
      "\n",
      "jobelin_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  165  | 63.22 % |\n",
      "| father |  63   | 24.14 % |\n",
      "| shared |  33   | 12.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.795\n",
      "\n",
      "jobelin_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  166  | 63.60 % |\n",
      "| father |  63   | 24.14 % |\n",
      "| shared |  32   | 12.26 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.779\n",
      "\n",
      "jobelin_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  166  | 63.60 % |\n",
      "| father |  62   | 23.75 % |\n",
      "| shared |  33   | 12.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.755\n",
      "\n",
      "jobelin_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  166  | 63.60 % |\n",
      "| father |  62   | 23.75 % |\n",
      "| shared |  33   | 12.64 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.619\n",
      "  CV Macro-F1 = 0.741  0.063\n",
      "\n",
      "jobelin_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  207  | 63.50 % |\n",
      "| father |  78   | 23.93 % |\n",
      "| shared |  41   | 12.58 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "jobelin_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 39.88 % |\n",
      "| father |  98   | 30.06 % |\n",
      "| shared |  98   | 30.06 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.783\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET inconel  (408 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "inconel_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 63.08 % |\n",
      "| father |  65   | 25.00 % |\n",
      "| shared |  31   | 11.92 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.827\n",
      "\n",
      "inconel_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  66   | 25.29 % |\n",
      "| shared |  31   | 11.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.774\n",
      "\n",
      "inconel_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  66   | 25.29 % |\n",
      "| shared |  31   | 11.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.800\n",
      "\n",
      "inconel_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  66   | 25.29 % |\n",
      "| shared |  31   | 11.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.842\n",
      "\n",
      "inconel_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  65   | 24.90 % |\n",
      "| shared |  32   | 12.26 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.960\n",
      "  CV Macro-F1 = 0.841  0.064\n",
      "\n",
      "inconel_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  205  | 62.88 % |\n",
      "| father |  82   | 25.15 % |\n",
      "| shared |  39   | 11.96 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 39.88 % |\n",
      "| father |  98   | 30.06 % |\n",
      "| shared |  98   | 30.06 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.852\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "inconel_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 63.08 % |\n",
      "| father |  65   | 25.00 % |\n",
      "| shared |  31   | 11.92 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.834\n",
      "\n",
      "inconel_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  66   | 25.29 % |\n",
      "| shared |  31   | 11.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.849\n",
      "\n",
      "inconel_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  66   | 25.29 % |\n",
      "| shared |  31   | 11.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.852\n",
      "\n",
      "inconel_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  66   | 25.29 % |\n",
      "| shared |  31   | 11.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.784\n",
      "\n",
      "inconel_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  65   | 24.90 % |\n",
      "| shared |  32   | 12.26 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.923\n",
      "  CV Macro-F1 = 0.848  0.044\n",
      "\n",
      "inconel_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  205  | 62.88 % |\n",
      "| father |  82   | 25.15 % |\n",
      "| shared |  39   | 11.96 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 39.88 % |\n",
      "| father |  98   | 30.06 % |\n",
      "| shared |  98   | 30.06 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.795\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "inconel_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 63.08 % |\n",
      "| father |  65   | 25.00 % |\n",
      "| shared |  31   | 11.92 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.790\n",
      "\n",
      "inconel_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  66   | 25.29 % |\n",
      "| shared |  31   | 11.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.745\n",
      "\n",
      "inconel_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  66   | 25.29 % |\n",
      "| shared |  31   | 11.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.805\n",
      "\n",
      "inconel_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  66   | 25.29 % |\n",
      "| shared |  31   | 11.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.885\n",
      "\n",
      "inconel_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  164  | 62.84 % |\n",
      "| father |  65   | 24.90 % |\n",
      "| shared |  32   | 12.26 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  104  | 40.00 % |\n",
      "| father |  78   | 30.00 % |\n",
      "| shared |  78   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.933\n",
      "  CV Macro-F1 = 0.832  0.068\n",
      "\n",
      "inconel_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  205  | 62.88 % |\n",
      "| father |  82   | 25.15 % |\n",
      "| shared |  39   | 11.96 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "inconel_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 39.88 % |\n",
      "| father |  98   | 30.06 % |\n",
      "| shared |  98   | 30.06 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.821\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET kochias  (360 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "kochias_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  133  | 57.83 % |\n",
      "| father |  59   | 25.65 % |\n",
      "| shared |  38   | 16.52 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.817\n",
      "\n",
      "kochias_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  133  | 57.83 % |\n",
      "| father |  59   | 25.65 % |\n",
      "| shared |  38   | 16.52 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.931\n",
      "\n",
      "kochias_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  134  | 58.26 % |\n",
      "| father |  58   | 25.22 % |\n",
      "| shared |  38   | 16.52 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.823\n",
      "\n",
      "kochias_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  134  | 58.01 % |\n",
      "| father |  58   | 25.11 % |\n",
      "| shared |  39   | 16.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.896\n",
      "\n",
      "kochias_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  134  | 58.01 % |\n",
      "| father |  58   | 25.11 % |\n",
      "| shared |  39   | 16.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.894\n",
      "  CV Macro-F1 = 0.872  0.045\n",
      "\n",
      "kochias_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  167  | 57.99 % |\n",
      "| father |  73   | 25.35 % |\n",
      "| shared |  48   | 16.67 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  115  | 40.07 % |\n",
      "| father |  86   | 29.97 % |\n",
      "| shared |  86   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.847\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "kochias_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  133  | 57.83 % |\n",
      "| father |  59   | 25.65 % |\n",
      "| shared |  38   | 16.52 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.798\n",
      "\n",
      "kochias_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  133  | 57.83 % |\n",
      "| father |  59   | 25.65 % |\n",
      "| shared |  38   | 16.52 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.928\n",
      "\n",
      "kochias_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  134  | 58.26 % |\n",
      "| father |  58   | 25.22 % |\n",
      "| shared |  38   | 16.52 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.835\n",
      "\n",
      "kochias_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  134  | 58.01 % |\n",
      "| father |  58   | 25.11 % |\n",
      "| shared |  39   | 16.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.904\n",
      "\n",
      "kochias_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  134  | 58.01 % |\n",
      "| father |  58   | 25.11 % |\n",
      "| shared |  39   | 16.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.836\n",
      "  CV Macro-F1 = 0.860  0.048\n",
      "\n",
      "kochias_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  167  | 57.99 % |\n",
      "| father |  73   | 25.35 % |\n",
      "| shared |  48   | 16.67 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  115  | 40.07 % |\n",
      "| father |  86   | 29.97 % |\n",
      "| shared |  86   | 29.97 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.821\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "kochias_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  133  | 57.83 % |\n",
      "| father |  59   | 25.65 % |\n",
      "| shared |  38   | 16.52 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.803\n",
      "\n",
      "kochias_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  133  | 57.83 % |\n",
      "| father |  59   | 25.65 % |\n",
      "| shared |  38   | 16.52 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.920\n",
      "\n",
      "kochias_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  134  | 58.26 % |\n",
      "| father |  58   | 25.22 % |\n",
      "| shared |  38   | 16.52 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.808\n",
      "\n",
      "kochias_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  134  | 58.01 % |\n",
      "| father |  58   | 25.11 % |\n",
      "| shared |  39   | 16.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.881\n",
      "\n",
      "kochias_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  134  | 58.01 % |\n",
      "| father |  58   | 25.11 % |\n",
      "| shared |  39   | 16.88 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  92   | 40.00 % |\n",
      "| father |  69   | 30.00 % |\n",
      "| shared |  69   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.890\n",
      "  CV Macro-F1 = 0.860  0.047\n",
      "\n",
      "kochias_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  167  | 57.99 % |\n",
      "| father |  73   | 25.35 % |\n",
      "| shared |  48   | 16.67 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "kochias_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  115  | 40.07 % |\n",
      "| father |  86   | 29.97 % |\n",
      "| shared |  86   | 29.97 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.858\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET orillon  (311 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "orillon_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  129  | 65.15 % |\n",
      "| father |  46   | 23.23 % |\n",
      "| shared |  23   | 11.62 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.846\n",
      "\n",
      "orillon_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  129  | 65.15 % |\n",
      "| father |  46   | 23.23 % |\n",
      "| shared |  23   | 11.62 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.944\n",
      "\n",
      "orillon_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 65.66 % |\n",
      "| father |  45   | 22.73 % |\n",
      "| shared |  23   | 11.62 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.924\n",
      "\n",
      "orillon_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 65.33 % |\n",
      "| father |  45   | 22.61 % |\n",
      "| shared |  24   | 12.06 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  80   | 40.00 % |\n",
      "| father |  60   | 30.00 % |\n",
      "| shared |  60   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.921\n",
      "\n",
      "orillon_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 65.33 % |\n",
      "| father |  46   | 23.12 % |\n",
      "| shared |  23   | 11.56 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  80   | 40.00 % |\n",
      "| father |  60   | 30.00 % |\n",
      "| shared |  60   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.831\n",
      "  CV Macro-F1 = 0.894  0.046\n",
      "\n",
      "orillon_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 65.32 % |\n",
      "| father |  57   | 22.98 % |\n",
      "| shared |  29   | 11.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  99   | 40.08 % |\n",
      "| father |  74   | 29.96 % |\n",
      "| shared |  74   | 29.96 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.900\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "orillon_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  129  | 65.15 % |\n",
      "| father |  46   | 23.23 % |\n",
      "| shared |  23   | 11.62 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.866\n",
      "\n",
      "orillon_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  129  | 65.15 % |\n",
      "| father |  46   | 23.23 % |\n",
      "| shared |  23   | 11.62 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.841\n",
      "\n",
      "orillon_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 65.66 % |\n",
      "| father |  45   | 22.73 % |\n",
      "| shared |  23   | 11.62 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.906\n",
      "\n",
      "orillon_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 65.33 % |\n",
      "| father |  45   | 22.61 % |\n",
      "| shared |  24   | 12.06 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  80   | 40.00 % |\n",
      "| father |  60   | 30.00 % |\n",
      "| shared |  60   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.915\n",
      "\n",
      "orillon_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 65.33 % |\n",
      "| father |  46   | 23.12 % |\n",
      "| shared |  23   | 11.56 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  80   | 40.00 % |\n",
      "| father |  60   | 30.00 % |\n",
      "| shared |  60   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.804\n",
      "  CV Macro-F1 = 0.866  0.041\n",
      "\n",
      "orillon_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 65.32 % |\n",
      "| father |  57   | 22.98 % |\n",
      "| shared |  29   | 11.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  99   | 40.08 % |\n",
      "| father |  74   | 29.96 % |\n",
      "| shared |  74   | 29.96 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.865\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "orillon_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  129  | 65.15 % |\n",
      "| father |  46   | 23.23 % |\n",
      "| shared |  23   | 11.62 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.795\n",
      "\n",
      "orillon_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  129  | 65.15 % |\n",
      "| father |  46   | 23.23 % |\n",
      "| shared |  23   | 11.62 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.927\n",
      "\n",
      "orillon_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 65.66 % |\n",
      "| father |  45   | 22.73 % |\n",
      "| shared |  23   | 11.62 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.927\n",
      "\n",
      "orillon_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 65.33 % |\n",
      "| father |  45   | 22.61 % |\n",
      "| shared |  24   | 12.06 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  80   | 40.00 % |\n",
      "| father |  60   | 30.00 % |\n",
      "| shared |  60   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.981\n",
      "\n",
      "orillon_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  130  | 65.33 % |\n",
      "| father |  46   | 23.12 % |\n",
      "| shared |  23   | 11.56 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  80   | 40.00 % |\n",
      "| father |  60   | 30.00 % |\n",
      "| shared |  60   | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.784\n",
      "  CV Macro-F1 = 0.883  0.079\n",
      "\n",
      "orillon_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  162  | 65.32 % |\n",
      "| father |  57   | 22.98 % |\n",
      "| shared |  29   | 11.69 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "orillon_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  99   | 40.08 % |\n",
      "| father |  74   | 29.96 % |\n",
      "| shared |  74   | 29.96 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.873\n",
      "\n",
      "================================================================================\n",
      "                         BUCKET labourg  (308 samples)                          \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "labourg_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 74.49 % |\n",
      "| father |  26   | 13.27 % |\n",
      "| shared |  24   | 12.24 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  78   | 39.80 % |\n",
      "| father |  59   | 30.10 % |\n",
      "| shared |  59   | 30.10 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.868\n",
      "\n",
      "labourg_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 74.11 % |\n",
      "| father |  27   | 13.71 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.829\n",
      "\n",
      "labourg_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 74.11 % |\n",
      "| father |  27   | 13.71 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.877\n",
      "\n",
      "labourg_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  147  | 74.62 % |\n",
      "| father |  26   | 13.20 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.839\n",
      "\n",
      "labourg_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  147  | 74.62 % |\n",
      "| father |  26   | 13.20 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.923\n",
      "  CV Macro-F1 = 0.867  0.033\n",
      "\n",
      "labourg_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  183  | 74.39 % |\n",
      "| father |  33   | 13.41 % |\n",
      "| shared |  30   | 12.20 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  98   | 39.84 % |\n",
      "| father |  74   | 30.08 % |\n",
      "| shared |  74   | 30.08 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.819\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "labourg_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 74.49 % |\n",
      "| father |  26   | 13.27 % |\n",
      "| shared |  24   | 12.24 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  78   | 39.80 % |\n",
      "| father |  59   | 30.10 % |\n",
      "| shared |  59   | 30.10 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.816\n",
      "\n",
      "labourg_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 74.11 % |\n",
      "| father |  27   | 13.71 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.849\n",
      "\n",
      "labourg_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 74.11 % |\n",
      "| father |  27   | 13.71 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.877\n",
      "\n",
      "labourg_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  147  | 74.62 % |\n",
      "| father |  26   | 13.20 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.777\n",
      "\n",
      "labourg_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  147  | 74.62 % |\n",
      "| father |  26   | 13.20 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.853\n",
      "  CV Macro-F1 = 0.834  0.035\n",
      "\n",
      "labourg_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  183  | 74.39 % |\n",
      "| father |  33   | 13.41 % |\n",
      "| shared |  30   | 12.20 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  98   | 39.84 % |\n",
      "| father |  74   | 30.08 % |\n",
      "| shared |  74   | 30.08 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.881\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "labourg_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 74.49 % |\n",
      "| father |  26   | 13.27 % |\n",
      "| shared |  24   | 12.24 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  78   | 39.80 % |\n",
      "| father |  59   | 30.10 % |\n",
      "| shared |  59   | 30.10 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.849\n",
      "\n",
      "labourg_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 74.11 % |\n",
      "| father |  27   | 13.71 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.815\n",
      "\n",
      "labourg_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  146  | 74.11 % |\n",
      "| father |  27   | 13.71 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.877\n",
      "\n",
      "labourg_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  147  | 74.62 % |\n",
      "| father |  26   | 13.20 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.757\n",
      "\n",
      "labourg_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  147  | 74.62 % |\n",
      "| father |  26   | 13.20 % |\n",
      "| shared |  24   | 12.18 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  79   | 40.10 % |\n",
      "| father |  59   | 29.95 % |\n",
      "| shared |  59   | 29.95 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.894\n",
      "  CV Macro-F1 = 0.838  0.049\n",
      "\n",
      "labourg_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  183  | 74.39 % |\n",
      "| father |  33   | 13.41 % |\n",
      "| shared |  30   | 12.20 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "labourg_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother |  98   | 39.84 % |\n",
      "| father |  74   | 30.08 % |\n",
      "| shared |  74   | 30.08 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.842\n",
      "\n",
      "================================================================================\n",
      "                        BUCKET generic  (11878 samples)                         \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Model: RandomForest\n",
      "\n",
      "generic_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5198  | 68.39 % |\n",
      "| father | 1643  | 21.62 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3040  | 40.00 % |\n",
      "| father | 2280  | 30.00 % |\n",
      "| shared | 2280  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.827\n",
      "\n",
      "generic_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5198  | 68.39 % |\n",
      "| father | 1643  | 21.62 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3040  | 40.00 % |\n",
      "| father | 2280  | 30.00 % |\n",
      "| shared | 2280  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.822\n",
      "\n",
      "generic_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5198  | 68.38 % |\n",
      "| father | 1644  | 21.63 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3041  | 40.00 % |\n",
      "| father | 2281  | 30.00 % |\n",
      "| shared | 2281  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.830\n",
      "\n",
      "generic_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5199  | 68.39 % |\n",
      "| father | 1643  | 21.61 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3041  | 40.00 % |\n",
      "| father | 2281  | 30.00 % |\n",
      "| shared | 2281  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.840\n",
      "\n",
      "generic_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5199  | 68.39 % |\n",
      "| father | 1643  | 21.61 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3041  | 40.00 % |\n",
      "| father | 2281  | 30.00 % |\n",
      "| shared | 2281  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.795\n",
      "  CV Macro-F1 = 0.823  0.015\n",
      "\n",
      "generic_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 6498  | 68.39 % |\n",
      "| father | 2054  | 21.62 % |\n",
      "| shared |  950  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3801  | 40.00 % |\n",
      "| father | 2851  | 30.00 % |\n",
      "| shared | 2851  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.823\n",
      "\n",
      "Model: SVC\n",
      "\n",
      "generic_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5198  | 68.39 % |\n",
      "| father | 1643  | 21.62 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3040  | 40.00 % |\n",
      "| father | 2280  | 30.00 % |\n",
      "| shared | 2280  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.819\n",
      "\n",
      "generic_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5198  | 68.39 % |\n",
      "| father | 1643  | 21.62 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3040  | 40.00 % |\n",
      "| father | 2280  | 30.00 % |\n",
      "| shared | 2280  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.820\n",
      "\n",
      "generic_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5198  | 68.38 % |\n",
      "| father | 1644  | 21.63 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3041  | 40.00 % |\n",
      "| father | 2281  | 30.00 % |\n",
      "| shared | 2281  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.817\n",
      "\n",
      "generic_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5199  | 68.39 % |\n",
      "| father | 1643  | 21.61 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3041  | 40.00 % |\n",
      "| father | 2281  | 30.00 % |\n",
      "| shared | 2281  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.823\n",
      "\n",
      "generic_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5199  | 68.39 % |\n",
      "| father | 1643  | 21.61 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3041  | 40.00 % |\n",
      "| father | 2281  | 30.00 % |\n",
      "| shared | 2281  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.804\n",
      "  CV Macro-F1 = 0.817  0.007\n",
      "\n",
      "generic_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 6498  | 68.39 % |\n",
      "| father | 2054  | 21.62 % |\n",
      "| shared |  950  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3801  | 40.00 % |\n",
      "| father | 2851  | 30.00 % |\n",
      "| shared | 2851  | 30.00 % |\n",
      "+--------+-------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Model has no native feature importance; returning zeros.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST Macro-F1 = 0.814\n",
      "\n",
      "Model: XGB\n",
      "\n",
      "generic_f1  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5198  | 68.39 % |\n",
      "| father | 1643  | 21.62 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f1  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3040  | 40.00 % |\n",
      "| father | 2280  | 30.00 % |\n",
      "| shared | 2280  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 1/5  Macro-F1 = 0.821\n",
      "\n",
      "generic_f2  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5198  | 68.39 % |\n",
      "| father | 1643  | 21.62 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f2  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3040  | 40.00 % |\n",
      "| father | 2280  | 30.00 % |\n",
      "| shared | 2280  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 2/5  Macro-F1 = 0.823\n",
      "\n",
      "generic_f3  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5198  | 68.38 % |\n",
      "| father | 1644  | 21.63 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f3  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3041  | 40.00 % |\n",
      "| father | 2281  | 30.00 % |\n",
      "| shared | 2281  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 3/5  Macro-F1 = 0.828\n",
      "\n",
      "generic_f4  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5199  | 68.39 % |\n",
      "| father | 1643  | 21.61 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f4  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3041  | 40.00 % |\n",
      "| father | 2281  | 30.00 % |\n",
      "| shared | 2281  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 4/5  Macro-F1 = 0.833\n",
      "\n",
      "generic_f5  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 5199  | 68.39 % |\n",
      "| father | 1643  | 21.61 % |\n",
      "| shared |  760  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_f5  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3041  | 40.00 % |\n",
      "| father | 2281  | 30.00 % |\n",
      "| shared | 2281  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  Fold 5/5  Macro-F1 = 0.816\n",
      "  CV Macro-F1 = 0.824  0.006\n",
      "\n",
      "generic_final  BEFORE\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 6498  | 68.39 % |\n",
      "| father | 2054  | 21.62 % |\n",
      "| shared |  950  | 10.00 % |\n",
      "+--------+-------+---------+\n",
      "\n",
      "generic_final  AFTER (sampled)\n",
      "+--------+-------+---------+\n",
      "| Class  | Count |    %    |\n",
      "+--------+-------+---------+\n",
      "| mother | 3801  | 40.00 % |\n",
      "| father | 2851  | 30.00 % |\n",
      "| shared | 2851  | 30.00 % |\n",
      "+--------+-------+---------+\n",
      "  TEST Macro-F1 = 0.826\n",
      "\n",
      "================================================================================\n",
      "                            CROSS-BUCKET EVALUATION                             \n",
      "================================================================================\n",
      "\n",
      "   anatole/RandomForest  anatole\n",
      "   anatole/RandomForest  babiche\n",
      "   anatole/RandomForest  cabeche\n",
      "   anatole/RandomForest  dacrons\n",
      "   anatole/RandomForest  echevin\n",
      "   anatole/RandomForest  gargote\n",
      "   anatole/RandomForest  faubers\n",
      "   anatole/RandomForest  hauynes\n",
      "   anatole/RandomForest  jobelin\n",
      "   anatole/RandomForest  inconel\n",
      "   anatole/RandomForest  kochias\n",
      "   anatole/RandomForest  orillon\n",
      "   anatole/RandomForest  labourg\n",
      "   anatole/RandomForest  generic\n",
      "   anatole/SVC  anatole\n",
      "   anatole/SVC  babiche\n",
      "   anatole/SVC  cabeche\n",
      "   anatole/SVC  dacrons\n",
      "   anatole/SVC  echevin\n",
      "   anatole/SVC  gargote\n",
      "   anatole/SVC  faubers\n",
      "   anatole/SVC  hauynes\n",
      "   anatole/SVC  jobelin\n",
      "   anatole/SVC  inconel\n",
      "   anatole/SVC  kochias\n",
      "   anatole/SVC  orillon\n",
      "   anatole/SVC  labourg\n",
      "   anatole/SVC  generic\n",
      "   anatole/XGB  anatole\n",
      "   anatole/XGB  babiche\n",
      "   anatole/XGB  cabeche\n",
      "   anatole/XGB  dacrons\n",
      "   anatole/XGB  echevin\n",
      "   anatole/XGB  gargote\n",
      "   anatole/XGB  faubers\n",
      "   anatole/XGB  hauynes\n",
      "   anatole/XGB  jobelin\n",
      "   anatole/XGB  inconel\n",
      "   anatole/XGB  kochias\n",
      "   anatole/XGB  orillon\n",
      "   anatole/XGB  labourg\n",
      "   anatole/XGB  generic\n",
      "   babiche/RandomForest  anatole\n",
      "   babiche/RandomForest  babiche\n",
      "   babiche/RandomForest  cabeche\n",
      "   babiche/RandomForest  dacrons\n",
      "   babiche/RandomForest  echevin\n",
      "   babiche/RandomForest  gargote\n",
      "   babiche/RandomForest  faubers\n",
      "   babiche/RandomForest  hauynes\n",
      "   babiche/RandomForest  jobelin\n",
      "   babiche/RandomForest  inconel\n",
      "   babiche/RandomForest  kochias\n",
      "   babiche/RandomForest  orillon\n",
      "   babiche/RandomForest  labourg\n",
      "   babiche/RandomForest  generic\n",
      "   babiche/SVC  anatole\n",
      "   babiche/SVC  babiche\n",
      "   babiche/SVC  cabeche\n",
      "   babiche/SVC  dacrons\n",
      "   babiche/SVC  echevin\n",
      "   babiche/SVC  gargote\n",
      "   babiche/SVC  faubers\n",
      "   babiche/SVC  hauynes\n",
      "   babiche/SVC  jobelin\n",
      "   babiche/SVC  inconel\n",
      "   babiche/SVC  kochias\n",
      "   babiche/SVC  orillon\n",
      "   babiche/SVC  labourg\n",
      "   babiche/SVC  generic\n",
      "   babiche/XGB  anatole\n",
      "   babiche/XGB  babiche\n",
      "   babiche/XGB  cabeche\n",
      "   babiche/XGB  dacrons\n",
      "   babiche/XGB  echevin\n",
      "   babiche/XGB  gargote\n",
      "   babiche/XGB  faubers\n",
      "   babiche/XGB  hauynes\n",
      "   babiche/XGB  jobelin\n",
      "   babiche/XGB  inconel\n",
      "   babiche/XGB  kochias\n",
      "   babiche/XGB  orillon\n",
      "   babiche/XGB  labourg\n",
      "   babiche/XGB  generic\n",
      "   cabeche/RandomForest  anatole\n",
      "   cabeche/RandomForest  babiche\n",
      "   cabeche/RandomForest  cabeche\n",
      "   cabeche/RandomForest  dacrons\n",
      "   cabeche/RandomForest  echevin\n",
      "   cabeche/RandomForest  gargote\n",
      "   cabeche/RandomForest  faubers\n",
      "   cabeche/RandomForest  hauynes\n",
      "   cabeche/RandomForest  jobelin\n",
      "   cabeche/RandomForest  inconel\n",
      "   cabeche/RandomForest  kochias\n",
      "   cabeche/RandomForest  orillon\n",
      "   cabeche/RandomForest  labourg\n",
      "   cabeche/RandomForest  generic\n",
      "   cabeche/SVC  anatole\n",
      "   cabeche/SVC  babiche\n",
      "   cabeche/SVC  cabeche\n",
      "   cabeche/SVC  dacrons\n",
      "   cabeche/SVC  echevin\n",
      "   cabeche/SVC  gargote\n",
      "   cabeche/SVC  faubers\n",
      "   cabeche/SVC  hauynes\n",
      "   cabeche/SVC  jobelin\n",
      "   cabeche/SVC  inconel\n",
      "   cabeche/SVC  kochias\n",
      "   cabeche/SVC  orillon\n",
      "   cabeche/SVC  labourg\n",
      "   cabeche/SVC  generic\n",
      "   cabeche/XGB  anatole\n",
      "   cabeche/XGB  babiche\n",
      "   cabeche/XGB  cabeche\n",
      "   cabeche/XGB  dacrons\n",
      "   cabeche/XGB  echevin\n",
      "   cabeche/XGB  gargote\n",
      "   cabeche/XGB  faubers\n",
      "   cabeche/XGB  hauynes\n",
      "   cabeche/XGB  jobelin\n",
      "   cabeche/XGB  inconel\n",
      "   cabeche/XGB  kochias\n",
      "   cabeche/XGB  orillon\n",
      "   cabeche/XGB  labourg\n",
      "   cabeche/XGB  generic\n",
      "   dacrons/RandomForest  anatole\n",
      "   dacrons/RandomForest  babiche\n",
      "   dacrons/RandomForest  cabeche\n",
      "   dacrons/RandomForest  dacrons\n",
      "   dacrons/RandomForest  echevin\n",
      "   dacrons/RandomForest  gargote\n",
      "   dacrons/RandomForest  faubers\n",
      "   dacrons/RandomForest  hauynes\n",
      "   dacrons/RandomForest  jobelin\n",
      "   dacrons/RandomForest  inconel\n",
      "   dacrons/RandomForest  kochias\n",
      "   dacrons/RandomForest  orillon\n",
      "   dacrons/RandomForest  labourg\n",
      "   dacrons/RandomForest  generic\n",
      "   dacrons/SVC  anatole\n",
      "   dacrons/SVC  babiche\n",
      "   dacrons/SVC  cabeche\n",
      "   dacrons/SVC  dacrons\n",
      "   dacrons/SVC  echevin\n",
      "   dacrons/SVC  gargote\n",
      "   dacrons/SVC  faubers\n",
      "   dacrons/SVC  hauynes\n",
      "   dacrons/SVC  jobelin\n",
      "   dacrons/SVC  inconel\n",
      "   dacrons/SVC  kochias\n",
      "   dacrons/SVC  orillon\n",
      "   dacrons/SVC  labourg\n",
      "   dacrons/SVC  generic\n",
      "   dacrons/XGB  anatole\n",
      "   dacrons/XGB  babiche\n",
      "   dacrons/XGB  cabeche\n",
      "   dacrons/XGB  dacrons\n",
      "   dacrons/XGB  echevin\n",
      "   dacrons/XGB  gargote\n",
      "   dacrons/XGB  faubers\n",
      "   dacrons/XGB  hauynes\n",
      "   dacrons/XGB  jobelin\n",
      "   dacrons/XGB  inconel\n",
      "   dacrons/XGB  kochias\n",
      "   dacrons/XGB  orillon\n",
      "   dacrons/XGB  labourg\n",
      "   dacrons/XGB  generic\n",
      "   echevin/RandomForest  anatole\n",
      "   echevin/RandomForest  babiche\n",
      "   echevin/RandomForest  cabeche\n",
      "   echevin/RandomForest  dacrons\n",
      "   echevin/RandomForest  echevin\n",
      "   echevin/RandomForest  gargote\n",
      "   echevin/RandomForest  faubers\n",
      "   echevin/RandomForest  hauynes\n",
      "   echevin/RandomForest  jobelin\n",
      "   echevin/RandomForest  inconel\n",
      "   echevin/RandomForest  kochias\n",
      "   echevin/RandomForest  orillon\n",
      "   echevin/RandomForest  labourg\n",
      "   echevin/RandomForest  generic\n",
      "   echevin/SVC  anatole\n",
      "   echevin/SVC  babiche\n",
      "   echevin/SVC  cabeche\n",
      "   echevin/SVC  dacrons\n",
      "   echevin/SVC  echevin\n",
      "   echevin/SVC  gargote\n",
      "   echevin/SVC  faubers\n",
      "   echevin/SVC  hauynes\n",
      "   echevin/SVC  jobelin\n",
      "   echevin/SVC  inconel\n",
      "   echevin/SVC  kochias\n",
      "   echevin/SVC  orillon\n",
      "   echevin/SVC  labourg\n",
      "   echevin/SVC  generic\n",
      "   echevin/XGB  anatole\n",
      "   echevin/XGB  babiche\n",
      "   echevin/XGB  cabeche\n",
      "   echevin/XGB  dacrons\n",
      "   echevin/XGB  echevin\n",
      "   echevin/XGB  gargote\n",
      "   echevin/XGB  faubers\n",
      "   echevin/XGB  hauynes\n",
      "   echevin/XGB  jobelin\n",
      "   echevin/XGB  inconel\n",
      "   echevin/XGB  kochias\n",
      "   echevin/XGB  orillon\n",
      "   echevin/XGB  labourg\n",
      "   echevin/XGB  generic\n",
      "   gargote/RandomForest  anatole\n",
      "   gargote/RandomForest  babiche\n",
      "   gargote/RandomForest  cabeche\n",
      "   gargote/RandomForest  dacrons\n",
      "   gargote/RandomForest  echevin\n",
      "   gargote/RandomForest  gargote\n",
      "   gargote/RandomForest  faubers\n",
      "   gargote/RandomForest  hauynes\n",
      "   gargote/RandomForest  jobelin\n",
      "   gargote/RandomForest  inconel\n",
      "   gargote/RandomForest  kochias\n",
      "   gargote/RandomForest  orillon\n",
      "   gargote/RandomForest  labourg\n",
      "   gargote/RandomForest  generic\n",
      "   gargote/SVC  anatole\n",
      "   gargote/SVC  babiche\n",
      "   gargote/SVC  cabeche\n",
      "   gargote/SVC  dacrons\n",
      "   gargote/SVC  echevin\n",
      "   gargote/SVC  gargote\n",
      "   gargote/SVC  faubers\n",
      "   gargote/SVC  hauynes\n",
      "   gargote/SVC  jobelin\n",
      "   gargote/SVC  inconel\n",
      "   gargote/SVC  kochias\n",
      "   gargote/SVC  orillon\n",
      "   gargote/SVC  labourg\n",
      "   gargote/SVC  generic\n",
      "   gargote/XGB  anatole\n",
      "   gargote/XGB  babiche\n",
      "   gargote/XGB  cabeche\n",
      "   gargote/XGB  dacrons\n",
      "   gargote/XGB  echevin\n",
      "   gargote/XGB  gargote\n",
      "   gargote/XGB  faubers\n",
      "   gargote/XGB  hauynes\n",
      "   gargote/XGB  jobelin\n",
      "   gargote/XGB  inconel\n",
      "   gargote/XGB  kochias\n",
      "   gargote/XGB  orillon\n",
      "   gargote/XGB  labourg\n",
      "   gargote/XGB  generic\n",
      "   faubers/RandomForest  anatole\n",
      "   faubers/RandomForest  babiche\n",
      "   faubers/RandomForest  cabeche\n",
      "   faubers/RandomForest  dacrons\n",
      "   faubers/RandomForest  echevin\n",
      "   faubers/RandomForest  gargote\n",
      "   faubers/RandomForest  faubers\n",
      "   faubers/RandomForest  hauynes\n",
      "   faubers/RandomForest  jobelin\n",
      "   faubers/RandomForest  inconel\n",
      "   faubers/RandomForest  kochias\n",
      "   faubers/RandomForest  orillon\n",
      "   faubers/RandomForest  labourg\n",
      "   faubers/RandomForest  generic\n",
      "   faubers/SVC  anatole\n",
      "   faubers/SVC  babiche\n",
      "   faubers/SVC  cabeche\n",
      "   faubers/SVC  dacrons\n",
      "   faubers/SVC  echevin\n",
      "   faubers/SVC  gargote\n",
      "   faubers/SVC  faubers\n",
      "   faubers/SVC  hauynes\n",
      "   faubers/SVC  jobelin\n",
      "   faubers/SVC  inconel\n",
      "   faubers/SVC  kochias\n",
      "   faubers/SVC  orillon\n",
      "   faubers/SVC  labourg\n",
      "   faubers/SVC  generic\n",
      "   faubers/XGB  anatole\n",
      "   faubers/XGB  babiche\n",
      "   faubers/XGB  cabeche\n",
      "   faubers/XGB  dacrons\n",
      "   faubers/XGB  echevin\n",
      "   faubers/XGB  gargote\n",
      "   faubers/XGB  faubers\n",
      "   faubers/XGB  hauynes\n",
      "   faubers/XGB  jobelin\n",
      "   faubers/XGB  inconel\n",
      "   faubers/XGB  kochias\n",
      "   faubers/XGB  orillon\n",
      "   faubers/XGB  labourg\n",
      "   faubers/XGB  generic\n",
      "   hauynes/RandomForest  anatole\n",
      "   hauynes/RandomForest  babiche\n",
      "   hauynes/RandomForest  cabeche\n",
      "   hauynes/RandomForest  dacrons\n",
      "   hauynes/RandomForest  echevin\n",
      "   hauynes/RandomForest  gargote\n",
      "   hauynes/RandomForest  faubers\n",
      "   hauynes/RandomForest  hauynes\n",
      "   hauynes/RandomForest  jobelin\n",
      "   hauynes/RandomForest  inconel\n",
      "   hauynes/RandomForest  kochias\n",
      "   hauynes/RandomForest  orillon\n",
      "   hauynes/RandomForest  labourg\n",
      "   hauynes/RandomForest  generic\n",
      "   hauynes/SVC  anatole\n",
      "   hauynes/SVC  babiche\n",
      "   hauynes/SVC  cabeche\n",
      "   hauynes/SVC  dacrons\n",
      "   hauynes/SVC  echevin\n",
      "   hauynes/SVC  gargote\n",
      "   hauynes/SVC  faubers\n",
      "   hauynes/SVC  hauynes\n",
      "   hauynes/SVC  jobelin\n",
      "   hauynes/SVC  inconel\n",
      "   hauynes/SVC  kochias\n",
      "   hauynes/SVC  orillon\n",
      "   hauynes/SVC  labourg\n",
      "   hauynes/SVC  generic\n",
      "   hauynes/XGB  anatole\n",
      "   hauynes/XGB  babiche\n",
      "   hauynes/XGB  cabeche\n",
      "   hauynes/XGB  dacrons\n",
      "   hauynes/XGB  echevin\n",
      "   hauynes/XGB  gargote\n",
      "   hauynes/XGB  faubers\n",
      "   hauynes/XGB  hauynes\n",
      "   hauynes/XGB  jobelin\n",
      "   hauynes/XGB  inconel\n",
      "   hauynes/XGB  kochias\n",
      "   hauynes/XGB  orillon\n",
      "   hauynes/XGB  labourg\n",
      "   hauynes/XGB  generic\n",
      "   jobelin/RandomForest  anatole\n",
      "   jobelin/RandomForest  babiche\n",
      "   jobelin/RandomForest  cabeche\n",
      "   jobelin/RandomForest  dacrons\n",
      "   jobelin/RandomForest  echevin\n",
      "   jobelin/RandomForest  gargote\n",
      "   jobelin/RandomForest  faubers\n",
      "   jobelin/RandomForest  hauynes\n",
      "   jobelin/RandomForest  jobelin\n",
      "   jobelin/RandomForest  inconel\n",
      "   jobelin/RandomForest  kochias\n",
      "   jobelin/RandomForest  orillon\n",
      "   jobelin/RandomForest  labourg\n",
      "   jobelin/RandomForest  generic\n",
      "   jobelin/SVC  anatole\n",
      "   jobelin/SVC  babiche\n",
      "   jobelin/SVC  cabeche\n",
      "   jobelin/SVC  dacrons\n",
      "   jobelin/SVC  echevin\n",
      "   jobelin/SVC  gargote\n",
      "   jobelin/SVC  faubers\n",
      "   jobelin/SVC  hauynes\n",
      "   jobelin/SVC  jobelin\n",
      "   jobelin/SVC  inconel\n",
      "   jobelin/SVC  kochias\n",
      "   jobelin/SVC  orillon\n",
      "   jobelin/SVC  labourg\n",
      "   jobelin/SVC  generic\n",
      "   jobelin/XGB  anatole\n",
      "   jobelin/XGB  babiche\n",
      "   jobelin/XGB  cabeche\n",
      "   jobelin/XGB  dacrons\n",
      "   jobelin/XGB  echevin\n",
      "   jobelin/XGB  gargote\n",
      "   jobelin/XGB  faubers\n",
      "   jobelin/XGB  hauynes\n",
      "   jobelin/XGB  jobelin\n",
      "   jobelin/XGB  inconel\n",
      "   jobelin/XGB  kochias\n",
      "   jobelin/XGB  orillon\n",
      "   jobelin/XGB  labourg\n",
      "   jobelin/XGB  generic\n",
      "   inconel/RandomForest  anatole\n",
      "   inconel/RandomForest  babiche\n",
      "   inconel/RandomForest  cabeche\n",
      "   inconel/RandomForest  dacrons\n",
      "   inconel/RandomForest  echevin\n",
      "   inconel/RandomForest  gargote\n",
      "   inconel/RandomForest  faubers\n",
      "   inconel/RandomForest  hauynes\n",
      "   inconel/RandomForest  jobelin\n",
      "   inconel/RandomForest  inconel\n",
      "   inconel/RandomForest  kochias\n",
      "   inconel/RandomForest  orillon\n",
      "   inconel/RandomForest  labourg\n",
      "   inconel/RandomForest  generic\n",
      "   inconel/SVC  anatole\n",
      "   inconel/SVC  babiche\n",
      "   inconel/SVC  cabeche\n",
      "   inconel/SVC  dacrons\n",
      "   inconel/SVC  echevin\n",
      "   inconel/SVC  gargote\n",
      "   inconel/SVC  faubers\n",
      "   inconel/SVC  hauynes\n",
      "   inconel/SVC  jobelin\n",
      "   inconel/SVC  inconel\n",
      "   inconel/SVC  kochias\n",
      "   inconel/SVC  orillon\n",
      "   inconel/SVC  labourg\n",
      "   inconel/SVC  generic\n",
      "   inconel/XGB  anatole\n",
      "   inconel/XGB  babiche\n",
      "   inconel/XGB  cabeche\n",
      "   inconel/XGB  dacrons\n",
      "   inconel/XGB  echevin\n",
      "   inconel/XGB  gargote\n",
      "   inconel/XGB  faubers\n",
      "   inconel/XGB  hauynes\n",
      "   inconel/XGB  jobelin\n",
      "   inconel/XGB  inconel\n",
      "   inconel/XGB  kochias\n",
      "   inconel/XGB  orillon\n",
      "   inconel/XGB  labourg\n",
      "   inconel/XGB  generic\n",
      "   kochias/RandomForest  anatole\n",
      "   kochias/RandomForest  babiche\n",
      "   kochias/RandomForest  cabeche\n",
      "   kochias/RandomForest  dacrons\n",
      "   kochias/RandomForest  echevin\n",
      "   kochias/RandomForest  gargote\n",
      "   kochias/RandomForest  faubers\n",
      "   kochias/RandomForest  hauynes\n",
      "   kochias/RandomForest  jobelin\n",
      "   kochias/RandomForest  inconel\n",
      "   kochias/RandomForest  kochias\n",
      "   kochias/RandomForest  orillon\n",
      "   kochias/RandomForest  labourg\n",
      "   kochias/RandomForest  generic\n",
      "   kochias/SVC  anatole\n",
      "   kochias/SVC  babiche\n",
      "   kochias/SVC  cabeche\n",
      "   kochias/SVC  dacrons\n",
      "   kochias/SVC  echevin\n",
      "   kochias/SVC  gargote\n",
      "   kochias/SVC  faubers\n",
      "   kochias/SVC  hauynes\n",
      "   kochias/SVC  jobelin\n",
      "   kochias/SVC  inconel\n",
      "   kochias/SVC  kochias\n",
      "   kochias/SVC  orillon\n",
      "   kochias/SVC  labourg\n",
      "   kochias/SVC  generic\n",
      "   kochias/XGB  anatole\n",
      "   kochias/XGB  babiche\n",
      "   kochias/XGB  cabeche\n",
      "   kochias/XGB  dacrons\n",
      "   kochias/XGB  echevin\n",
      "   kochias/XGB  gargote\n",
      "   kochias/XGB  faubers\n",
      "   kochias/XGB  hauynes\n",
      "   kochias/XGB  jobelin\n",
      "   kochias/XGB  inconel\n",
      "   kochias/XGB  kochias\n",
      "   kochias/XGB  orillon\n",
      "   kochias/XGB  labourg\n",
      "   kochias/XGB  generic\n",
      "   orillon/RandomForest  anatole\n",
      "   orillon/RandomForest  babiche\n",
      "   orillon/RandomForest  cabeche\n",
      "   orillon/RandomForest  dacrons\n",
      "   orillon/RandomForest  echevin\n",
      "   orillon/RandomForest  gargote\n",
      "   orillon/RandomForest  faubers\n",
      "   orillon/RandomForest  hauynes\n",
      "   orillon/RandomForest  jobelin\n",
      "   orillon/RandomForest  inconel\n",
      "   orillon/RandomForest  kochias\n",
      "   orillon/RandomForest  orillon\n",
      "   orillon/RandomForest  labourg\n",
      "   orillon/RandomForest  generic\n",
      "   orillon/SVC  anatole\n",
      "   orillon/SVC  babiche\n",
      "   orillon/SVC  cabeche\n",
      "   orillon/SVC  dacrons\n",
      "   orillon/SVC  echevin\n",
      "   orillon/SVC  gargote\n",
      "   orillon/SVC  faubers\n",
      "   orillon/SVC  hauynes\n",
      "   orillon/SVC  jobelin\n",
      "   orillon/SVC  inconel\n",
      "   orillon/SVC  kochias\n",
      "   orillon/SVC  orillon\n",
      "   orillon/SVC  labourg\n",
      "   orillon/SVC  generic\n",
      "   orillon/XGB  anatole\n",
      "   orillon/XGB  babiche\n",
      "   orillon/XGB  cabeche\n",
      "   orillon/XGB  dacrons\n",
      "   orillon/XGB  echevin\n",
      "   orillon/XGB  gargote\n",
      "   orillon/XGB  faubers\n",
      "   orillon/XGB  hauynes\n",
      "   orillon/XGB  jobelin\n",
      "   orillon/XGB  inconel\n",
      "   orillon/XGB  kochias\n",
      "   orillon/XGB  orillon\n",
      "   orillon/XGB  labourg\n",
      "   orillon/XGB  generic\n",
      "   labourg/RandomForest  anatole\n",
      "   labourg/RandomForest  babiche\n",
      "   labourg/RandomForest  cabeche\n",
      "   labourg/RandomForest  dacrons\n",
      "   labourg/RandomForest  echevin\n",
      "   labourg/RandomForest  gargote\n",
      "   labourg/RandomForest  faubers\n",
      "   labourg/RandomForest  hauynes\n",
      "   labourg/RandomForest  jobelin\n",
      "   labourg/RandomForest  inconel\n",
      "   labourg/RandomForest  kochias\n",
      "   labourg/RandomForest  orillon\n",
      "   labourg/RandomForest  labourg\n",
      "   labourg/RandomForest  generic\n",
      "   labourg/SVC  anatole\n",
      "   labourg/SVC  babiche\n",
      "   labourg/SVC  cabeche\n",
      "   labourg/SVC  dacrons\n",
      "   labourg/SVC  echevin\n",
      "   labourg/SVC  gargote\n",
      "   labourg/SVC  faubers\n",
      "   labourg/SVC  hauynes\n",
      "   labourg/SVC  jobelin\n",
      "   labourg/SVC  inconel\n",
      "   labourg/SVC  kochias\n",
      "   labourg/SVC  orillon\n",
      "   labourg/SVC  labourg\n",
      "   labourg/SVC  generic\n",
      "   labourg/XGB  anatole\n",
      "   labourg/XGB  babiche\n",
      "   labourg/XGB  cabeche\n",
      "   labourg/XGB  dacrons\n",
      "   labourg/XGB  echevin\n",
      "   labourg/XGB  gargote\n",
      "   labourg/XGB  faubers\n",
      "   labourg/XGB  hauynes\n",
      "   labourg/XGB  jobelin\n",
      "   labourg/XGB  inconel\n",
      "   labourg/XGB  kochias\n",
      "   labourg/XGB  orillon\n",
      "   labourg/XGB  labourg\n",
      "   labourg/XGB  generic\n",
      "   generic/RandomForest  anatole\n",
      "   generic/RandomForest  babiche\n",
      "   generic/RandomForest  cabeche\n",
      "   generic/RandomForest  dacrons\n",
      "   generic/RandomForest  echevin\n",
      "   generic/RandomForest  gargote\n",
      "   generic/RandomForest  faubers\n",
      "   generic/RandomForest  hauynes\n",
      "   generic/RandomForest  jobelin\n",
      "   generic/RandomForest  inconel\n",
      "   generic/RandomForest  kochias\n",
      "   generic/RandomForest  orillon\n",
      "   generic/RandomForest  labourg\n",
      "   generic/RandomForest  generic\n",
      "   generic/SVC  anatole\n",
      "   generic/SVC  babiche\n",
      "   generic/SVC  cabeche\n",
      "   generic/SVC  dacrons\n",
      "   generic/SVC  echevin\n",
      "   generic/SVC  gargote\n",
      "   generic/SVC  faubers\n",
      "   generic/SVC  hauynes\n",
      "   generic/SVC  jobelin\n",
      "   generic/SVC  inconel\n",
      "   generic/SVC  kochias\n",
      "   generic/SVC  orillon\n",
      "   generic/SVC  labourg\n",
      "   generic/SVC  generic\n",
      "   generic/XGB  anatole\n",
      "   generic/XGB  babiche\n",
      "   generic/XGB  cabeche\n",
      "   generic/XGB  dacrons\n",
      "   generic/XGB  echevin\n",
      "   generic/XGB  gargote\n",
      "   generic/XGB  faubers\n",
      "   generic/XGB  hauynes\n",
      "   generic/XGB  jobelin\n",
      "   generic/XGB  inconel\n",
      "   generic/XGB  kochias\n",
      "   generic/XGB  orillon\n",
      "   generic/XGB  labourg\n",
      "   generic/XGB  generic\n",
      "Completed cross-evaluation for 588 combinations.\n",
      "\n",
      "================================================================================\n",
      "                               Pipeline Completed                               \n",
      "================================================================================\n",
      "\n",
      "Results saved to pipeline_outputs\\experiment_20250630_212223\\pipeline_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#        LEGAL CASE OUTCOME PREDICTION PIPELINE (final version)\n",
    "# ==============================================================================\n",
    "#\n",
    "# This script implements a machine learning pipeline for predicting legal case outcomes,\n",
    "# specifically custody decisions (\"mother\", \"father\", \"shared\"). It handles data loading,\n",
    "# preprocessing, feature encoding, judge-specific bucketing, flexible data balancing,\n",
    "# model training (XGBoost, RF, LogReg, SVM), hyperparameter tuning, evaluation,\n",
    "# and comprehensive result exports.\n",
    "\n",
    "# ==========================\n",
    "# Standard library imports\n",
    "# ==========================\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import io\n",
    "import gc\n",
    "import time\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any, Union, Callable\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "# ==========================\n",
    "# Third-party imports\n",
    "# ==========================\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier # type: ignore\n",
    "from sklearn.ensemble import RandomForestClassifier # type: ignore\n",
    "from sklearn.linear_model import LogisticRegression # type: ignore\n",
    "from sklearn.svm import SVC # type: ignore\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV # type: ignore\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder # type: ignore\n",
    "from sklearn.compose import ColumnTransformer # type: ignore\n",
    "from sklearn.pipeline import Pipeline as SklearnPipeline # type: ignore\n",
    "from sklearn.metrics import ( # type: ignore\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from tabulate import tabulate # type: ignore\n",
    "\n",
    "try:\n",
    "    from imblearn.over_sampling import RandomOverSampler # type: ignore\n",
    "    from imblearn.under_sampling import RandomUnderSampler # type: ignore\n",
    "    # Imblearn Pipeline is not strictly needed if we apply samplers directly\n",
    "except ImportError:\n",
    "    RandomOverSampler = RandomUnderSampler = None\n",
    "    logging.warning(\"imbalanced-learn library not found. Sampling-based balancing will not be available.\")\n",
    "\n",
    "# Suppress common warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='sklearn')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost')\n",
    "\n",
    "# ------------------------------------------------------------------ #\n",
    "# 1  IMPORTS  (extend the existing sklearn.model_selection import) #\n",
    "# ------------------------------------------------------------------ #\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Constants\n",
    "# ==========================\n",
    "RANDOM_STATE: int = 42\n",
    "DEFAULT_OUTPUT_BASE_DIR: str = \"pipeline_outputs\"\n",
    "CONFIG_FILENAME: str = \"run_config.json\"\n",
    "LOG_FILENAME: str = \"pipeline_run.log\"\n",
    "RESULTS_XLSX_FILENAME: str = \"pipeline_results.xlsx\"\n",
    "CM_SUBDIR_NAME: str = \"confusion_matrices\"\n",
    "\n",
    "# Target variable specifics\n",
    "TARGET_CLASS_NAMES: List[str] = [\"mother\", \"father\", \"shared\"] # Corresponds to 0, 1, 2\n",
    "TARGET_CLASS_MAP: Dict[str, int] = {name: i for i, name in enumerate(TARGET_CLASS_NAMES)}\n",
    "CLASS_LABELS_NUMERIC: List[int] = list(TARGET_CLASS_MAP.values())\n",
    "\n",
    "#  balancing choices \n",
    "BALANCING_METHODS: List[str] = [\"none\", \"sampling\", \"weighting\"]\n",
    "\n",
    "# default number of features we will keep when exporting\n",
    "TOP_K_FEATURES: int = 15\n",
    "\n",
    "# ==========================\n",
    "# Global Configuration Store\n",
    "# ==========================\n",
    "CONFIG: Dict[str, Any] = {}\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Logging Setup\n",
    "# ==========================\n",
    "def setup_logging(log_path: Union[str, Path]) -> None:\n",
    "    \"\"\"Configures logging to file and console.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)-7s] [%(filename)s:%(lineno)d] %(message)s\",\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_path, mode='w', encoding='utf-8'), # Overwrite log for new run\n",
    "            logging.StreamHandler(sys.stdout) # Ensure stdout is used\n",
    "        ]\n",
    "    )\n",
    "    logging.info(f\"Logging initialized. Log file: {log_path}\")\n",
    "    # Test encoding for logger\n",
    "    logging.info(\"Test log with special characters:  \")\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Console Encoding Fix (from user script)\n",
    "# ==========================\n",
    "def fix_console_encoding() -> None:\n",
    "    \"\"\"Attempt to fix console encoding issues, especially on Windows.\"\"\"\n",
    "    if sys.platform == \"win32\":\n",
    "        try:\n",
    "            # Try to set console to UTF-8 if possible\n",
    "            os.system(\"chcp 65001 > nul\") # type: ignore\n",
    "            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')\n",
    "            sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')\n",
    "            logging.info(\"Attempted to set console to UTF-8 (chcp 65001) and wrap stdout/stderr.\")\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not fully set console to UTF-8 or wrap streams: {e}. Using PYTHONIOENCODING as fallback if set.\")\n",
    "            # Fallback for environments where buffer is not available or chcp fails (e.g., some IDE consoles)\n",
    "            if \"PYTHONIOENCODING\" not in os.environ:\n",
    "                os.environ[\"PYTHONIOENCODING\"] = \"utf-8\"\n",
    "                logging.info(\"Set PYTHONIOENCODING=utf-8 as a fallback.\")\n",
    "\n",
    "# Call encoding fix early\n",
    "fix_console_encoding()\n",
    "\n",
    "# ==========================\n",
    "# Utility Functions\n",
    "# ==========================\n",
    "def create_output_directory(base_dir: str = DEFAULT_OUTPUT_BASE_DIR) -> str:\n",
    "    \"\"\"Creates a timestamped output directory for an experiment run.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = os.path.join(base_dir, f\"experiment_{timestamp}\")\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "def print_section_header(title: str) -> None:\n",
    "    \"\"\"Prints a formatted section header to the console.\"\"\"\n",
    "    bar = \"=\" * 80\n",
    "    print(f\"\\n{bar}\\n{title.center(80)}\\n{bar}\\n\")\n",
    "\n",
    "def safe_input(prompt: str, default: Optional[str] = None, type_caster: Optional[Callable] = None, choices: Optional[List[str]] = None) -> Any:\n",
    "    \"\"\"Generic safe input function with type casting and choice validation.\"\"\"\n",
    "    while True:\n",
    "        default_str = f\" (default: {default})\" if default is not None else \"\"\n",
    "        choice_str = f\" (options: {', '.join(choices)})\" if choices else \"\"\n",
    "        user_input = input(f\"{prompt}{default_str}{choice_str}: \").strip()\n",
    "\n",
    "        if not user_input and default is not None:\n",
    "            user_input = str(default) # Ensure default is string for processing\n",
    "\n",
    "        if choices and user_input.lower() not in [c.lower() for c in choices]:\n",
    "            print(f\"Invalid choice. Please select from: {', '.join(choices)}\")\n",
    "            continue\n",
    "\n",
    "        if type_caster:\n",
    "            try:\n",
    "                return type_caster(user_input)\n",
    "            except ValueError:\n",
    "                print(f\"Invalid input type. Expected {type_caster.__name__ if hasattr(type_caster, '__name__') else 'specific type'}.\")\n",
    "        else:\n",
    "            return user_input # Return as string if no caster\n",
    "\n",
    "def get_yes_no_input(prompt_message: str, default_yes: bool = True) -> bool:\n",
    "    \"\"\"Gets a yes/no input from the user.\"\"\"\n",
    "    suffix = \"(Y/n)\" if default_yes else \"(y/N)\"\n",
    "    while True:\n",
    "        user_input = input(f\"{prompt_message} {suffix}: \").strip().lower()\n",
    "        if not user_input:\n",
    "            return default_yes\n",
    "        if user_input in ['y', 'yes']:\n",
    "            return True\n",
    "        if user_input in ['n', 'no']:\n",
    "            return False\n",
    "        print(\"Invalid input. Please enter 'y' or 'n'.\")\n",
    "\n",
    "# Assuming your display_df_columns is similar to this:\n",
    "def display_df_columns(df_to_display: pd.DataFrame, description: str) -> None:\n",
    "    \"\"\"Displays DataFrame columns in a tabulated format with 0-based indexing for THIS list.\"\"\"\n",
    "    print_section_header(description) # Use your existing print_section_header\n",
    "    if df_to_display.empty and not list(df_to_display.columns): # Handle empty df with no columns\n",
    "        print(f\"  ({description} is empty or has no columns to display)\")\n",
    "        return\n",
    "        \n",
    "    # df_to_display.columns will give the list of column names\n",
    "    # The indices will be 0 to len(df_to_display.columns)-1\n",
    "    cols_tbl = [[idx, col_name] for idx, col_name in enumerate(df_to_display.columns)]\n",
    "    \n",
    "    if not cols_tbl: # If there are columns but they are all None or something odd\n",
    "        print(f\"  (No valid column names to display for {description})\")\n",
    "        return\n",
    "\n",
    "    print(tabulate(cols_tbl, headers=[\"Index (for this list)\", \"Column Name\"], tablefmt=\"grid\"))\n",
    "    print(f\"  Total columns in this list: {len(df_to_display.columns)}\\n\")\n",
    "\n",
    "class NumpyJSONEncoder(json.JSONEncoder):\n",
    "    \"\"\"JSON encoder that handles NumPy data types (from user script).\"\"\"\n",
    "    def default(self, obj: Any) -> Any:\n",
    "        if isinstance(obj, (np.integer, np.int64, np.int32)): return int(obj)\n",
    "        if isinstance(obj, (np.floating, np.float32, np.float64)): return float(obj)\n",
    "        if isinstance(obj, np.ndarray): return obj.tolist()\n",
    "        if isinstance(obj, np.bool_): return bool(obj)\n",
    "        if isinstance(obj, (Path)): return str(obj) # Handle Path objects\n",
    "        if isinstance(obj, pd.Timestamp): return obj.isoformat()\n",
    "        try: # For other non-serializable objects, convert to string representation\n",
    "            return super().default(obj)\n",
    "        except TypeError:\n",
    "            return str(obj)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Configuration Management\n",
    "# ==========================\n",
    "def _clean_path_input(path_str: str) -> str:\n",
    "    \"\"\"Strips quotes and whitespace from a path string.\"\"\"\n",
    "    return path_str.strip().strip('\"').strip(\"'\")\n",
    "\n",
    "def get_file_paths_config() -> Dict[str, Any]:\n",
    "    \"\"\"Gets file paths and saving directory configuration interactively.\"\"\"\n",
    "    print_section_header(\"File Paths Configuration\")\n",
    "    cfg = {}\n",
    "    cfg['output_base_dir'] = _clean_path_input(safe_input(\"Enter base directory for outputs\", DEFAULT_OUTPUT_BASE_DIR))\n",
    "    cfg['cases_file_path'] = _clean_path_input(safe_input(\"Enter path to cases XLSX file\"))\n",
    "    cfg['judges_file_path'] = _clean_path_input(safe_input(\"Enter path to judges XLSX file (optional, press Enter to skip)\", default=\"\")) or None\n",
    "    return cfg\n",
    "\n",
    "def _select_columns_interactive(df_columns: List[str], prompt_message: str, allow_multiple: bool = False, is_required: bool = True) -> Union[Optional[str], List[str]]:\n",
    "    \"\"\"Helper for interactive column selection by name or index.\"\"\"\n",
    "    if not df_columns:\n",
    "        print(f\"Warning: No columns available for selection for '{prompt_message}'.\")\n",
    "        return [] if allow_multiple else None\n",
    "\n",
    "    while True:\n",
    "        user_input_str = safe_input(prompt_message).strip()\n",
    "\n",
    "        if not user_input_str:\n",
    "            if is_required:\n",
    "                print(\"This field is required. Please provide an input.\")\n",
    "                continue\n",
    "            return [] if allow_multiple else None\n",
    "\n",
    "        selected_col_names: List[str] = []\n",
    "        inputs = [item.strip() for item in user_input_str.split(',')] if allow_multiple else [user_input_str]\n",
    "\n",
    "        valid_selection = True\n",
    "        for item in inputs:\n",
    "            try:\n",
    "                if item.isdigit(): # Index-based selection\n",
    "                    idx = int(item)\n",
    "                    if 0 <= idx < len(df_columns):\n",
    "                        selected_col_names.append(df_columns[idx])\n",
    "                    else:\n",
    "                        print(f\"Error: Index {idx} is out of range (0-{len(df_columns)-1}).\")\n",
    "                        valid_selection = False; break\n",
    "                elif item in df_columns: # Name-based selection\n",
    "                    selected_col_names.append(item)\n",
    "                else:\n",
    "                    print(f\"Error: Column '{item}' not found.\")\n",
    "                    # Provide suggestions for similar column names\n",
    "                    from difflib import get_close_matches\n",
    "                    matches = get_close_matches(item, df_columns, n=3, cutoff=0.6)\n",
    "                    if matches:\n",
    "                        print(f\"Did you mean one of these: {', '.join(matches)}?\")\n",
    "                    valid_selection = False; break\n",
    "            except ValueError:\n",
    "                print(f\"Error: Invalid input '{item}'. Use column names or indices.\")\n",
    "                valid_selection = False; break\n",
    "        \n",
    "        if valid_selection:\n",
    "            return selected_col_names if allow_multiple else selected_col_names[0]\n",
    "\n",
    "def get_operational_columns_config(df_final: pd.DataFrame, current_config: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Gets bucketing ID, target, and features from the FINAL merged DataFrame.\n",
    "    Ensures correct indexing for feature selection.\n",
    "    \"\"\"\n",
    "    print_section_header(\"Select Operational Columns from Merged Data\")\n",
    "    \n",
    "    # Display ALL columns of the final merged DataFrame first for context\n",
    "    display_df_columns(df_final, \"Full List of Columns in Final Merged Data\")\n",
    "    \n",
    "    cfg = {}\n",
    "    df_cols_list_full = list(df_final.columns) # All columns from the merged df\n",
    "\n",
    "    # --- 1. Select Judge ID for Bucketing (Optional) ---\n",
    "    if get_yes_no_input(\"Will you use judge-specific bucketing?\", default_yes=True):\n",
    "        print(\"\\n--- Select Judge ID for Bucketing ---\")\n",
    "        # User selects from the full list of columns in the merged DataFrame\n",
    "        cfg['judge_id_col_final_bucketing'] = _select_columns_interactive(\n",
    "            df_cols_list_full, # Select from ALL columns in df_final\n",
    "            \"Enter the column NAME or INDEX (from the full list above) for Judge ID (for bucketing)\",\n",
    "            allow_multiple=False, \n",
    "            is_required=True # If they said yes to bucketing, this is required\n",
    "        )\n",
    "    else:\n",
    "        cfg['judge_id_col_final_bucketing'] = None\n",
    "    logging.info(f\"Judge ID for bucketing set to: {cfg['judge_id_col_final_bucketing']}\")\n",
    "\n",
    "    # --- 2. Select Target Column ---\n",
    "    print(\"\\n--- Select Target Column ---\")\n",
    "    # Columns to exclude from being the target: the bucketing ID if selected\n",
    "    cols_to_exclude_for_target = [cfg.get('judge_id_col_final_bucketing')]\n",
    "    available_for_target = [\n",
    "        col for col in df_cols_list_full \n",
    "        if col not in cols_to_exclude_for_target and col is not None\n",
    "    ]\n",
    "    # Display the list from which the target will be selected (which is almost the full list)\n",
    "    # For clarity, could re-display df_cols_list_full here or a filtered version if it's very different.\n",
    "    # For now, assume user refers to the \"Full List\" displayed at the start of this function.\n",
    "    cfg['target_col'] = _select_columns_interactive(\n",
    "        df_cols_list_full, # User selects target from ALL columns in df_final\n",
    "        f\"Enter the TARGET column NAME or INDEX (from the full list above, e.g., 'custody_outcome')\",\n",
    "        allow_multiple=False, \n",
    "        is_required=True\n",
    "    )\n",
    "    logging.info(f\"Target column set to: {cfg['target_col']}\")\n",
    "\n",
    "    # --- 3. Prepare List of Potential Feature Columns ---\n",
    "    # Exclude bucketing ID (if any) and the chosen target column\n",
    "    cols_to_exclude_for_features = [\n",
    "        cfg.get('judge_id_col_final_bucketing'),\n",
    "        cfg.get('target_col')\n",
    "    ]\n",
    "    potential_feature_cols = [\n",
    "        col for col in df_cols_list_full \n",
    "        if col not in cols_to_exclude_for_features and col is not None\n",
    "    ]\n",
    "\n",
    "    if not potential_feature_cols:\n",
    "        logging.error(\"No potential feature columns remain after excluding ID and target. Cannot proceed.\")\n",
    "        # In a real scenario, you might want to sys.exit() or raise an error here.\n",
    "        # For now, return empty features, which will likely cause issues later.\n",
    "        cfg['feature_cols'] = []\n",
    "        logging.info(f\"Operational columns selected: Bucketing ID='{cfg.get('judge_id_col_final_bucketing')}', Target='{cfg['target_col']}', Features=0.\")\n",
    "        return cfg\n",
    "\n",
    "    # --- 4. Select Feature Columns ---\n",
    "    print_section_header(\"Select Feature Columns\")\n",
    "    logging.info(f\"Presenting {len(potential_feature_cols)} potential features for selection.\")\n",
    "    \n",
    "    # IMPORTANT: Display the `potential_feature_cols` list with ITS OWN 0-based indexing.\n",
    "    # The `display_df_columns` helper needs to be able to take a list of column names\n",
    "    # and display them with 0-based indexing for that list.\n",
    "    # Let's assume `display_df_columns` can handle this by creating a temporary DataFrame for display:\n",
    "    df_potential_features_for_display = pd.DataFrame(columns=potential_feature_cols)\n",
    "    display_df_columns(df_potential_features_for_display, \"POTENTIAL FEATURES (select from this list using its 0-based index or name)\")\n",
    "\n",
    "    if get_yes_no_input(f\"Use all {len(potential_feature_cols)} listed POTENTIAL features?\", default_yes=True):\n",
    "        cfg['feature_cols'] = potential_feature_cols # Assign all names\n",
    "    else:\n",
    "        # User selects from the `potential_feature_cols` list using ITS 0-based index or name\n",
    "        selected_features_from_potential_list = _select_columns_interactive(\n",
    "            potential_feature_cols, # Pass the list they are seeing\n",
    "            \"Enter FEATURE column NAMES or INDICES (comma-separated, from the POTENTIAL FEATURES list above)\",\n",
    "            allow_multiple=True, \n",
    "            is_required=True # If they choose to select manually, they must select at least one\n",
    "        )\n",
    "        cfg['feature_cols'] = selected_features_from_potential_list if selected_features_from_potential_list else []\n",
    "\n",
    "\n",
    "    # --- 5. Confirm Selected Features ---\n",
    "    if cfg.get('feature_cols'):\n",
    "        print_section_header(\"Confirm Final Selected Features\")\n",
    "        print(\"You have selected the following features for the model:\")\n",
    "        # Display the NAMES of the features that are now in cfg['feature_cols']\n",
    "        # These names come from the `potential_feature_cols` list.\n",
    "        selected_features_table = [[i, name] for i, name in enumerate(cfg['feature_cols'])]\n",
    "        print(tabulate(selected_features_table, headers=[\"# (For Info)\", \"Selected Feature Name\"], tablefmt=\"grid\"))\n",
    "        \n",
    "        if not get_yes_no_input(\"Proceed with these features?\", default_yes=True):\n",
    "            logging.warning(\"User did not confirm the selected features. The pipeline will proceed with the current selection. To change, restart configuration.\")\n",
    "            # For a more robust UI, you would loop back to the feature selection step here.\n",
    "            # Simplified: proceed with what was selected.\n",
    "    elif not cfg.get('feature_cols'): # This case happens if user said \"no\" to all features, then selected none.\n",
    "        logging.error(\"No features were selected. At least one feature is generally required for modeling.\")\n",
    "        # This should ideally be prevented by `_select_columns_interactive` if `is_required=True`.\n",
    "        # If it can still happen, the pipeline might fail later.\n",
    "        # For now, allow it to proceed with empty features, but it's a critical state.\n",
    "\n",
    "    num_selected_features = len(cfg.get('feature_cols', []))\n",
    "    logging.info(f\"Operational columns configuration complete: Bucketing ID='{cfg.get('judge_id_col_final_bucketing')}', Target='{cfg['target_col']}', Features selected={num_selected_features}.\")\n",
    "    if num_selected_features > 0:\n",
    "        logging.info(f\"Selected feature names: {cfg.get('feature_cols')}\")\n",
    "    \n",
    "    return cfg\n",
    "\n",
    "def validate_feature_types_interactive(df: pd.DataFrame, feature_cols: List[str]) -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Interactively validates feature types (categorical/numeric),\n",
    "    incorporating a heuristic for unique value counts.\n",
    "    \"\"\"\n",
    "    print_section_header(\"Feature Type Validation\")\n",
    "    numerical_features: List[str] = []\n",
    "    categorical_features: List[str] = []\n",
    "\n",
    "    if not feature_cols:\n",
    "        logging.warning(\"No feature columns provided for type validation.\")\n",
    "        return numerical_features, categorical_features\n",
    "\n",
    "    for col in feature_cols:\n",
    "        if col not in df.columns:\n",
    "            logging.warning(f\"Feature column '{col}' not found in DataFrame. Skipping validation for this column.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n--- Validating Feature: '{col}' ---\")\n",
    "        print(f\"  Original Data Type: {df[col].dtype}\")\n",
    "        \n",
    "        # Handle potential all-NaN columns gracefully before nunique() or stats\n",
    "        if df[col].isnull().all():\n",
    "            print(\"  Column contains only NaN values.\")\n",
    "            # Decide how to treat all-NaN columns. Often categorical or dropped later.\n",
    "            # For now, let's suggest categorical and let user decide.\n",
    "            default_type = \"categorical\"\n",
    "            suggestion_reason = \"Column is all NaN values.\"\n",
    "            nunique = 0\n",
    "        else:\n",
    "            unique_values = df[col].dropna().unique() # Drop NaNs for unique value display\n",
    "            nunique = len(unique_values) # df[col].nunique() also works but might be slower on object types\n",
    "            print(f\"  Unique Values (sample, non-NaN): {unique_values[:min(5, len(unique_values))]}\")\n",
    "            print(f\"  Number of Unique Values (non-NaN): {nunique}\")\n",
    "\n",
    "            is_numeric_dtype = pd.api.types.is_numeric_dtype(df[col])\n",
    "\n",
    "            # Determine the default suggestion based on dtype and your nunique rule\n",
    "            if is_numeric_dtype:\n",
    "                if nunique > 7:\n",
    "                    default_type = \"numeric\"\n",
    "                    suggestion_reason = \"Detected as numeric dtype with >7 unique values.\"\n",
    "                elif nunique == 0 and df[col].isnull().all(): # Already handled above, but as a safeguard\n",
    "                    default_type = \"categorical\"\n",
    "                    suggestion_reason = \"Column is all NaN values (numeric dtype).\"\n",
    "                else: # nunique <= 7 and is_numeric_dtype (and not all NaN)\n",
    "                    default_type = \"categorical\"\n",
    "                    suggestion_reason = \"Numeric dtype, but <=7 unique values suggests it might be categorical (e.g., codes).\"\n",
    "            else: # Not a numeric dtype (e.g., object, string, bool)\n",
    "                default_type = \"categorical\"\n",
    "                suggestion_reason = \"Detected as non-numeric dtype.\"\n",
    "        \n",
    "        print(f\"  Suggestion: Treat as {default_type.upper()}. Reason: {suggestion_reason}\")\n",
    "\n",
    "        user_choice = safe_input(\n",
    "            f\"  Confirm type for '{col}' (NUMERIC or CATEGORICAL)?\",\n",
    "            default=default_type,\n",
    "            choices=[\"numeric\", \"categorical\"]\n",
    "        ).lower()\n",
    "\n",
    "        if user_choice == \"numeric\":\n",
    "            numerical_features.append(col)\n",
    "            # Attempt to print numeric stats if confirmed as numeric\n",
    "            # Ensure the column can actually be treated as numeric before stats\n",
    "            try:\n",
    "                # Attempt to convert to numeric if user says so, to catch errors early if not possible\n",
    "                temp_numeric_col = pd.to_numeric(df[col], errors='raise')\n",
    "                if temp_numeric_col.notna().any(): # Check if not all NaNs after conversion\n",
    "                    col_stats = temp_numeric_col.agg(['min', 'max', 'mean'])\n",
    "                    print(f\"    Selected as NUMERIC. Stats: Min={col_stats['min']:.2f}, Max={col_stats['max']:.2f}, Mean={col_stats['mean']:.2f}\")\n",
    "                else:\n",
    "                    print(\"    Selected as NUMERIC, but column became all NaNs after attempted numeric conversion or was already all NaNs.\")\n",
    "            except (ValueError, TypeError):\n",
    "                print(f\"    Selected as NUMERIC, but failed to convert column '{col}' to a numeric type for stats calculation. Original dtype: {df[col].dtype}. It will be included in numerical_features list, but ensure it's truly numeric for transformers.\")\n",
    "        else: # user_choice == \"categorical\"\n",
    "            categorical_features.append(col)\n",
    "            print(f\"    Selected as CATEGORICAL.\")\n",
    "        \n",
    "        logging.info(f\"Feature '{col}': Original dtype {df[col].dtype}, Unique values {nunique}, Validated by user as {user_choice.upper()}.\")\n",
    "\n",
    "    logging.info(f\"Final Numerical features ({len(numerical_features)}): {numerical_features}\")\n",
    "    logging.info(f\"Final Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "    return numerical_features, categorical_features\n",
    "\n",
    "def get_encoding_config_interactive(df: pd.DataFrame, target_col: str) -> Dict[str, Any]:\n",
    "    \"\"\"Gets data encoding configuration, especially for the target variable.\"\"\"\n",
    "    print_section_header(\"Data Encoding Configuration\")\n",
    "    cfg = {}\n",
    "    print(f\"\\nTarget Variable: '{target_col}'\")\n",
    "    unique_targets_original = df[target_col].dropna().unique()\n",
    "    print(f\"  Unique values found in '{target_col}': {unique_targets_original}\")\n",
    "    print(f\"  Expected target classes: {', '.join(TARGET_CLASS_NAMES)} (mapped to {CLASS_LABELS_NUMERIC})\")\n",
    "\n",
    "    # Target mapping: Allow user to map their raw labels to the predefined numeric ones\n",
    "    target_map_raw_to_numeric: Dict[Any, int] = {}\n",
    "    print(\"\\nPlease map your raw target labels to the standard numeric classes:\")\n",
    "    for std_name, numeric_val in TARGET_CLASS_MAP.items():\n",
    "        raw_val_str = safe_input(f\"  Enter raw label in your data that corresponds to '{std_name}' (Class {numeric_val})\")\n",
    "        # Try to cast raw_val_str to original dtype of target column\n",
    "        try:\n",
    "            original_dtype = df[target_col].dtype\n",
    "            if pd.api.types.is_numeric_dtype(original_dtype) and not pd.api.types.is_bool_dtype(original_dtype):\n",
    "                raw_val_typed = original_dtype.type(raw_val_str)\n",
    "            elif pd.api.types.is_bool_dtype(original_dtype): # Handle boolean types carefully\n",
    "                 if raw_val_str.lower() in ['true', '1', 't', 'yes', 'y']: raw_val_typed = True\n",
    "                 elif raw_val_str.lower() in ['false', '0', 'f', 'no', 'n']: raw_val_typed = False\n",
    "                 else: raise ValueError(\"Invalid boolean string\")\n",
    "            else: # string or object\n",
    "                raw_val_typed = raw_val_str\n",
    "            target_map_raw_to_numeric[raw_val_typed] = numeric_val\n",
    "        except ValueError:\n",
    "            logging.warning(f\"Could not convert '{raw_val_str}' to dtype {original_dtype}. Storing as string.\")\n",
    "            target_map_raw_to_numeric[raw_val_str] = numeric_val\n",
    "            \n",
    "    cfg['target_mapping_raw_to_numeric'] = target_map_raw_to_numeric\n",
    "    logging.info(f\"Target encoding map (raw to numeric): {target_map_raw_to_numeric}\")\n",
    "    return cfg\n",
    "\n",
    "def get_bucketing_config_interactive() -> Dict[str, Any]:\n",
    "    \"\"\"Gets judge bucketing configuration.\"\"\"\n",
    "    print_section_header(\"Judge Bucketing Configuration\")\n",
    "    cfg = {}\n",
    "    cfg['use_judge_bucketing'] = get_yes_no_input(\"Enable judge-specific bucketing?\", default_yes=True)\n",
    "    if cfg['use_judge_bucketing']:\n",
    "        cfg['min_samples_per_judge_bucket'] = int(safe_input(\"Min samples per judge for dedicated bucket (others to 'generic')\", default=30, type_caster=int))\n",
    "    else:\n",
    "        cfg['min_samples_per_judge_bucket'] = 0 # Not used\n",
    "    logging.info(f\"Bucketing config: {cfg}\")\n",
    "    return cfg\n",
    "\n",
    "def get_balancing_config_interactive(\n",
    "    class_counter: Optional[Counter] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Simplified balancing config: 'none', 'sampling', 'weighting'.\n",
    "\n",
    "    If sampling   ask for target PERCENTAGES.\n",
    "    If weighting  ask for relative weights (ratios) w.r.t. class 0.\n",
    "    \"\"\"\n",
    "    print_section_header(\"Class Balancing Configuration\")\n",
    "    cfg: Dict[str, Any] = {}\n",
    "\n",
    "    #  current distribution preview \n",
    "    if class_counter:\n",
    "        print(\"Current global distribution:\")\n",
    "        print_class_distribution(class_counter, \"GLOBAL\")\n",
    "\n",
    "    #  choose method \n",
    "    method = safe_input(\n",
    "        \"Balancing method\",\n",
    "        default=\"sampling\",\n",
    "        choices=BALANCING_METHODS\n",
    "    ).lower()\n",
    "    cfg[\"balancing_method\"] = method\n",
    "\n",
    "    if method == \"sampling\":\n",
    "        default_str = \"33,33,34\"\n",
    "        pct_str = safe_input(\n",
    "            \"Target class percentages for (mother,father,shared)\",\n",
    "            default=default_str,\n",
    "        )\n",
    "        try:\n",
    "            p0, p1, p2 = [float(x) for x in pct_str.split(\",\")]\n",
    "        except Exception:\n",
    "            print(\"Invalid format  falling back to default 33,33,34.\")\n",
    "            p0, p1, p2 = 33.0, 33.0, 34.0\n",
    "        total = p0 + p1 + p2\n",
    "        cfg[\"sampling_target_percentages\"] = {\n",
    "            0: 100.0 * p0 / total,\n",
    "            1: 100.0 * p1 / total,\n",
    "            2: 100.0 * p2 / total,\n",
    "        }\n",
    "    elif method == \"weighting\":\n",
    "        default_str = \"1,1,1\"\n",
    "        w_str = safe_input(\n",
    "            \"Relative class weights for (mother,father,shared)\",\n",
    "            default=default_str,\n",
    "        )\n",
    "        try:\n",
    "            w0, w1, w2 = [float(x) for x in w_str.split(\",\")]\n",
    "        except Exception:\n",
    "            print(\"Invalid format  using equal weights.\")\n",
    "            w0, w1, w2 = 1.0, 1.0, 1.0\n",
    "        cfg[\"class_weight_ratios\"] = {0: w0, 1: w1, 2: w2}\n",
    "\n",
    "    logging.info(f\"Balancing configuration: {cfg}\")\n",
    "    return cfg\n",
    "\n",
    "def _load_hyperparameter_grid_file() -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Lets the user point to a JSON file that contains a dictionary\n",
    "    {model_name -> param_distributions}.\n",
    "    Returns the dict or None if user skips / on error.\n",
    "    \"\"\"\n",
    "    print_section_header(\"Hyper-parameter Grid (optional)\")\n",
    "    wants_file = get_yes_no_input(\n",
    "        \"Load hyper-parameter search space from a JSON file?\",\n",
    "        default_yes=False,\n",
    "    )\n",
    "    if not wants_file:\n",
    "        return None\n",
    "\n",
    "    path_str = safe_input(\"Path to hyper-param JSON file\")\n",
    "    path = Path(_clean_path_input(path_str))\n",
    "    if not path.exists():\n",
    "        print(f\"  File '{path}' not found. Falling back to built-in grids.\")\n",
    "        logging.warning(f\"Hyper-param grid file missing: {path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as fp:\n",
    "            grids = json.load(fp)\n",
    "        print(\"  Custom hyper-parameter grid loaded.\")\n",
    "        logging.info(f\"Hyper-param grids loaded from {path}\")\n",
    "        return grids\n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to load hyper-parameter JSON: {e}\")\n",
    "        logging.error(f\"Hyper-param JSON load error: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_cv_model_hyperparam_config() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Builds the cross-validation, model list and hyper-parameter grid section\n",
    "    of CONFIG.  Now supports external JSON for the grid definition.\n",
    "    \"\"\"\n",
    "    cfg: Dict[str, Any] = {}\n",
    "\n",
    "    #  models to run \n",
    "    all_models = [\"RandomForest\", \"LogisticRegression\", \"SVC\", \"XGB\"]\n",
    "    use_models = safe_input(\n",
    "        f\"Models to run (comma separated, available {all_models})\",\n",
    "        default=\",\".join(all_models)\n",
    "    )\n",
    "    cfg[\"models_to_run\"] = [m.strip() for m in use_models.split(\",\") if m.strip()]\n",
    "\n",
    "    #  CV settings \n",
    "    cfg[\"cv_folds\"] = int(safe_input(\"Number of CV folds\", default=\"5\", type_caster=int))\n",
    "    cfg[\"cv_random_state\"] = RANDOM_STATE\n",
    "    cfg[\"hyperparameter_tuning_iterations\"] = int(\n",
    "        safe_input(\"RandomizedSearch iterations\", default=\"50\", type_caster=int)\n",
    "    )\n",
    "\n",
    "    #  hyper-parameter grid \n",
    "    external_grid = _load_hyperparameter_grid_file()\n",
    "    if external_grid:\n",
    "        cfg[\"hyperparameter_grids\"] = external_grid\n",
    "        cfg[\"hyperparameter_grids_loaded_from\"] = True\n",
    "    else:\n",
    "        # fall-back defaults (feel free to extend)\n",
    "        cfg[\"hyperparameter_grids\"] = {\n",
    "            \"RandomForest\": {\n",
    "                \"n_estimators\": [100, 300, 500],\n",
    "                \"max_depth\": [None, 10, 20],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "            },\n",
    "            \"LogisticRegression\": {\n",
    "                \"C\": np.logspace(-3, 3, 7),\n",
    "                \"penalty\": [\"l2\"],\n",
    "                \"solver\": [\"lbfgs\"],\n",
    "            },\n",
    "            \"SVC\": {\n",
    "                \"C\": np.logspace(-2, 2, 5),\n",
    "                \"kernel\": [\"linear\", \"rbf\"],\n",
    "                \"gamma\": [\"scale\", \"auto\"],\n",
    "            },\n",
    "            \"XGB\": {\n",
    "                \"n_estimators\": [200, 400],\n",
    "                \"max_depth\": [3, 6, 9],\n",
    "                \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "                \"subsample\": [0.8, 1.0],\n",
    "            },\n",
    "        }\n",
    "        cfg[\"hyperparameter_grids_loaded_from\"] = False\n",
    "    return cfg\n",
    "\n",
    "def load_or_request_config(output_dir: str) -> None:\n",
    "    \"\"\"Loads config from file or prompts user if not found/chosen.\"\"\"\n",
    "    global CONFIG\n",
    "    config_file_path = Path(output_dir) / CONFIG_FILENAME\n",
    "\n",
    "    if get_yes_no_input(\"Load configuration from a file?\", default_yes=config_file_path.exists()):\n",
    "        if config_file_path.exists():\n",
    "            chosen_path_str = safe_input(\"Enter path to configuration JSON file\", default=str(config_file_path))\n",
    "        else:\n",
    "            chosen_path_str = safe_input(\"Enter path to configuration JSON file (no default found)\")\n",
    "        \n",
    "        chosen_path = Path(_clean_path_input(chosen_path_str))\n",
    "        try:\n",
    "            with open(chosen_path, 'r', encoding='utf-8') as f:\n",
    "                CONFIG = json.load(f)\n",
    "            logging.info(f\"Configuration loaded from {chosen_path}\")\n",
    "            # Update output_base_dir from loaded config if it exists, otherwise keep current\n",
    "            CONFIG['output_base_dir'] = Path(output_dir).parent # Parent of the timestamped experiment dir\n",
    "            CONFIG['output_dir_actual'] = str(output_dir) # The current timestamped dir\n",
    "            return\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading config file '{chosen_path}': {e}. Proceeding with interactive setup.\")\n",
    "            # Fall through to interactive setup\n",
    "    \n",
    "    # Interactive Setup\n",
    "    print_section_header(\"Pipeline Configuration (Interactive Mode)\")\n",
    "    # 1. File paths (already got output_base_dir, need others)\n",
    "    CONFIG.update(get_file_paths_config()) # This will update output_base_dir if user changes it\n",
    "    # Re-derive output_dir_actual based on potentially new output_base_dir from user\n",
    "    # The output_dir passed to this function was based on initial/default base_dir\n",
    "    # If user changes output_base_dir, the actual experiment dir path needs to reflect that.\n",
    "    # However, the timestamped dir is already created. For simplicity, we'll use the one created at startup.\n",
    "    # A more complex flow would recreate the dir or warn. For now, assume output_dir is fixed once created.\n",
    "    CONFIG['output_dir_actual'] = str(output_dir)\n",
    "\n",
    "    # 2. Load data for column selection\n",
    "    df_cases_preview = load_data_from_path(CONFIG['cases_file_path'], \"Cases Data\")\n",
    "    df_judges_preview = None\n",
    "    if CONFIG.get('judges_file_path'):\n",
    "        df_judges_preview = load_data_from_path(CONFIG['judges_file_path'], \"Judges Data\")\n",
    "\n",
    "    df_merged_preview = initial_merge_for_column_selection(df_cases_preview, df_judges_preview, CONFIG)\n",
    "    if df_merged_preview is None or df_merged_preview.empty:\n",
    "        logging.error(\"Failed to load or merge data for column selection. Exiting.\")\n",
    "        sys.exit(\"Cannot proceed without data for column selection.\")\n",
    "\n",
    "    # 3. Column selections\n",
    "    CONFIG.update(get_column_config_interactive(df_merged_preview))\n",
    "\n",
    "    # 4. Feature type validation\n",
    "    numerical_cols, categorical_cols = validate_feature_types_interactive(df_merged_preview, CONFIG['feature_cols'])\n",
    "    CONFIG['numerical_features'] = numerical_cols\n",
    "    CONFIG['categorical_features'] = categorical_cols\n",
    "    \n",
    "    # 5. Encoding (target variable)\n",
    "    CONFIG.update(get_encoding_config_interactive(df_merged_preview, CONFIG['target_col']))\n",
    "\n",
    "    # 6. Bucketing\n",
    "    CONFIG.update(get_bucketing_config_interactive())\n",
    "\n",
    "    # 7. Balancing\n",
    "    CONFIG.update(get_balancing_config_interactive())\n",
    "\n",
    "    # 8. CV, Models, Hyperparams\n",
    "    CONFIG.update(get_cv_model_hyperparam_config())\n",
    "\n",
    "    logging.info(\"Interactive configuration complete.\")\n",
    "    save_config(CONFIG, Path(CONFIG['output_dir_actual']) / CONFIG_FILENAME)\n",
    "\n",
    "\n",
    "def save_config(config_data: Dict[str, Any], filepath: Path) -> None:\n",
    "    \"\"\"Saves the configuration dictionary to a JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(config_data, f, cls=NumpyJSONEncoder, indent=2)\n",
    "        logging.info(f\"Configuration successfully saved to {filepath}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving configuration to {filepath}: {e}\")\n",
    "\n",
    "# ==========================\n",
    "# Data Loading and Initial Merge for Column Selection\n",
    "# ==========================\n",
    "def load_data_from_path(file_path: Optional[str], description: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Loads data from an Excel file (first sheet).\"\"\"\n",
    "    if not file_path:\n",
    "        logging.info(f\"{description} file path not provided. Skipping load.\")\n",
    "        return None\n",
    "    try:\n",
    "        logging.info(f\"Loading {description} from: {file_path}\")\n",
    "        df = pd.read_excel(file_path, sheet_name=0) # Always first sheet\n",
    "        logging.info(f\"Successfully loaded {description}. Shape: {df.shape}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Error: File not found at {file_path} for {description}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading {description} from {file_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def initial_merge_for_column_selection(\n",
    "    df_cases: Optional[pd.DataFrame],\n",
    "    df_judges: Optional[pd.DataFrame],\n",
    "    current_config: Dict[str, Any]\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Performs a preliminary (initial) merge so the user can preview\n",
    "    columns from both dataframes before the real merge keys are final.\n",
    "    \"\"\"\n",
    "    if df_cases is None:\n",
    "        return None\n",
    "    if df_judges is None:\n",
    "        return df_cases.copy()  # no judges data  just return cases\n",
    "\n",
    "    # 1. use configured keys if they exist\n",
    "    case_key  = current_config.get('judge_id_col_cases')\n",
    "    judge_key = current_config.get('judge_id_col_judges')\n",
    "\n",
    "    temp_keys_used = False\n",
    "    if not (case_key and judge_key\n",
    "            and case_key in df_cases.columns\n",
    "            and judge_key in df_judges.columns):\n",
    "        print_section_header(\"Temporary Merge Key for Column Preview\")\n",
    "        logging.info(\"Configured merge keys missing; prompting for temporary keys.\")\n",
    "        display_df_columns(df_cases,  \"Cases Data (temp merge key)\")\n",
    "        case_key = _select_columns_interactive(\n",
    "            list(df_cases.columns),\n",
    "            \"Enter temporary merge key from CASES data\",\n",
    "            is_required=True\n",
    "        )\n",
    "        display_df_columns(df_judges, \"Judges Data (temp merge key)\")\n",
    "        judge_key = _select_columns_interactive(\n",
    "            list(df_judges.columns),\n",
    "            \"Enter temporary merge key from JUDGES data\",\n",
    "            is_required=True\n",
    "        )\n",
    "        temp_keys_used = True\n",
    "        if not (case_key and judge_key\n",
    "                and case_key in df_cases.columns\n",
    "                and judge_key in df_judges.columns):\n",
    "            logging.error(\"Invalid temporary merge keys. Using cases data only.\")\n",
    "            return df_cases.copy()\n",
    "\n",
    "    try:\n",
    "        df_preview = pd.merge(\n",
    "            df_cases,\n",
    "            df_judges,\n",
    "            left_on=str(case_key),\n",
    "            right_on=str(judge_key),\n",
    "            how='left',\n",
    "            suffixes=('_case', '_judge')\n",
    "        )\n",
    "        logging.info(\n",
    "            f\"Pre-merge preview done (keys: {case_key}/{judge_key}, \"\n",
    "            f\"temp_used={temp_keys_used}). Shape: {df_preview.shape}\"\n",
    "        )\n",
    "        return df_preview\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in pre-merge preview: {e}\")\n",
    "        return df_cases.copy()\n",
    "\n",
    "# ==========================\n",
    "# Data Preparation (Full Merge & Preprocessing)\n",
    "# ==========================\n",
    "def full_data_merge(df_cases: pd.DataFrame, df_judges: Optional[pd.DataFrame], config: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"Merges cases and judges data based on configuration captured earlier.\"\"\"\n",
    "    if df_judges is None or 'merge_config' not in config:\n",
    "        logging.info(\"Judges data not available or merge not configured. Using only cases data for pipeline run.\")\n",
    "        return df_cases.copy()\n",
    "    \n",
    "    merge_cfg = config['merge_config']\n",
    "    case_key = str(merge_cfg['cases_link_col'])\n",
    "    judge_key = str(merge_cfg['judges_link_col'])\n",
    "    how_merge = merge_cfg.get('how', 'left')\n",
    "\n",
    "    try:\n",
    "        df_cases_copy = df_cases.copy()\n",
    "        df_judges_copy = df_judges.copy()\n",
    "        df_cases_copy[case_key] = df_cases_copy[case_key].astype(str)\n",
    "        df_judges_copy[judge_key] = df_judges_copy[judge_key].astype(str)\n",
    "\n",
    "        df_merged = pd.merge(\n",
    "            df_cases_copy, df_judges_copy,\n",
    "            left_on=case_key, right_on=judge_key,\n",
    "            how=how_merge, suffixes=('_case', '_judge')\n",
    "        )\n",
    "        logging.info(f\"Pipeline data merge successful. Merged shape: {df_merged.shape}\")\n",
    "        # Further checks for essential columns (target, features, bucketing ID) can be done here or before use.\n",
    "        return df_merged\n",
    "    except KeyError as e:\n",
    "        logging.error(f\"KeyError during pipeline merge: {e}. Check config for merge keys. Using unmerged cases data.\")\n",
    "        return df_cases.copy() # Fallback\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error during pipeline data merge: {e}. Using unmerged cases data.\")\n",
    "        return df_cases.copy() # Fallback\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame, config: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"Applies target mapping and basic feature imputation.\"\"\"\n",
    "    logging.info(\"Starting data preprocessing...\")\n",
    "    df_processed = df.copy()\n",
    "    target_col = config['target_col']\n",
    "    raw_to_numeric_map = config['target_mapping_raw_to_numeric']\n",
    "\n",
    "    # Apply target mapping\n",
    "    if target_col not in df_processed.columns:\n",
    "        logging.error(f\"Target column '{target_col}' not found in DataFrame. Preprocessing cannot continue.\")\n",
    "        raise ValueError(f\"Target column '{target_col}' not found.\")\n",
    "    \n",
    "    df_processed[target_col] = df_processed[target_col].map(raw_to_numeric_map)\n",
    "    \n",
    "    original_rows = len(df_processed)\n",
    "    df_processed.dropna(subset=[target_col], inplace=True) # Drop rows where target is NaN after mapping\n",
    "    rows_dropped = original_rows - len(df_processed)\n",
    "    if rows_dropped > 0:\n",
    "        logging.warning(f\"Dropped {rows_dropped} rows due to unmapped/NaN target values after mapping.\")\n",
    "\n",
    "    # Impute missing values for features\n",
    "    feature_cols = config.get('feature_cols', [])\n",
    "    numerical_features = config.get('numerical_features', [])\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        if df_processed[col].isnull().any():\n",
    "            if col in numerical_features:\n",
    "                fill_value = df_processed[col].median()\n",
    "                df_processed[col].fillna(fill_value, inplace=True)\n",
    "                logging.info(f\"Imputed NaNs in NUMERIC column '{col}' with median ({fill_value:.2f}).\")\n",
    "            else: # Categorical\n",
    "                fill_value = df_processed[col].mode()\n",
    "                if not fill_value.empty:\n",
    "                    fill_value = fill_value[0]\n",
    "                    df_processed[col].fillna(fill_value, inplace=True)\n",
    "                    logging.info(f\"Imputed NaNs in CATEGORICAL column '{col}' with mode ('{fill_value}').\")\n",
    "                else:\n",
    "                    df_processed[col].fillna(\"__MISSING__\", inplace=True) # Fallback if mode is empty\n",
    "                    logging.warning(f\"Column '{col}' had no mode for imputation; filled NaNs with '__MISSING__'.\")\n",
    "    \n",
    "    logging.info(f\"Preprocessing complete. Data shape: {df_processed.shape}\")\n",
    "    return df_processed\n",
    "\n",
    "def get_feature_transformer(config: Dict[str, Any]) -> ColumnTransformer:\n",
    "    \"\"\"Creates a ColumnTransformer for scaling numerical and encoding categorical features.\"\"\"\n",
    "    numerical_features = config.get('numerical_features', [])\n",
    "    categorical_features = config.get('categorical_features', [])\n",
    "    \n",
    "    transformers = []\n",
    "    if numerical_features:\n",
    "        transformers.append(('num', StandardScaler(), numerical_features))\n",
    "    if categorical_features:\n",
    "        transformers.append(('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features))\n",
    "    \n",
    "    if not transformers: # No features to transform, passthrough all\n",
    "        return ColumnTransformer(transformers=[], remainder='passthrough')\n",
    "        \n",
    "    # remainder='drop' (default) or 'passthrough'. If 'passthrough', non-specified cols are kept.\n",
    "    # For feature selection, 'drop' is safer unless passthrough columns are explicitly handled.\n",
    "    # Let's use 'passthrough' for now and ensure only feature_cols are used.\n",
    "    preprocessor = ColumnTransformer(transformers=transformers, remainder='passthrough', verbose_feature_names_out=False)\n",
    "    logging.info(\"Feature transformer (preprocessor) created.\")\n",
    "    return preprocessor\n",
    "\n",
    "# ==========================\n",
    "# Judge Bucketing\n",
    "# ==========================\n",
    "def create_judge_buckets(df: pd.DataFrame, config: Dict[str, Any]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"Creates judge-specific data buckets and a generic bucket.\"\"\"\n",
    "    if not config.get('use_judge_bucketing', False) or not config.get('judge_id_col_final_bucketing'):\n",
    "        logging.info(\"Judge bucketing not enabled or no final judge ID column. Using one 'generic' bucket.\")\n",
    "        return {'generic': df.copy()}\n",
    "\n",
    "    judge_col = str(config['judge_id_col_final_bucketing'])\n",
    "    min_samples = config.get('min_samples_per_judge_bucket', 30)\n",
    "    \n",
    "    if judge_col not in df.columns:\n",
    "        logging.warning(f\"Judge column '{judge_col}' for bucketing not found. Using one 'generic' bucket.\")\n",
    "        return {'generic': df.copy()}\n",
    "\n",
    "    judge_counts = df[judge_col].value_counts()\n",
    "    judge_buckets: Dict[str, pd.DataFrame] = {}\n",
    "    generic_bucket_list: List[pd.DataFrame] = []\n",
    "\n",
    "    for judge_id_val, count in judge_counts.items():\n",
    "        judge_id_str = str(judge_id_val) # Ensure string key\n",
    "        judge_df = df[df[judge_col] == judge_id_val].copy() # Use original value for filtering\n",
    "        if count >= min_samples:\n",
    "            judge_buckets[judge_id_str] = judge_df\n",
    "            logging.info(f\"Created bucket for judge '{judge_id_str}' with {count} samples.\")\n",
    "        else:\n",
    "            generic_bucket_list.append(judge_df)\n",
    "            logging.info(f\"Judge '{judge_id_str}' with {count} samples added to generic bucket.\")\n",
    "    \n",
    "    if generic_bucket_list:\n",
    "        df_generic = pd.concat(generic_bucket_list, ignore_index=True)\n",
    "        if not df_generic.empty:\n",
    "            judge_buckets['generic'] = df_generic\n",
    "            logging.info(f\"Generic bucket created with {len(df_generic)} samples from {len(generic_bucket_list)} judges/groups.\")\n",
    "    elif not judge_buckets: # No specific buckets and no generic data (e.g. all judges too small and no generic created)\n",
    "        logging.warning(\"No specific judge buckets created and no data for generic bucket. All data might be in one implicit 'generic' bucket if bucketing failed.\")\n",
    "        return {'generic': df.copy()} # Fallback\n",
    "\n",
    "    if not judge_buckets: # If still empty after all logic\n",
    "        logging.warning(\"No buckets could be created. Returning all data in a single 'generic' bucket.\")\n",
    "        return {'generic': df.copy()}\n",
    "        \n",
    "    return judge_buckets\n",
    "\n",
    "# ==========================\n",
    "# Data Balancing \n",
    "# ==========================\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def print_class_distribution(\n",
    "    y_or_counter: Union[pd.Series, Counter],\n",
    "    context_message: str = \"\"\n",
    ") -> Counter:\n",
    "    \"\"\"\n",
    "    Accepts a pandas Series of class labels OR an already-computed Counter.\n",
    "    Prints counts and percentages; returns the Counter.\n",
    "    \"\"\"\n",
    "    if isinstance(y_or_counter, Counter):\n",
    "        counts = y_or_counter\n",
    "    else:\n",
    "        counts = Counter(y_or_counter)\n",
    "\n",
    "    total = sum(counts.values())\n",
    "    table = [\n",
    "        [TARGET_CLASS_NAMES[c], counts.get(c, 0),\n",
    "         f\"{100.0 * counts.get(c, 0) / total:6.2f} %\"]  # pct column\n",
    "        for c in CLASS_LABELS_NUMERIC\n",
    "    ]\n",
    "\n",
    "    if context_message:\n",
    "        print(f\"\\n{context_message}\")\n",
    "\n",
    "    print(tabulate(table, headers=[\"Class\", \"Count\", \"%\"], tablefmt=\"pretty\"))\n",
    "    return counts\n",
    "\n",
    "def _determine_auto_sampling_targets(current_counts: Counter, config: Dict[str, Any]) -> Dict[int, int]:\n",
    "    \"\"\"Calculates target sample counts for 'auto' sampling (two-stage).\"\"\"\n",
    "    N0_orig, N1_orig, N2_orig = current_counts.get(0,0), current_counts.get(1,0), current_counts.get(2,0)\n",
    "    r10_target = config.get('sampling_target_ratio_1_vs_0', 1.0)\n",
    "    r2_01_target = config.get('sampling_target_ratio_2_vs_01', 0.5)\n",
    "    \n",
    "    logging.info(f\"Auto-sampling: Initial counts N0={N0_orig}, N1={N1_orig}, N2={N2_orig}\")\n",
    "    logging.info(f\"Auto-sampling: Target R1/R0={r10_target}, Target R2/(R0+R1)={r2_01_target}\")\n",
    "\n",
    "    N0_inter, N1_inter = N0_orig, N1_orig\n",
    "\n",
    "    # Stage 1: Balance Class 0 (mother) and Class 1 (father)\n",
    "    if N0_orig == 0 and N1_orig > 0 and r10_target > 0:\n",
    "        logging.warning(\"Auto-sampling Stage 1: Class 0 is empty, cannot use as reference for Class 1. Class 1 count remains unchanged.\")\n",
    "    elif N0_orig > 0 : # N0_orig is not 0\n",
    "        current_r10 = N1_orig / N0_orig\n",
    "        delta_samples_total_stage1 = abs(N1_orig - (N0_orig * r10_target)) # Simplified delta idea\n",
    "        \n",
    "        # This logic aims to meet N1_inter / N0_inter = r10_target\n",
    "        # by adjusting N0_inter and N1_inter by delta/2 each.\n",
    "        # (N1_orig + d) / (N0_orig - d) = r10_target  => N1_orig + d = r10_target * N0_orig - r10_target * d\n",
    "        # d * (1 + r10_target) = r10_target * N0_orig - N1_orig\n",
    "        # d = (r10_target * N0_orig - N1_orig) / (1 + r10_target)\n",
    "        # d is the amount to ADD to N1 and SUBTRACT from N0.\n",
    "        if (1 + r10_target) == 0: # Avoid division by zero\n",
    "            d1 = 0\n",
    "        else:\n",
    "            d1 = (r10_target * N0_orig - N1_orig) / (1 + r10_target)\n",
    "        \n",
    "        N0_inter = round(N0_orig - d1)\n",
    "        N1_inter = round(N1_orig + d1)\n",
    "    \n",
    "    # Ensure non-negative and preserve original zeros\n",
    "    N0_inter = max(0, N0_inter) if N0_orig > 0 else 0\n",
    "    N1_inter = max(0, N1_inter) if N1_orig > 0 else 0\n",
    "    logging.info(f\"Auto-sampling Stage 1: Intermediate counts N0_inter={N0_inter}, N1_inter={N1_inter}\")\n",
    "\n",
    "    # Stage 2: Balance Class 2 (shared) against (N0_inter + N1_inter)\n",
    "    N01_inter_sum = N0_inter + N1_inter\n",
    "    N2_final = N2_orig # Start with original N2\n",
    "\n",
    "    if N01_inter_sum == 0 and N2_orig > 0 and r2_01_target > 0:\n",
    "        logging.warning(\"Auto-sampling Stage 2: Sum of (Class 0 + Class 1) is zero. Cannot use as reference for Class 2. Class 2 count remains unchanged.\")\n",
    "    elif N01_inter_sum > 0:\n",
    "        # (N2_orig + d) / (N01_inter_sum - d) = r2_01_target\n",
    "        # d = (r2_01_target * N01_inter_sum - N2_orig) / (1 + r2_01_target)\n",
    "        # d is amount to ADD to N2 and SUBTRACT from N01_inter_sum\n",
    "        if (1 + r2_01_target) == 0:\n",
    "            d2 = 0\n",
    "        else:\n",
    "            d2 = (r2_01_target * N01_inter_sum - N2_orig) / (1 + r2_01_target)\n",
    "        \n",
    "        N2_final = round(N2_orig + d2)\n",
    "        N01_sum_final = round(N01_inter_sum - d2)\n",
    "\n",
    "        # Distribute change in N01_sum_final back to N0 and N1 proportionally\n",
    "        N0_final, N1_final = N0_inter, N1_inter # Start with intermediate values\n",
    "        if N01_inter_sum > 0 and N01_sum_final != N01_inter_sum : # If there was a change to the sum\n",
    "            prop0 = N0_inter / N01_inter_sum if N01_inter_sum > 0 else 0\n",
    "            prop1 = N1_inter / N01_inter_sum if N01_inter_sum > 0 else 0\n",
    "            N0_final = round(N01_sum_final * prop0)\n",
    "            N1_final = round(N01_sum_final * prop1)\n",
    "            # Adjust for rounding to ensure sum matches N01_sum_final\n",
    "            if N0_final + N1_final != N01_sum_final:\n",
    "                if N0_orig >= N1_orig: N0_final = N01_sum_final - N1_final\n",
    "                else: N1_final = N01_sum_final - N0_final\n",
    "        else: # No change to N01_sum or it was zero\n",
    "            N0_final, N1_final = N0_inter, N1_inter\n",
    "    else: # N01_inter_sum is 0\n",
    "        N0_final, N1_final = N0_inter, N1_inter # Which are likely 0\n",
    "\n",
    "    # Ensure non-negative and preserve original zeros\n",
    "    target_counts = {\n",
    "        0: max(0, N0_final) if N0_orig > 0 else 0,\n",
    "        1: max(0, N1_final) if N1_orig > 0 else 0,\n",
    "        2: max(0, N2_final) if N2_orig > 0 else 0,\n",
    "    }\n",
    "    \n",
    "    # Sanity check: prevent reduction to 0 if class existed, unless user confirms (not interactive here)\n",
    "    # For now, if a class had samples, ensure it has at least 1 after auto-sampling if target became 0\n",
    "    for cls_idx in [0,1,2]:\n",
    "        if current_counts.get(cls_idx, 0) > 0 and target_counts[cls_idx] == 0:\n",
    "            logging.warning(f\"Auto-sampling for class {TARGET_CLASS_NAMES[cls_idx]} resulted in 0 samples (was {current_counts.get(cls_idx,0)}). Setting target to 1 to preserve class.\")\n",
    "            target_counts[cls_idx] = 1\n",
    "            \n",
    "    logging.info(f\"Auto-sampling Final Targets: N0={target_counts[0]}, N1={target_counts[1]}, N2={target_counts[2]}\")\n",
    "    return target_counts\n",
    "\n",
    "def _prompt_manual_sampling_targets(current_counts: Counter, bucket_name: str) -> Dict[int, int]:\n",
    "    \"\"\"Prompts user for manual target sample counts per class for a bucket.\"\"\"\n",
    "    print_section_header(f\"Manual Sampling Configuration for Bucket: {bucket_name}\")\n",
    "    print_class_distribution(pd.Series(dict(current_counts)), f\"Current distribution for {bucket_name}\") # pd.Series for print_class_distribution\n",
    "    \n",
    "    target_counts: Dict[int, int] = {}\n",
    "    for cls_numeric, cls_name in enumerate(TARGET_CLASS_NAMES):\n",
    "        default_val = current_counts.get(cls_numeric, 0)\n",
    "        target_counts[cls_numeric] = int(safe_input(\n",
    "            f\"  Enter target #samples for Class {cls_numeric} ({cls_name})\",\n",
    "            default=default_val, type_caster=int\n",
    "        ))\n",
    "    logging.info(f\"Manual sampling for {bucket_name}: Target counts {target_counts}\")\n",
    "    return target_counts\n",
    "\n",
    "def _apply_imblearn_sampling(X: pd.DataFrame, y: pd.Series, target_counts: Dict[int, int]) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Applies imblearn over/under sampling to reach target_counts.\"\"\"\n",
    "    if X.empty or y.empty:\n",
    "        logging.warning(\"Skipping imblearn sampling for empty X or y.\")\n",
    "        return X, y\n",
    "    if RandomOverSampler is None or RandomUnderSampler is None:\n",
    "        logging.error(\"imbalanced-learn is not installed. Cannot perform sampling.\")\n",
    "        return X, y\n",
    "\n",
    "    current_counts = Counter(y)\n",
    "    X_resampled, y_resampled = X.copy(), y.copy()\n",
    "\n",
    "    # Strategy:\n",
    "    # 1. Undersample classes where current_count > target_count\n",
    "    # 2. Oversample classes where current_count_after_under < target_count\n",
    "\n",
    "    # Undersampling\n",
    "    under_targets = {cls: count for cls, count in target_counts.items() if cls in current_counts and current_counts[cls] > count and count > 0}\n",
    "    if under_targets:\n",
    "        try:\n",
    "            # Ensure target counts for undersampling are not less than 1 if original class exists\n",
    "            safe_under_targets = {k: max(1, v) for k,v in under_targets.items()}\n",
    "            under_sampler = RandomUnderSampler(sampling_strategy=safe_under_targets, random_state=RANDOM_STATE)\n",
    "            X_resampled, y_resampled = under_sampler.fit_resample(X_resampled, y_resampled)\n",
    "            logging.info(f\"Applied undersampling. New distribution: {Counter(y_resampled)}\")\n",
    "        except ValueError as e:\n",
    "            logging.warning(f\"Undersampling failed: {e}. Proceeding with data before undersampling for oversampling step.\")\n",
    "            X_resampled, y_resampled = X.copy(), y.copy() # Reset to before this attempt\n",
    "\n",
    "    current_counts_after_under = Counter(y_resampled)\n",
    "\n",
    "    # Oversampling\n",
    "    # Oversample if target is > current (after under), and target > 0, and original class existed or target > 0\n",
    "    over_targets = {\n",
    "        cls: count for cls, count in target_counts.items() \n",
    "        if count > 0 and # Target must be positive\n",
    "           ( (cls in current_counts_after_under and current_counts_after_under[cls] < count) or \\\n",
    "             (cls not in current_counts_after_under and current_counts.get(cls,0) > 0) ) # Class existed originally but might have been removed by undersampling\n",
    "    }\n",
    "    \n",
    "    # Ensure over_targets only targets classes that originally existed if they are not in current_counts_after_under\n",
    "    # And ensure that for classes present, the target is greater than current.\n",
    "    final_over_targets = {}\n",
    "    for cls, target_count in over_targets.items():\n",
    "        if current_counts.get(cls, 0) == 0 and target_count > 0: # Trying to create a new class\n",
    "            logging.warning(f\"Cannot oversample class {cls} as it had 0 samples originally. Skipping oversample for this class.\")\n",
    "            continue\n",
    "        current_val_for_over = current_counts_after_under.get(cls,0)\n",
    "        if target_count > current_val_for_over:\n",
    "             final_over_targets[cls] = target_count\n",
    "\n",
    "    if final_over_targets:\n",
    "        try:\n",
    "            over_sampler = RandomOverSampler(sampling_strategy=final_over_targets, random_state=RANDOM_STATE)\n",
    "            X_resampled, y_resampled = over_sampler.fit_resample(X_resampled, y_resampled)\n",
    "            logging.info(f\"Applied oversampling. Final distribution: {Counter(y_resampled)}\")\n",
    "        except ValueError as e:\n",
    "            logging.warning(f\"Oversampling failed: {e}. Using data after any undersampling.\")\n",
    "            # Data is already X_resampled, y_resampled from undersampling stage or original\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def _calculate_class_weights(y_series: pd.Series, config: Dict[str, Any]) -> Optional[Dict[int, float]]:\n",
    "    \"\"\"Calculates class weights based on target ratios relative to class 0.\"\"\"\n",
    "    counts = Counter(y_series)\n",
    "    N0, N1, N2 = counts.get(0,0), counts.get(1,0), counts.get(2,0)\n",
    "    \n",
    "    r10_target_weight = config.get('weighting_target_ratio_1_vs_0', 1.0)\n",
    "    r20_target_weight = config.get('weighting_target_ratio_2_vs_0', 1.0)\n",
    "    \n",
    "    class_weights = {0: 1.0, 1: 1.0, 2: 1.0} # Default\n",
    "\n",
    "    if N0 > 0:\n",
    "        if N1 > 0:\n",
    "            class_weights[1] = (N0 / N1) * r10_target_weight\n",
    "        elif r10_target_weight > 0 : # N1 is 0, but target wants it to have weight\n",
    "            class_weights[1] = 100.0 # Assign a large weight as a heuristic\n",
    "            logging.warning(f\"Class {TARGET_CLASS_NAMES[1]} has 0 samples, but weighting target ratio > 0. Assigning large weight.\")\n",
    "\n",
    "        if N2 > 0:\n",
    "            class_weights[2] = (N0 / N2) * r20_target_weight\n",
    "        elif r20_target_weight > 0: # N2 is 0\n",
    "            class_weights[2] = 100.0\n",
    "            logging.warning(f\"Class {TARGET_CLASS_NAMES[2]} has 0 samples, but weighting target ratio > 0. Assigning large weight.\")\n",
    "    else:\n",
    "        logging.warning(\"Class 0 (mother) has 0 samples. Cannot compute ratio-based class weights. Using default weights [1,1,1].\")\n",
    "        # Or could try sklearn's 'balanced' string for models that support it.\n",
    "        # For custom weights, this is tricky. Defaulting to 1.0 for all.\n",
    "        return None # Indicate that custom weights couldn't be effectively computed\n",
    "\n",
    "    logging.info(f\"Calculated class weights for model: {class_weights}\")\n",
    "    return class_weights\n",
    "\n",
    "def balance_data_for_fold(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    cfg: Dict[str, Any],\n",
    "    *,\n",
    "    tag: str = \"\",\n",
    "    verbose: bool = True\n",
    ") -> Tuple[pd.DataFrame, pd.Series, Optional[np.ndarray], Counter, Counter]:\n",
    "    \"\"\"\n",
    "    Balances a fold according to cfg['balancing_method'] and returns:\n",
    "        X_bal, y_bal, sample_weight (or None), Counter_before, Counter_after\n",
    "\n",
    "    If verbose=True, prints BEFORE and AFTER distributions (counts + %).\n",
    "    \"\"\"\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # BEFORE\n",
    "    # ------------------------------------------------------------------ #\n",
    "    before_cnt = Counter(y)\n",
    "    if verbose:\n",
    "        print_class_distribution(before_cnt, f\"{tag}  BEFORE\")\n",
    "\n",
    "    method = cfg[\"balancing_method\"]\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # NONE    no changes\n",
    "    # ------------------------------------------------------------------ #\n",
    "    if method == \"none\":\n",
    "        after_cnt = before_cnt  # unchanged\n",
    "        if verbose:\n",
    "            print_class_distribution(after_cnt, f\"{tag}  AFTER (no change)\")\n",
    "        return X, y, None, before_cnt, after_cnt\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # WEIGHTING    compute sample_weight, no resampling\n",
    "    # ------------------------------------------------------------------ #\n",
    "    if method == \"weighting\":\n",
    "        ratios = cfg[\"class_weight_ratios\"]\n",
    "        sample_w = y.map(ratios).to_numpy(dtype=float)\n",
    "        after_cnt = before_cnt  # distribution unchanged\n",
    "        if verbose:\n",
    "            print_class_distribution(after_cnt, f\"{tag}  AFTER (weighted)\")\n",
    "        return X, y, sample_w, before_cnt, after_cnt\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # SAMPLING    under-/over-sample to hit target percentages\n",
    "    # ------------------------------------------------------------------ #\n",
    "    target_pct = cfg[\"sampling_target_percentages\"]\n",
    "\n",
    "    # desired counts given the current total size\n",
    "    total_after = len(y)\n",
    "    target_counts = {\n",
    "        cls: int(round(total_after * target_pct[cls] / 100.0))\n",
    "        for cls in CLASS_LABELS_NUMERIC\n",
    "    }\n",
    "\n",
    "    # -- UNDER-sample classes above target ------------------------------\n",
    "    to_under = {cls: cnt for cls, cnt in before_cnt.items()\n",
    "                if cnt > target_counts.get(cls, cnt)}\n",
    "    if to_under:\n",
    "        rus = RandomUnderSampler(\n",
    "            sampling_strategy={cls: target_counts[cls] for cls in to_under},\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        X, y = rus.fit_resample(X, y)\n",
    "\n",
    "    # -- OVER-sample classes below target -------------------------------\n",
    "    after_under_cnt = Counter(y)\n",
    "    to_over = {cls: target_counts[cls] for cls in CLASS_LABELS_NUMERIC\n",
    "               if after_under_cnt.get(cls, 0) < target_counts[cls]}\n",
    "    if to_over:\n",
    "        ros = RandomOverSampler(\n",
    "            sampling_strategy=to_over,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "        X, y = ros.fit_resample(X, y)\n",
    "\n",
    "    after_cnt = Counter(y)\n",
    "    if verbose:\n",
    "        print_class_distribution(after_cnt, f\"{tag}  AFTER (sampled)\")\n",
    "\n",
    "    return X, y, None, before_cnt, after_cnt\n",
    "\n",
    "# ==========================\n",
    "# Model Training and Evaluation\n",
    "# ==========================\n",
    "\n",
    "def get_feature_importances(model, feature_names: List[str]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Returns a pd.Series indexed by feature name.\n",
    "    Works for tree models, linear coef_, etc.\n",
    "    \"\"\"\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        imp = model.feature_importances_\n",
    "    elif hasattr(model, \"coef_\"):\n",
    "        coef = model.coef_\n",
    "        # handle binary vs multinomial\n",
    "        if coef.ndim == 1:\n",
    "            imp = np.abs(coef)\n",
    "        else:\n",
    "            imp = np.abs(coef).mean(axis=0)\n",
    "    else:\n",
    "        logging.warning(\"Model has no native feature importance; \"\n",
    "                        \"returning zeros.\")\n",
    "        imp = np.zeros(len(feature_names))\n",
    "    return pd.Series(imp, index=feature_names)\n",
    "\n",
    "def get_model_instance(model_name: str,\n",
    "                       model_params: Optional[Dict] = None,\n",
    "                       random_state: int = RANDOM_STATE) -> Any:\n",
    "    \"\"\"\n",
    "    Returns a fresh model instance for the given shorthand.\n",
    "    \"\"\"\n",
    "    model_params = model_params or {}\n",
    "    name = model_name.lower()\n",
    "\n",
    "    if name in {\"rf\", \"randomforest\", \"randomforestclassifier\"}:\n",
    "        return RandomForestClassifier(random_state=random_state, **model_params)\n",
    "\n",
    "    if name in {\"lr\", \"logreg\", \"logisticregression\"}:\n",
    "        return LogisticRegression(\n",
    "            random_state=random_state,\n",
    "            max_iter=1000,\n",
    "            n_jobs=-1,\n",
    "            **model_params\n",
    "        )\n",
    "\n",
    "    if name in {\"svc\", \"svm\"}:\n",
    "        return SVC(probability=True, random_state=random_state, **model_params)\n",
    "\n",
    "    if name in {\"xgb\", \"xgboost\", \"xgbclassifier\"}:\n",
    "        return XGBClassifier(\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "            objective=\"multi:softprob\",\n",
    "            eval_metric=\"mlogloss\",\n",
    "            **model_params\n",
    "        )\n",
    "\n",
    "    raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "def tune_hyperparameters(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    model_name: str,\n",
    "    param_distributions: Dict[str, Any],\n",
    "    *,\n",
    "    cv_folds_inner: int,\n",
    "    n_iter: int,\n",
    "    sample_weight_train: Optional[np.ndarray] = None,\n",
    ") -> Tuple[Any, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    RandomizedSearchCV wrapper that returns (best_estimator, best_params).\n",
    "    \"\"\"\n",
    "    mdl = get_model_instance(model_name)\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator=mdl,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv_folds_inner,\n",
    "        scoring=\"f1_macro\",\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "    rs.fit(X, y, sample_weight=sample_weight_train)\n",
    "    return rs.best_estimator_, rs.best_params_\n",
    "\n",
    "\n",
    "def evaluate_model_on_test_set(\n",
    "    model: Any, X_test: pd.DataFrame, y_test: pd.Series, \n",
    "    class_labels_numeric: List[int] = CLASS_LABELS_NUMERIC\n",
    ") -> Tuple[Dict[str, Any], np.ndarray]:\n",
    "    \"\"\"Evaluates the model and returns metrics and confusion matrix.\"\"\"\n",
    "    if X_test.empty or y_test.empty:\n",
    "        logging.warning(\"Skipping evaluation due to empty X_test or y_test.\")\n",
    "        return {}, np.array([])\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    metrics: Dict[str, Any] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'per_class': {},\n",
    "        'auc_macro_ovr': np.nan # Initialize\n",
    "    }\n",
    "    \n",
    "    # Precision, Recall, F1 (per-class and macro)\n",
    "    # Ensure labels parameter matches the unique values in y_test for calculation, but report for all expected classes\n",
    "    # unique_y_test_labels = sorted(y_test.unique())\n",
    "    # if not all(l in class_labels_numeric for l in unique_y_test_labels):\n",
    "    #     logging.warning(f\"y_test contains labels not in predefined class_labels_numeric. Metrics might be affected. y_test labels: {unique_y_test_labels}\")\n",
    "\n",
    "    # Use predefined class_labels_numeric for consistent reporting structure\n",
    "    # zero_division=0 avoids warnings and returns 0 for metrics where division by zero occurs\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, labels=class_labels_numeric, average=None, zero_division=0)\n",
    "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(y_test, y_pred, labels=class_labels_numeric, average='macro', zero_division=0)\n",
    "\n",
    "    metrics['macro_precision'] = macro_precision\n",
    "    metrics['macro_recall'] = macro_recall\n",
    "    metrics['macro_f1'] = macro_f1\n",
    "\n",
    "    for i, label_num in enumerate(class_labels_numeric):\n",
    "        metrics['per_class'][label_num] = {\n",
    "            'precision': precision[i],\n",
    "            'recall': recall[i],\n",
    "            'f1_score': f1[i],\n",
    "            'auc_ovr': np.nan # Initialize\n",
    "        }\n",
    "\n",
    "    # AUC\n",
    "    if y_proba is not None and y_test.nunique() > 1:\n",
    "        try:\n",
    "            # Ensure y_proba has correct shape for multi_class='ovr' (n_samples, n_classes)\n",
    "            if y_proba.ndim == 1: # If predict_proba returns 1D array (e.g. for binary case by some models)\n",
    "                 if len(class_labels_numeric) == 2: y_proba = np.vstack([1 - y_proba, y_proba]).T\n",
    "                 else: logging.warning(f\"1D y_proba for {len(class_labels_numeric)}-class problem. AUC might be incorrect.\"); y_proba = None\n",
    "\n",
    "            if y_proba is not None and y_proba.shape[1] == len(class_labels_numeric):\n",
    "                auc_scores_ovr = roc_auc_score(y_test, y_proba, multi_class='ovr', average=None, labels=class_labels_numeric)\n",
    "                metrics['auc_macro_ovr'] = roc_auc_score(y_test, y_proba, multi_class='ovr', average='macro', labels=class_labels_numeric)\n",
    "                for i, label_num in enumerate(class_labels_numeric):\n",
    "                    metrics['per_class'][label_num]['auc_ovr'] = auc_scores_ovr[i]\n",
    "            else:\n",
    "                logging.warning(f\"y_proba shape mismatch for AUC calculation. Expected {len(class_labels_numeric)} columns, got {y_proba.shape[1] if y_proba is not None else 'None'}.\")\n",
    "        except ValueError as e_auc:\n",
    "            logging.warning(f\"Could not calculate ROC AUC: {e_auc}. y_test unique: {y_test.unique().tolist()}\")\n",
    "    \n",
    "    cm_array = confusion_matrix(y_test, y_pred, labels=class_labels_numeric)\n",
    "    return metrics, cm_array\n",
    "\n",
    "# ==========================\n",
    "# Results Export\n",
    "# ==========================\n",
    "\n",
    "# =============================================================\n",
    "#  Model Persistence Utilities\n",
    "#  (NEW  place e.g. in util_io.py or wherever helpers live)\n",
    "# =============================================================\n",
    "import copy\n",
    "import joblib\n",
    "from datetime import datetime as dt\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "\n",
    "def export_model_bundle(\n",
    "    model: Any,\n",
    "    fitted_transformer: Any,\n",
    "    meta: Dict[str, Any],\n",
    "    save_path: Path,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Serialises the trained model **together with** its fitted transformer\n",
    "    (and some lightweight metadata) so that the bundle can be re-loaded and\n",
    "    used for single-case predictions in any Python app.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn-compatible estimator\n",
    "    fitted_transformer : ColumnTransformer or Pipeline  must already be .fit()\n",
    "    meta : dict\n",
    "        Arbitrary information you want to save (bucket_id, model_name, etc.).\n",
    "    save_path : pathlib.Path\n",
    "        Full filename ('.joblib' recommended). Directories will be created.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pathlib.Path  the actual path written to disk.\n",
    "    \"\"\"\n",
    "    import logging, os\n",
    "\n",
    "    # 1. Deep-copy the transformer so subsequent .fit() calls in the main loop\n",
    "    #    do NOT mutate the object stored on disk.\n",
    "    transformer_copy = copy.deepcopy(fitted_transformer)\n",
    "\n",
    "    # 2. Build the bundle\n",
    "    bundle = {\n",
    "        \"model\": model,\n",
    "        \"transformer\": transformer_copy,\n",
    "        \"meta\": {\n",
    "            \"saved_at\": dt.now().isoformat(timespec=\"seconds\"),\n",
    "            **meta,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # 3. Make sure the directory exists\n",
    "    os.makedirs(save_path.parent, exist_ok=True)\n",
    "\n",
    "    # 4. Dump with joblib\n",
    "    joblib.dump(bundle, save_path)\n",
    "    logging.info(f\"Model bundle exported to {save_path}\")\n",
    "\n",
    "    return save_path\n",
    "\n",
    "\n",
    "def load_model_bundle(bundle_path: Path) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Quick convenience wrapper for `joblib.load`.\n",
    "\n",
    "    Returns the dict created by `export_model_bundle`.\n",
    "    Keys: 'model', 'transformer', 'meta'\n",
    "    \"\"\"\n",
    "    import joblib, logging\n",
    "\n",
    "    loaded = joblib.load(bundle_path)\n",
    "    logging.info(f\"Model bundle loaded from {bundle_path}\")\n",
    "    return loaded\n",
    "\n",
    "# =============================================================\n",
    "#  Cross-Bucket / Cross-Model Evaluation\n",
    "#  (NEW)\n",
    "# =============================================================\n",
    "from collections import defaultdict\n",
    "from typing import Any, Dict, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "def cross_compare_models(\n",
    "    model_bundles: Dict[Tuple[str, str], Dict[str, Any]],\n",
    "    test_sets: Dict[str, Tuple[pd.DataFrame, pd.Series]],\n",
    "    out_dir: Path,\n",
    ") -> Tuple[List[Dict[str, Any]], List[pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Evaluates every trained model (source bucket  model name)\n",
    "    on **every** available held-out test set (target bucket).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_bundles : dict\n",
    "        Key = (src_bucket_id, model_name)  \n",
    "        Value = dict with at least keys { 'model', 'transformer' }\n",
    "        (i.e. exactly what `export_model_bundle` returns, but kept in-memory).\n",
    "    test_sets : dict\n",
    "        Key = target_bucket_id  \n",
    "        Value = (X_test_raw, y_test)   **un-transformed** dataframes/series.\n",
    "    out_dir : pathlib.Path\n",
    "        Root experiment directory  confusion-matrix PNGs will be placed\n",
    "        in `<out_dir>/<CM_SUBDIR_NAME>/`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cross_metrics_rows : list[dict]\n",
    "        One flat dict per (src_model, target_test_set) combination.\n",
    "    cross_cm_tables    : list[pd.DataFrame]\n",
    "        Each DF is the flattened confusion matrix, augmented with identifiers.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure CM directory exists\n",
    "    cm_dir = out_dir / CM_SUBDIR_NAME\n",
    "    cm_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    cross_metrics_rows: List[Dict[str, Any]] = []\n",
    "    cross_cm_tables:  List[pd.DataFrame]      = []\n",
    "\n",
    "    total_evals = len(model_bundles) * len(test_sets)\n",
    "    logging.info(f\"Cross-evaluation: {total_evals} modeltest combinations.\")\n",
    "    print_section_header(\"CROSS-BUCKET EVALUATION\")\n",
    "\n",
    "    # \n",
    "    for (src_bucket, model_name), bundle in model_bundles.items():\n",
    "        model       = bundle[\"model\"]\n",
    "        transformer = bundle[\"transformer\"]\n",
    "\n",
    "        for tgt_bucket, (X_tgt_raw, y_tgt) in test_sets.items():\n",
    "            tag = f\"{src_bucket}/{model_name}  {tgt_bucket}\"\n",
    "            print(f\"   {tag}\")\n",
    "\n",
    "            # 1. Transform with *that model's* fitted transformer\n",
    "            try:\n",
    "                X_tgt = pd.DataFrame(\n",
    "                    transformer.transform(X_tgt_raw),\n",
    "                    columns=transformer.get_feature_names_out(),\n",
    "                    index=X_tgt_raw.index,\n",
    "                )\n",
    "            except Exception as e_tr:\n",
    "                logging.error(f\"Transformer failure for {tag}: {e_tr}\")\n",
    "                continue  # skip to next pair\n",
    "\n",
    "            # 2. Evaluate\n",
    "            metrics, cm = evaluate_model_on_test_set(model, X_tgt, y_tgt)\n",
    "\n",
    "            # 3. Store metrics\n",
    "            row = {\n",
    "                \"ModelBucket\": src_bucket,\n",
    "                \"Model\":       model_name,\n",
    "                \"TestBucket\":  tgt_bucket,\n",
    "                **metrics,\n",
    "            }\n",
    "            cross_metrics_rows.append(row)\n",
    "\n",
    "            # 4. Confusion matrix  save PNG & DF\n",
    "            if cm.size:\n",
    "                cm_png = cm_dir / f\"{src_bucket}_{model_name}_ON_{tgt_bucket}.png\"\n",
    "                save_cm_png(cm, TARGET_CLASS_NAMES, tag, cm_png)\n",
    "\n",
    "                cm_df = cm_to_dataframe(cm, TARGET_CLASS_NAMES)\n",
    "                cm_df[\"ModelBucket\"] = src_bucket\n",
    "                cm_df[\"Model\"]       = model_name\n",
    "                cm_df[\"TestBucket\"]  = tgt_bucket\n",
    "                cross_cm_tables.append(cm_df)\n",
    "\n",
    "    print(f\"Completed cross-evaluation for {len(cross_metrics_rows)} combinations.\")\n",
    "    logging.info(\"Cross-bucket evaluation finished.\")\n",
    "\n",
    "    return cross_metrics_rows, cross_cm_tables\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# CONFUSION-MATRIX HELPERS\n",
    "# -----------------------------------------------------------------\n",
    "def save_cm_png(cm: np.ndarray, labels: List[str], title: str, out_path: Path) -> None:\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "                xticklabels=labels, yticklabels=labels,\n",
    "                cmap=\"Blues\", cbar=False)\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\"); plt.title(title)\n",
    "    plt.tight_layout(); out_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "    plt.savefig(out_path, dpi=150); plt.close()\n",
    "\n",
    "def cm_to_dataframe(cm: np.ndarray, labels: List[str]) -> pd.DataFrame:\n",
    "    return pd.DataFrame(cm, index=[f\"Actual_{l}\" for l in labels],\n",
    "                           columns=[f\"Pred_{l}\" for l in labels])\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# CLASS-DISTRIBUTION  tidy DataFrame   (for nice XLSX export)\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "def distribution_to_rows(\n",
    "    counter: Counter,\n",
    "    bucket: str,\n",
    "    subset: str\n",
    ") -> List[Dict[str, Any]]:\n",
    "    total = sum(counter.values())\n",
    "    rows = []\n",
    "    for cls in CLASS_LABELS_NUMERIC:\n",
    "        rows.append({\n",
    "            \"Bucket\"     : bucket,\n",
    "            \"Subset\"     : subset,\n",
    "            \"Class\"      : TARGET_CLASS_NAMES[cls],\n",
    "            \"Count\"      : counter.get(cls, 0),\n",
    "            \"Percent\"    : 100.0 * counter.get(cls, 0) / total if total else 0.0,\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def export_class_distributions_xlsx(writer: pd.ExcelWriter, global_dist: Optional[Counter], per_bucket_dist: Dict[str, Counter]) -> None:\n",
    "    \"\"\"Exports global and per-bucket class distributions to Excel.\"\"\"\n",
    "    if global_dist:\n",
    "        global_data = [[TARGET_CLASS_NAMES[cls], count] for cls, count in sorted(global_dist.items())]\n",
    "        df_global = pd.DataFrame(global_data, columns=['Class', 'Count'])\n",
    "        df_global.to_excel(writer, sheet_name='Global Class Distribution', index=False)\n",
    "\n",
    "    bucket_data_list = []\n",
    "    for bucket_id, dist_counter in per_bucket_dist.items():\n",
    "        for cls_numeric, count in sorted(dist_counter.items()):\n",
    "            bucket_data_list.append({\n",
    "                'Bucket ID': bucket_id, \n",
    "                'Class Name': TARGET_CLASS_NAMES[cls_numeric],\n",
    "                'Class Numeric': cls_numeric,\n",
    "                'Count': count\n",
    "            })\n",
    "    if bucket_data_list:\n",
    "        pd.DataFrame(bucket_data_list).to_excel(writer, sheet_name='Per Bucket Class Distribution', index=False)\n",
    "    logging.info(\"Exported class distributions to XLSX.\")\n",
    "\n",
    "\n",
    "def export_metrics_xlsx(writer: pd.ExcelWriter, all_fold_results: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"Exports aggregated CV metrics per bucket and model to Excel.\"\"\"\n",
    "    metrics_export_list = []\n",
    "    for res in all_fold_results: # res is one model's aggregated performance in one bucket\n",
    "        bucket_id = res['bucket_id']\n",
    "        model_name = res['model_name']\n",
    "        avg_metrics = res['avg_metrics'] # This should contain mean metrics from CV\n",
    "\n",
    "        # Macro metrics\n",
    "        for metric_key, report_name in [\n",
    "            ('accuracy_mean', 'Accuracy'), ('macro_precision_mean', 'Macro Precision'),\n",
    "            ('macro_recall_mean', 'Macro Recall'), ('macro_f1_mean', 'Macro F1-Score'),\n",
    "            ('auc_macro_ovr_mean', 'Macro AUC (OvR)')\n",
    "        ]:\n",
    "            metrics_export_list.append({\n",
    "                'Bucket ID': bucket_id, 'Model': model_name, 'Metric Type': 'Macro',\n",
    "                'Class': 'N/A', 'Metric Name': report_name, 'Value': avg_metrics.get(metric_key, np.nan)\n",
    "            })\n",
    "        \n",
    "        # Per-class metrics\n",
    "        if 'per_class_mean' in avg_metrics:\n",
    "            for cls_numeric, cls_avg_metrics in avg_metrics['per_class_mean'].items():\n",
    "                cls_name = TARGET_CLASS_NAMES[cls_numeric]\n",
    "                for pc_metric_key, pc_report_name in [\n",
    "                    ('precision_mean', 'Precision'), ('recall_mean', 'Recall'),\n",
    "                    ('f1_score_mean', 'F1-Score'), ('auc_ovr_mean', 'AUC (OvR)')\n",
    "                ]:\n",
    "                    metrics_export_list.append({\n",
    "                        'Bucket ID': bucket_id, 'Model': model_name, 'Metric Type': 'Per-Class',\n",
    "                        'Class': f\"{cls_name} ({cls_numeric})\", 'Metric Name': pc_report_name, \n",
    "                        'Value': cls_avg_metrics.get(pc_metric_key, np.nan)\n",
    "                    })\n",
    "    \n",
    "    if metrics_export_list:\n",
    "        pd.DataFrame(metrics_export_list).to_excel(writer, sheet_name='Model CV Metrics', index=False)\n",
    "    logging.info(\"Exported model CV metrics to XLSX.\")\n",
    "\n",
    "def export_hyperparameters_xlsx(writer: pd.ExcelWriter, all_fold_results: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"Exports best hyperparameters (from final model fit on full bucket data) to Excel.\"\"\"\n",
    "    params_list = []\n",
    "    for res in all_fold_results:\n",
    "        if res.get('final_best_params'): # These are from the model trained on full bucket data after CV\n",
    "            for param_name, param_value in res['final_best_params'].items():\n",
    "                params_list.append({\n",
    "                    'Bucket ID': res['bucket_id'], 'Model': res['model_name'],\n",
    "                    'Parameter': param_name, 'Value': str(param_value)\n",
    "                })\n",
    "    if params_list:\n",
    "        pd.DataFrame(params_list).to_excel(writer, sheet_name='Best Hyperparameters', index=False)\n",
    "    logging.info(\"Exported best hyperparameters to XLSX.\")\n",
    "\n",
    "def export_feature_importances_xlsx(writer: pd.ExcelWriter, all_fold_results: List[Dict[str, Any]], feature_names_map: Dict[str, List[str]]) -> None:\n",
    "    \"\"\"Exports feature importances from final models to Excel.\"\"\"\n",
    "    importances_list = []\n",
    "    for res in all_fold_results:\n",
    "        model = res.get('final_trained_model') # Model trained on full bucket data\n",
    "        bucket_id = res['bucket_id']\n",
    "        model_name = res['model_name']\n",
    "        \n",
    "        # Get correct feature names for this bucket (after preprocessing)\n",
    "        # These names come from the preprocessor fitted on the bucket's data or globally\n",
    "        bucket_feature_names = feature_names_map.get(bucket_id)\n",
    "        if not bucket_feature_names:\n",
    "            logging.warning(f\"No feature names found for bucket '{bucket_id}'. Skipping FI export for model '{model_name}'.\")\n",
    "            continue\n",
    "\n",
    "        fi_values = None\n",
    "        fi_type = \"Importance\"\n",
    "        if hasattr(model, 'feature_importances_'): # Tree-based models\n",
    "            fi_values = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'): # Linear models\n",
    "            if model.coef_.ndim == 2 and model.coef_.shape[0] > 1: # Multi-class coef_\n",
    "                fi_values = np.mean(np.abs(model.coef_), axis=0) # Avg abs coef across classes\n",
    "            else: # Binary or single output coef_\n",
    "                fi_values = np.abs(model.coef_.flatten())\n",
    "            fi_type = \"Abs Coefficient\"\n",
    "        \n",
    "        if fi_values is not None:\n",
    "            if len(bucket_feature_names) == len(fi_values):\n",
    "                for feat_name, importance_val in zip(bucket_feature_names, fi_values):\n",
    "                    importances_list.append({\n",
    "                        'Bucket ID': bucket_id, 'Model': model_name,\n",
    "                        'Feature': feat_name, fi_type: importance_val\n",
    "                    })\n",
    "            else:\n",
    "                logging.warning(f\"Feature name/importance length mismatch for {model_name} in bucket {bucket_id}. Names: {len(bucket_feature_names)}, FI: {len(fi_values)}. Skipping.\")\n",
    "        else:\n",
    "            logging.info(f\"Model {model_name} in bucket {bucket_id} does not have standard feature_importances_ or coef_ attribute.\")\n",
    "\n",
    "    if importances_list:\n",
    "        df_importances = pd.DataFrame(importances_list)\n",
    "        # Sort by importance value descending\n",
    "        sort_col = \"Importance\" if \"Importance\" in df_importances.columns else \"Abs Coefficient\"\n",
    "        df_importances = df_importances.sort_values(by=['Bucket ID', 'Model', sort_col], ascending=[True, True, False])\n",
    "        df_importances.to_excel(writer, sheet_name='Feature Importances', index=False)\n",
    "    logging.info(\"Exported feature importances to XLSX.\")\n",
    "\n",
    "\n",
    "def export_confusion_matrices_xlsx_and_png(\n",
    "    writer: pd.ExcelWriter, \n",
    "    all_fold_results: List[Dict[str, Any]], \n",
    "    output_dir_path: Path\n",
    ") -> None:\n",
    "    \"\"\"Exports aggregated confusion matrices (from CV) to Excel tables and PNG heatmaps.\"\"\"\n",
    "    cm_png_dir = output_dir_path / CM_SUBDIR_NAME\n",
    "    cm_png_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    current_row_excel = 0\n",
    "    sheet_name_excel = 'Aggregated CV CMs'\n",
    "\n",
    "    for res in all_fold_results:\n",
    "        cm_array = res.get('aggregated_cv_cm') # Sum of CMs from CV folds\n",
    "        bucket_id = res['bucket_id']\n",
    "        model_name = res['model_name']\n",
    "        \n",
    "        # Ensure class labels for CM are consistent (0, 1, 2)\n",
    "        cm_display_labels_str = TARGET_CLASS_NAMES\n",
    "        cm_display_labels_num = CLASS_LABELS_NUMERIC\n",
    "\n",
    "        if cm_array is not None and cm_array.size > 0 and cm_array.shape == (len(cm_display_labels_num), len(cm_display_labels_num)):\n",
    "            # --- Export to XLSX Table ---\n",
    "            df_cm = pd.DataFrame(cm_array, index=cm_display_labels_str, columns=cm_display_labels_str)\n",
    "            \n",
    "            header_df = pd.DataFrame([\n",
    "                [f\"Aggregated CV Confusion Matrix: Bucket {bucket_id}, Model {model_name}\"],\n",
    "                [\"Actual \\\\ Predicted\"] + cm_display_labels_str\n",
    "            ])\n",
    "            header_df.to_excel(writer, sheet_name=sheet_name_excel, startrow=current_row_excel, header=False, index=False)\n",
    "            current_row_excel += len(header_df)\n",
    "            df_cm.to_excel(writer, sheet_name=sheet_name_excel, startrow=current_row_excel, header=True, index=True) # Index=True for Actual labels\n",
    "            current_row_excel += len(df_cm) + 3 # Add spacing\n",
    "\n",
    "            # --- Export to PNG Heatmap ---\n",
    "            try:\n",
    "                fig, ax = plt.subplots(figsize=(7, 5)) # Smaller figure for individual CMs\n",
    "                disp = ConfusionMatrixDisplay(confusion_matrix=cm_array, display_labels=cm_display_labels_str)\n",
    "                disp.plot(ax=ax, cmap=plt.cm.Blues, values_format='d')\n",
    "                ax.set_title(f\"Agg. CV CM: {model_name}\\nBucket: {bucket_id}\", fontsize=10)\n",
    "                plt.tight_layout()\n",
    "                png_filename = f\"cm_agg_cv_{bucket_id}_{model_name}.png\".replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "                plt.savefig(cm_png_dir / png_filename)\n",
    "                plt.close(fig)\n",
    "            except Exception as e_plot:\n",
    "                logging.error(f\"Error plotting/saving CM PNG for {model_name}, bucket {bucket_id}: {e_plot}\")\n",
    "        else:\n",
    "            logging.warning(f\"Skipping CM export for {model_name} in bucket {bucket_id} due to missing, empty, or malformed CM array.\")\n",
    "            \n",
    "    if current_row_excel > 0:\n",
    "        logging.info(f\"Exported aggregated CV confusion matrices (tables) to XLSX sheet '{sheet_name_excel}'.\")\n",
    "    logging.info(f\"Exported confusion matrix PNGs to {cm_png_dir}.\")\n",
    "\n",
    "# ==========================\n",
    "# Main Pipeline Orchestration\n",
    "#  Run the full experiment, including logging & exports\n",
    "# ==========================\n",
    "def run_pipeline() -> None:\n",
    "    \"\"\"\n",
    "    Executes the full experiment:\n",
    "       Merges / preprocesses data\n",
    "       Buckets by judge (or generic bucket)\n",
    "       Balances data per user config\n",
    "       Performs CV with RandomizedSearchCV hyper-param tuning\n",
    "       Evaluates on held-out TEST set\n",
    "       Cross-evaluates every model on every buckets TEST set  (NEW)\n",
    "       Persists fitted model+transformer bundles to disk       (NEW)\n",
    "       Exports distributions, metrics, best params, feature\n",
    "        importances, confusion matrices, and cross-metrics\n",
    "        to XLSX / PNG / .joblib\n",
    "    \"\"\"\n",
    "    # \n",
    "    global CONFIG\n",
    "    out_dir = Path(CONFIG['output_dir_actual'])\n",
    "    cm_dir  = out_dir / CM_SUBDIR_NAME\n",
    "    cm_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    #  NEW  directory for serialised models\n",
    "    model_dir = out_dir / \"model_bundles\"\n",
    "    model_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    #  containers for cross-evaluation (NEW) \n",
    "    model_bundles: Dict[Tuple[str, str], Dict[str, Any]] = {}\n",
    "    test_sets_raw: Dict[str, Tuple[pd.DataFrame, pd.Series]] = {}\n",
    "\n",
    "    #  DATA LOADING \n",
    "    df_cases  = load_data_from_path(CONFIG['cases_file_path'], \"Cases Data\")\n",
    "    df_judges = load_data_from_path(CONFIG.get('judges_file_path'), \"Judges Data\")\n",
    "    if df_cases is None:\n",
    "        sys.exit(\"Cases data missing  aborting.\")\n",
    "\n",
    "    df_merged    = full_data_merge(df_cases, df_judges, CONFIG)\n",
    "    df_processed = preprocess_data(df_merged, CONFIG)\n",
    "    if df_processed.empty:\n",
    "        sys.exit(\"No data after preprocessing  aborting.\")\n",
    "\n",
    "    print_section_header(\"DATA OVERVIEW\")\n",
    "    print(f\"Final dataframe shape : {df_processed.shape}\")\n",
    "\n",
    "    #  BALANCING CONFIG (needs distribution) \n",
    "    global_counter = Counter(df_processed[CONFIG['target_col']])\n",
    "    get_balancing_config_interactive(global_counter)   # Updates CONFIG inplace\n",
    "\n",
    "    #  TEST-SET SHARE PROMPT \n",
    "    cv_folds = CONFIG['cv_folds']\n",
    "    test_pct = float(\n",
    "        safe_input(\"\\nTest-set percentage\", default=\"20\", type_caster=float)\n",
    "    )\n",
    "    CONFIG['test_size'] = test_pct / 100.0\n",
    "    print(f\"Validation share per fold  {100/cv_folds:.1f}%\")\n",
    "\n",
    "    #  FEATURE TRANSFORMER & BUCKETS \n",
    "    transformer = get_feature_transformer(CONFIG)\n",
    "    buckets     = create_judge_buckets(df_processed, CONFIG)\n",
    "    if not buckets:\n",
    "        sys.exit(\"No buckets created  aborting.\")\n",
    "\n",
    "    #  containers for XLSX export \n",
    "    dist_rows, agg_rows, test_rows, cm_tables = [], [], [], []\n",
    "    hp_rows, feat_rows = [], []\n",
    "\n",
    "    #  MAIN LOOP OVER BUCKETS \n",
    "    for bucket_id, bucket_df in buckets.items():\n",
    "        header = f\"BUCKET {bucket_id}  ({len(bucket_df)} samples)\"\n",
    "        print_section_header(header)\n",
    "        logging.info(header)\n",
    "\n",
    "        if bucket_df[CONFIG['target_col']].nunique() < 2:\n",
    "            print(\"Skipped: only one class present.\")\n",
    "            continue\n",
    "\n",
    "        X_all = bucket_df[CONFIG['feature_cols']]\n",
    "        y_all = bucket_df[CONFIG['target_col']].astype(int)\n",
    "\n",
    "        # Split\n",
    "        X_tr_raw, X_te_raw, y_tr_raw, y_te = train_test_split(\n",
    "            X_all, y_all,\n",
    "            test_size=CONFIG['test_size'],\n",
    "            stratify=y_all,\n",
    "            random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        #  NEW  cache the raw TEST set once per bucket (for cross eval)\n",
    "        if bucket_id not in test_sets_raw:\n",
    "            test_sets_raw[bucket_id] = (X_te_raw.copy(), y_te.copy())\n",
    "\n",
    "        # transformer\n",
    "        transformer.fit(X_tr_raw)\n",
    "        X_tr_raw = pd.DataFrame(transformer.transform(X_tr_raw),\n",
    "                                columns=transformer.get_feature_names_out(),\n",
    "                                index=X_tr_raw.index)\n",
    "        X_te = pd.DataFrame(transformer.transform(X_te_raw),\n",
    "                            columns=transformer.get_feature_names_out(),\n",
    "                            index=X_te_raw.index)\n",
    "\n",
    "        # store raw TRAIN / TEST distributions\n",
    "        dist_rows += distribution_to_rows(Counter(y_tr_raw), bucket_id, \"TRAIN_BEFORE\")\n",
    "        dist_rows += distribution_to_rows(Counter(y_te),      bucket_id, \"TEST\")\n",
    "\n",
    "        skf = StratifiedKFold(\n",
    "            n_splits=cv_folds,\n",
    "            shuffle=True,\n",
    "            random_state=CONFIG['cv_random_state']\n",
    "        )\n",
    "\n",
    "        #  MODELS \n",
    "        for model_name in CONFIG['models_to_run']:\n",
    "            print(f\"\\nModel: {model_name}\")\n",
    "            fold_metrics = []\n",
    "\n",
    "            #  CV loop \n",
    "            for f, (idx_tr, idx_val) in enumerate(skf.split(X_tr_raw, y_tr_raw), 1):\n",
    "                subset_tag = f\"FOLD{f}_TRAIN\"\n",
    "                X_f_tr_raw, y_f_tr_raw = X_tr_raw.iloc[idx_tr], y_tr_raw.iloc[idx_tr]\n",
    "                X_f_val,    y_f_val    = X_tr_raw.iloc[idx_val], y_tr_raw.iloc[idx_val]\n",
    "\n",
    "                # balance TRAIN fold\n",
    "                X_bal, y_bal, sw, cnt_bef, cnt_aft = balance_data_for_fold(\n",
    "                    X_f_tr_raw, y_f_tr_raw, CONFIG, tag=f\"{bucket_id}_f{f}\"\n",
    "                )\n",
    "                # log BEFORE/AFTER rows\n",
    "                dist_rows += distribution_to_rows(cnt_bef, bucket_id, f\"{subset_tag}_BEFORE\")\n",
    "                dist_rows += distribution_to_rows(cnt_aft, bucket_id, f\"{subset_tag}_AFTER\")\n",
    "\n",
    "                tuned_model, _ = tune_hyperparameters(\n",
    "                    X_bal, y_bal, model_name,\n",
    "                    CONFIG['hyperparameter_grids'][model_name],\n",
    "                    cv_folds_inner=max(2, cv_folds//2),\n",
    "                    n_iter=CONFIG['hyperparameter_tuning_iterations'],\n",
    "                    sample_weight_train=sw\n",
    "                )\n",
    "                met, _ = evaluate_model_on_test_set(tuned_model, X_f_val, y_f_val)\n",
    "                fold_metrics.append(met)\n",
    "                print(f\"  Fold {f}/{cv_folds}  Macro-F1 = {met.get('macro_f1', np.nan):.3f}\")\n",
    "\n",
    "            # aggregate CV\n",
    "            keys = [\"accuracy\", \"macro_precision\", \"macro_recall\", \"macro_f1\"]\n",
    "            agg = {f\"{k}_mean\": float(np.nanmean([m[k] for m in fold_metrics])) for k in keys}\n",
    "            agg.update({f\"{k}_std\": float(np.nanstd([m[k] for m in fold_metrics])) for k in keys})\n",
    "            agg_rows.append(dict(Bucket=bucket_id, Model=model_name, **agg))\n",
    "            print(f\"  CV Macro-F1 = {agg['macro_f1_mean']:.3f}  {agg['macro_f1_std']:.3f}\")\n",
    "\n",
    "            #  final model on full TRAIN (balanced) \n",
    "            X_bal_fin, y_bal_fin, sw_fin, cnt_bef_fin, cnt_aft_fin = balance_data_for_fold(\n",
    "                X_tr_raw, y_tr_raw, CONFIG, tag=f\"{bucket_id}_final\"\n",
    "            )\n",
    "            dist_rows += distribution_to_rows(cnt_bef_fin, bucket_id, \"TRAIN_FULL_BEFORE\")\n",
    "            dist_rows += distribution_to_rows(cnt_aft_fin, bucket_id, \"TRAIN_FULL_AFTER\")\n",
    "\n",
    "            final_model, best_params = tune_hyperparameters(\n",
    "                X_bal_fin, y_bal_fin, model_name,\n",
    "                CONFIG['hyperparameter_grids'][model_name],\n",
    "                cv_folds_inner=cv_folds,\n",
    "                n_iter=CONFIG['hyperparameter_tuning_iterations'],\n",
    "                sample_weight_train=sw_fin\n",
    "            )\n",
    "\n",
    "            # store best hyper-parameters\n",
    "            hp_row = {\"Bucket\": bucket_id, \"Model\": model_name}\n",
    "            hp_row.update(best_params)\n",
    "            hp_rows.append(hp_row)\n",
    "\n",
    "            # test evaluation\n",
    "            test_met, test_cm = evaluate_model_on_test_set(final_model, X_te, y_te)\n",
    "            test_rows.append(dict(Bucket=bucket_id, Model=model_name, **test_met))\n",
    "            print(f\"  TEST Macro-F1 = {test_met.get('macro_f1', np.nan):.3f}\")\n",
    "\n",
    "            # confusion matrix PNG + DF\n",
    "            if test_cm.size:\n",
    "                cm_path = cm_dir / f\"{bucket_id}_{model_name}_TEST.png\"\n",
    "                save_cm_png(test_cm, TARGET_CLASS_NAMES,\n",
    "                            f\"{bucket_id}-{model_name}-TEST\", cm_path)\n",
    "                cm_df = cm_to_dataframe(test_cm, TARGET_CLASS_NAMES)\n",
    "                cm_df['Bucket'], cm_df['Model'], cm_df['Fold'] = bucket_id, model_name, \"TEST\"\n",
    "                cm_tables.append(cm_df)\n",
    "\n",
    "            # feature importances\n",
    "            feat_imp = get_feature_importances(final_model, list(X_bal_fin.columns))\n",
    "            for rank, (fname, score) in enumerate(feat_imp.sort_values(ascending=False).head(TOP_K_FEATURES).items(), 1):\n",
    "                feat_rows.append({\n",
    "                    \"Bucket\": bucket_id,\n",
    "                    \"Model\": model_name,\n",
    "                    \"Rank\":  rank,\n",
    "                    \"Feature\": fname,\n",
    "                    \"Importance\": float(score)\n",
    "                })\n",
    "\n",
    "            #  NEW  cache model + transformer for cross-eval\n",
    "            import copy\n",
    "            bundle_meta = {\n",
    "                \"bucket_id\": bucket_id,\n",
    "                \"model_name\": model_name,\n",
    "                \"n_samples_bucket\": len(bucket_df),\n",
    "            }\n",
    "            bundle = {\n",
    "                \"model\": final_model,\n",
    "                \"transformer\": copy.deepcopy(transformer),\n",
    "                \"meta\": bundle_meta,\n",
    "            }\n",
    "            model_bundles[(bucket_id, model_name)] = bundle\n",
    "\n",
    "            #  NEW  persist bundle to disk\n",
    "            bundle_path = model_dir / f\"{bucket_id}_{model_name}.joblib\"\n",
    "            export_model_bundle(final_model, transformer, bundle_meta, bundle_path)\n",
    "\n",
    "    #  CROSS-BUCKET EVALUATION (NEW) \n",
    "    cross_rows, cross_cm_tables = cross_compare_models(\n",
    "        model_bundles=model_bundles,\n",
    "        test_sets=test_sets_raw,\n",
    "        out_dir=out_dir,\n",
    "    )\n",
    "\n",
    "    #  EXPORT XLSX \n",
    "    xlsx_path = out_dir / RESULTS_XLSX_FILENAME\n",
    "    with pd.ExcelWriter(xlsx_path) as writer:\n",
    "        pd.DataFrame(dist_rows).to_excel(writer, \"Distributions\", index=False)\n",
    "        pd.DataFrame(agg_rows).to_excel(writer, \"CV_Aggregated\", index=False)\n",
    "        pd.DataFrame(test_rows).to_excel(writer, \"Test_Metrics\", index=False)\n",
    "        if cross_rows:\n",
    "            pd.DataFrame(cross_rows).to_excel(writer, \"Cross_Test_Metrics\", index=False)\n",
    "        if hp_rows:\n",
    "            pd.DataFrame(hp_rows).to_excel(writer, \"Best_Hyperparameters\", index=False)\n",
    "        if feat_rows:\n",
    "            pd.DataFrame(feat_rows).to_excel(writer, \"Top_Features\", index=False)\n",
    "        if cm_tables:\n",
    "            pd.concat(cm_tables).to_excel(writer, \"Confusion_Matrices\", index=False)\n",
    "        if cross_cm_tables:\n",
    "            pd.concat(cross_cm_tables).to_excel(writer, \"Cross_Confusion_Matrices\", index=False)\n",
    "\n",
    "    print_section_header(\"Pipeline Completed\")\n",
    "    print(f\"Results saved to {xlsx_path}\")\n",
    "    logging.info(f\"Run finished. Results saved to {xlsx_path}\")\n",
    "\n",
    "# ==========================\n",
    "# Entry Point\n",
    "# ==========================\n",
    "# Place this function definition before main_interactive_pipeline()\n",
    "\n",
    "def load_or_trigger_interactive_config(output_dir_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Attempts to load configuration from a file. If not chosen or fails,\n",
    "    triggers the full interactive setup process.\n",
    "    Populates the global CONFIG.\n",
    "    \"\"\"\n",
    "    global CONFIG\n",
    "    \n",
    "    # Try to find a default config file in the experiment directory\n",
    "    default_config_file_in_experiment_dir = output_dir_path / CONFIG_FILENAME\n",
    "\n",
    "    load_from_file = get_yes_no_input(\n",
    "        f\"Load configuration from a file? (Default config if exists: {default_config_file_in_experiment_dir})\",\n",
    "        default_yes=default_config_file_in_experiment_dir.exists() # Default to yes if config found\n",
    "    )\n",
    "\n",
    "    if load_from_file:\n",
    "        if default_config_file_in_experiment_dir.exists():\n",
    "            chosen_path_str = safe_input(\"Enter path to configuration JSON file\", default=str(default_config_file_in_experiment_dir))\n",
    "        else:\n",
    "            chosen_path_str = safe_input(\"Enter path to configuration JSON file (no default found in experiment dir)\")\n",
    "        \n",
    "        chosen_path = Path(_clean_path_input(chosen_path_str))\n",
    "        try:\n",
    "            with open(chosen_path, 'r', encoding='utf-8') as f:\n",
    "                CONFIG = json.load(f)\n",
    "            logging.info(f\"Configuration successfully loaded from {chosen_path}\")\n",
    "            \n",
    "            # Ensure essential output directory paths are correctly set in the loaded CONFIG\n",
    "            # The loaded config might have an old output_base_dir.\n",
    "            # For this run, the output_dir_path (timestamped experiment dir) is fixed.\n",
    "            CONFIG['output_dir_actual'] = str(output_dir_path)\n",
    "            CONFIG['output_base_dir'] = str(output_dir_path.parent) # The parent of the timestamped dir\n",
    "            return # Config loaded successfully\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"Configuration file not found: {chosen_path}. Proceeding with interactive setup.\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            logging.error(f\"Error decoding JSON from configuration file {chosen_path}: {e}. Proceeding with interactive setup.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"An unexpected error occurred loading config file '{chosen_path}': {e}. Proceeding with interactive setup.\")\n",
    "        # If loading failed, fall through to interactive setup\n",
    "    \n",
    "    # If not loading from file, or if loading failed, proceed with full interactive setup\n",
    "    logging.info(\"Proceeding with interactive configuration setup.\")\n",
    "    _interactive_setup_configuration(output_dir_path) # Calls the new helper\n",
    "\n",
    "# Place this function definition before main_interactive_pipeline()\n",
    "\n",
    "def _interactive_setup_configuration(output_dir_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Handles the complete interactive configuration process, populating the global CONFIG.\n",
    "    This includes file paths, data loading, interactive merge, saving merged data,\n",
    "    and then selecting operational columns, validating features, and other settings.\n",
    "    \"\"\"\n",
    "    global CONFIG\n",
    "\n",
    "    print_section_header(\"Pipeline Configuration (Interactive Mode)\")\n",
    "\n",
    "    # --- Step 1: Get File Paths ---\n",
    "    # output_base_dir is already implicitly handled by output_dir_path's parent\n",
    "    # output_dir_actual is output_dir_path\n",
    "    CONFIG.update(get_file_paths_config()) # This gets cases_file_path, judges_file_path\n",
    "                                           # and might re-get output_base_dir if user changes it,\n",
    "                                           # but output_dir_actual_path is already fixed for this run.\n",
    "    CONFIG['output_dir_actual'] = str(output_dir_path) # Ensure this is always set\n",
    "\n",
    "    # --- Step 2: Load Raw Data ---\n",
    "    logging.info(\"Starting raw data load for interactive configuration...\")\n",
    "    df_cases_raw = load_data_from_path(CONFIG.get('cases_file_path'), \"Raw Cases Data\")\n",
    "    if df_cases_raw is None:\n",
    "        logging.critical(\"Raw cases data could not be loaded. Cannot proceed with interactive setup.\")\n",
    "        sys.exit(\"Raw cases data is essential for configuration.\")\n",
    "\n",
    "    df_judges_raw = None\n",
    "    if CONFIG.get('judges_file_path'): # Check if path is not None and not empty string\n",
    "        df_judges_raw = load_data_from_path(CONFIG.get('judges_file_path'), \"Raw Judges Data\")\n",
    "        if df_judges_raw is None:\n",
    "            logging.warning(\"Judges file path was provided, but data could not be loaded. Merge will be skipped.\")\n",
    "\n",
    "    # --- Step 3: Configure and Perform Data Merge Interactively ---\n",
    "    df_merged_for_pipeline = df_cases_raw.copy() # Default to cases data if no judges or merge fails\n",
    "\n",
    "    if df_judges_raw is not None:\n",
    "        print_section_header(\"Configure Data Merge\")\n",
    "        display_df_columns(df_cases_raw, \"RAW CASES Data - Select Linking Column\")\n",
    "        cases_link_col_name = _select_columns_interactive(\n",
    "            list(df_cases_raw.columns),\n",
    "            \"Enter column name from RAW CASES data to link with Judges data\",\n",
    "            allow_multiple=False, is_required=True\n",
    "        )\n",
    "        \n",
    "        display_df_columns(df_judges_raw, \"RAW JUDGES Data - Select Linking Column\")\n",
    "        judges_link_col_name = _select_columns_interactive(\n",
    "            list(df_judges_raw.columns),\n",
    "            \"Enter corresponding column name from RAW JUDGES data\",\n",
    "            allow_multiple=False, is_required=True\n",
    "        )\n",
    "        \n",
    "        merge_type = safe_input(\n",
    "            \"Enter merge type (e.g., 'left', 'inner')\",\n",
    "            default='left',\n",
    "            choices=['left', 'right', 'inner', 'outer']\n",
    "        ).lower()\n",
    "\n",
    "        if cases_link_col_name and judges_link_col_name:\n",
    "            # Store merge parameters in CONFIG for run_pipeline and reproducibility\n",
    "            CONFIG['merge_config'] = {\n",
    "                'cases_link_col': str(cases_link_col_name),\n",
    "                'judges_link_col': str(judges_link_col_name),\n",
    "                'how': merge_type\n",
    "            }\n",
    "            try:\n",
    "                # Perform the merge for subsequent steps\n",
    "                # Ensure keys are strings for pd.merge\n",
    "                df_cases_raw_copy = df_cases_raw.copy() # Use copies for merge operation\n",
    "                df_judges_raw_copy = df_judges_raw.copy()\n",
    "                df_cases_raw_copy[str(cases_link_col_name)] = df_cases_raw_copy[str(cases_link_col_name)].astype(str)\n",
    "                df_judges_raw_copy[str(judges_link_col_name)] = df_judges_raw_copy[str(judges_link_col_name)].astype(str)\n",
    "\n",
    "                df_merged_for_pipeline = pd.merge(\n",
    "                    df_cases_raw_copy, df_judges_raw_copy,\n",
    "                    left_on=str(cases_link_col_name),\n",
    "                    right_on=str(judges_link_col_name),\n",
    "                    how=merge_type,\n",
    "                    suffixes=('_case', '_judge') # Handle overlapping column names\n",
    "                )\n",
    "                logging.info(f\"Interactive merge successful. Merged data shape: {df_merged_for_pipeline.shape}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during interactive merge: {e}. Proceeding with unmerged CASES data.\")\n",
    "                df_merged_for_pipeline = df_cases_raw.copy() # Fallback\n",
    "                CONFIG.pop('merge_config', None) # Remove invalid merge config\n",
    "        else:\n",
    "            logging.warning(\"Linking columns for merge not specified by user. Proceeding with unmerged CASES data.\")\n",
    "            df_merged_for_pipeline = df_cases_raw.copy()\n",
    "            CONFIG.pop('merge_config', None)\n",
    "    else:\n",
    "        logging.info(\"No judges data provided. Skipping merge configuration. Using raw cases data.\")\n",
    "        CONFIG.pop('merge_config', None) # Ensure no old merge_config is present\n",
    "\n",
    "\n",
    "    # --- Step 4: Save the Merged Data ---\n",
    "    merged_data_filename = \"01_merged_data_interactive_setup.xlsx\"\n",
    "    merged_data_file_path = output_dir_path / merged_data_filename\n",
    "    try:\n",
    "        df_merged_for_pipeline.to_excel(merged_data_file_path, index=False)\n",
    "        logging.info(f\"Interactively merged data saved to: {merged_data_file_path}\")\n",
    "        CONFIG['merged_data_path'] = str(merged_data_file_path) # Store path for reference\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save interactively merged data: {e}\")\n",
    "        # Pipeline can still continue if df_merged_for_pipeline is in memory\n",
    "\n",
    "    if df_merged_for_pipeline.empty: # Critical check after merge attempt\n",
    "        logging.critical(\"Data is empty after merge attempt. Cannot proceed with configuration.\")\n",
    "        sys.exit(\"Data became empty after merge. Check merge keys and data.\")\n",
    "\n",
    "    # --- Step 5: Configure Operational Columns (using your patched function) ---\n",
    "    # This uses the df_merged_for_pipeline created above\n",
    "    CONFIG.update(get_operational_columns_config(df_merged_for_pipeline, CONFIG))\n",
    "\n",
    "    # --- Step 6: Validate Feature Types ---\n",
    "    if not CONFIG.get('feature_cols'):\n",
    "        logging.warning(\"No feature columns selected. Skipping feature type validation.\")\n",
    "    else:\n",
    "        numerical_cols, categorical_cols = validate_feature_types_interactive(\n",
    "            df_merged_for_pipeline, # Use the same merged df\n",
    "            CONFIG['feature_cols']\n",
    "        )\n",
    "        CONFIG['numerical_features'] = numerical_cols\n",
    "        CONFIG['categorical_features'] = categorical_cols\n",
    "\n",
    "    # --- Step 7: Configure Target Encoding ---\n",
    "    CONFIG.update(get_encoding_config_interactive(\n",
    "        df_merged_for_pipeline, # Use the same merged df\n",
    "        CONFIG['target_col']\n",
    "    ))\n",
    "\n",
    "    # --- Step 8: Configure Bucketing ---\n",
    "    CONFIG.update(get_bucketing_config_interactive())\n",
    "\n",
    "    # --- Step 9: Configure Balancing ---\n",
    "    CONFIG.update(get_balancing_config_interactive())\n",
    "\n",
    "    # --- Step 10: Configure CV, Models, Hyperparameters ---\n",
    "    CONFIG.update(get_cv_model_hyperparam_config())\n",
    "\n",
    "    logging.info(\"Interactive configuration process complete.\")\n",
    "    # The final CONFIG is now populated. It will be saved by the calling function.\n",
    "\n",
    "# This is your main script entry point\n",
    "\n",
    "def main_interactive_pipeline() -> None:\n",
    "    \"\"\"Main function to run the pipeline, handling initial setup and config.\"\"\"\n",
    "    global CONFIG # CONFIG will be populated by load_or_trigger_interactive_config\n",
    "    \n",
    "    # 0. Initial Setup (Output Dir for this specific run, Preliminary Logging)\n",
    "    # Determine initial base directory for outputs. This can be a constant or user-defined.\n",
    "    # For simplicity, let's assume a default. The user can change it during get_file_paths_config\n",
    "    # if interactive setup is chosen, but the actual experiment_YYYYMMDD_HHMMSS dir is created once.\n",
    "    initial_base_dir = DEFAULT_OUTPUT_BASE_DIR \n",
    "    \n",
    "    # Create the unique timestamped output directory for this run\n",
    "    # This directory will house logs, configs, and results for THIS execution.\n",
    "    try:\n",
    "        output_dir_actual_str = create_output_directory(initial_base_dir)\n",
    "        output_dir_actual_path = Path(output_dir_actual_str)\n",
    "    except Exception as e:\n",
    "        # Fallback if directory creation fails (e.g. permissions)\n",
    "        print(f\"CRITICAL: Failed to create output directory in '{initial_base_dir}': {e}\")\n",
    "        print(\"Please check permissions or specify a different base directory.\")\n",
    "        # Use a local fallback directory\n",
    "        fallback_dir_name = f\"pipeline_outputs_fallback_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        output_dir_actual_path = Path(fallback_dir_name)\n",
    "        output_dir_actual_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Using fallback output directory: {output_dir_actual_path.resolve()}\")\n",
    "        initial_base_dir = str(output_dir_actual_path.parent) # Update base dir to reflect fallback\n",
    "        # Store these paths in CONFIG early so logging can use them.\n",
    "        CONFIG['output_dir_actual'] = str(output_dir_actual_path)\n",
    "        CONFIG['output_base_dir'] = initial_base_dir\n",
    "\n",
    "\n",
    "    # Setup logging to the actual output directory (timestamped one)\n",
    "    log_file_path = output_dir_actual_path / LOG_FILENAME\n",
    "    setup_logging(log_file_path) # Logging starts here properly for the run\n",
    "\n",
    "    # Store the determined output paths in CONFIG so they are saved if user saves config\n",
    "    # and accessible by all functions.\n",
    "    CONFIG['output_dir_actual'] = str(output_dir_actual_path)\n",
    "    CONFIG['output_base_dir'] = initial_base_dir # This might be updated if user changes it in interactive file paths\n",
    "\n",
    "    try:\n",
    "        # 1. Load configuration from file OR go through full interactive setup\n",
    "        # This function will populate the global CONFIG dictionary.\n",
    "        load_or_trigger_interactive_config(output_dir_actual_path)\n",
    "\n",
    "        # 2. Save the final configuration (whether loaded or interactively built)\n",
    "        # This ensures the config used for *this run* is saved in *this run's output dir*.\n",
    "        final_config_path_for_this_run = output_dir_actual_path / CONFIG_FILENAME\n",
    "        save_config(CONFIG, final_config_path_for_this_run)\n",
    "        logging.info(f\"Final configuration for this run saved to: {final_config_path_for_this_run}\")\n",
    "\n",
    "        # 3. Run the main processing pipeline using the populated CONFIG\n",
    "        run_pipeline() # run_pipeline will use the global CONFIG\n",
    "\n",
    "    except SystemExit as e:\n",
    "        logging.error(f\"Pipeline terminated: {e}\")\n",
    "        print(f\"Pipeline terminated: {e}\")\n",
    "    except Exception as e:\n",
    "        logging.critical(\"An unhandled critical error occurred in the main pipeline driver:\")\n",
    "        logging.critical(traceback.format_exc()) # Log full traceback\n",
    "        print(f\"CRITICAL PIPELINE ERROR: {e}\\nSee log file for details: {log_file_path}\")\n",
    "    finally:\n",
    "        logging.info(\"Performing final cleanup if any...\")\n",
    "        gc.collect()\n",
    "        logging.info(\"Exiting legal case outcome prediction pipeline application.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_interactive_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5460f-24a3-4025-b9e6-74a008c9cace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:work]",
   "language": "python",
   "name": "conda-env-work-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
